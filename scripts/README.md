# üõ†Ô∏è Scripts de Utilidad

Esta carpeta contiene scripts √∫tiles para gestionar el workshop de Medical Reports Automation.

## üìú Scripts Disponibles

### 1. cleanup.sh

**Prop√≥sito:** Eliminar todos los recursos AWS creados durante el workshop.

**Uso:**
```bash
bash scripts/cleanup.sh
```

**Qu√© hace:**
- Elimina todos los stacks de CloudFormation en orden correcto
- Elimina base de datos Aurora (sin snapshots)
- Elimina funciones Lambda
- Elimina API Gateway
- Elimina roles y pol√≠ticas IAM
- Verifica recursos restantes

**Advertencia:** Este script es destructivo. Aseg√∫rate de que quieres eliminar todos los recursos antes de ejecutarlo.

**Ejemplo de salida:**
```
üßπ Iniciando limpieza de recursos AWS...

‚ö† ADVERTENCIA: Este script eliminar√° TODOS los recursos del workshop.
¬øEst√°s seguro de que quieres continuar? (escribe 'yes' para confirmar): yes

‚úì Iniciando limpieza...

‚úì Eliminando stack: AIEmailStack
‚úì Stack AIEmailStack eliminado exitosamente

‚úì Eliminando stack: AISummaryStack
‚úì Stack AISummaryStack eliminado exitosamente

...

‚úì ¬°Limpieza completada!
```

---

### 2. upload_sample_pdf.sh

**Prop√≥sito:** Subir PDFs de ejemplo al bucket S3 para probar el sistema de extracci√≥n.

**Uso:**

**Opci√≥n 1: Subir todos los PDFs de ejemplo**
```bash
bash scripts/upload_sample_pdf.sh
```

El script detectar√° autom√°ticamente el nombre del bucket desde CloudFormation.

**Opci√≥n 2: Subir un PDF espec√≠fico**
```bash
bash scripts/upload_sample_pdf.sh [archivo.pdf] [bucket-name]
```

**Ejemplos:**
```bash
# Subir todos los PDFs de ejemplo
bash scripts/upload_sample_pdf.sh

# Subir un PDF espec√≠fico
bash scripts/upload_sample_pdf.sh sample_data/informe_alto_riesgo.pdf my-bucket-name

# Subir un PDF personalizado
bash scripts/upload_sample_pdf.sh mi_informe.pdf my-bucket-name
```

**Qu√© hace:**
- Detecta autom√°ticamente el nombre del bucket (si no se especifica)
- Sube PDFs a la carpeta `external-reports/`
- Verifica que los archivos sean PDFs v√°lidos
- Lista los PDFs en S3 despu√©s de subir
- Proporciona comandos para verificar el procesamiento

**Ejemplo de salida:**
```
üìÑ Subir PDFs de Ejemplo a S3
==============================

‚úì Obteniendo nombre del bucket desde CloudFormation...
‚úì Bucket encontrado: medical-reports-bucket-abc123
‚úì PDFs encontrados: 3

Se subir√°n los siguientes archivos:
  - informe_alto_riesgo.pdf
  - informe_medio_riesgo.pdf
  - informe_bajo_riesgo.pdf

¬øContinuar? (y/n): y

Subiendo: informe_alto_riesgo.pdf
‚úì Subido: informe_alto_riesgo.pdf ‚Üí s3://medical-reports-bucket-abc123/external-reports/informe_alto_riesgo.pdf

...

‚úì Subidos: 3/3 PDFs

PDFs en S3:
----------
2024-01-15 10:30:00    1234567 external-reports/informe_alto_riesgo.pdf
2024-01-15 10:30:01    1234568 external-reports/informe_medio_riesgo.pdf
2024-01-15 10:30:02    1234569 external-reports/informe_bajo_riesgo.pdf

‚úì ¬°Listo! Los PDFs se procesar√°n autom√°ticamente.
```

---

## üöÄ Flujo de Trabajo T√≠pico

### Durante el Workshop

1. **Desplegar infraestructura:**
   ```bash
   cd cdk
   cdk deploy --all
   ```

2. **Subir PDFs de prueba:**
   ```bash
   bash scripts/upload_sample_pdf.sh
   ```

3. **Verificar procesamiento:**
   ```bash
   aws logs tail /aws/lambda/extract-pdf --follow
   ```

### Despu√©s del Workshop

1. **Limpiar recursos:**
   ```bash
   bash scripts/cleanup.sh
   ```

2. **Verificar limpieza:**
   ```bash
   aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE
   ```

---

## üìù Notas Importantes

### Permisos Requeridos

Los scripts requieren que tengas configurado AWS CLI con credenciales que tengan permisos para:
- CloudFormation (crear/eliminar stacks)
- S3 (subir/listar objetos)
- Lambda (ver logs)
- IAM (crear/eliminar roles)

### Regiones

Los scripts usan la regi√≥n configurada en tu AWS CLI. Verifica que est√©s en la regi√≥n correcta:
```bash
aws configure get region
```

### Troubleshooting

**Error: "Debes ejecutar este script desde la ra√≠z del proyecto"**
- Soluci√≥n: Ejecuta el script desde el directorio ra√≠z del proyecto, no desde la carpeta `scripts/`

**Error: "No se pudo obtener el nombre del bucket"**
- Soluci√≥n: Especifica el nombre del bucket manualmente o verifica que el stack LegacyStack est√© desplegado

**Error: "Stack no existe"**
- Soluci√≥n: Normal si el stack ya fue eliminado o nunca se despleg√≥

---

## üîß Personalizaci√≥n

### Agregar M√°s Stacks a cleanup.sh

Si agregas nuevos stacks, actualiza el array `STACKS` en `cleanup.sh`:

```bash
STACKS=(
    "MiNuevoStack"      # Agregar aqu√≠
    "AIEmailStack"
    "AISummaryStack"
    # ...
)
```

**Importante:** Los stacks deben estar en orden inverso al despliegue (√∫ltimo desplegado primero).

### Cambiar Carpeta de Destino en S3

Para subir PDFs a una carpeta diferente, modifica `upload_sample_pdf.sh`:

```bash
# Cambiar esta l√≠nea:
aws s3 cp "$file" "s3://$bucket/external-reports/$filename"

# Por:
aws s3 cp "$file" "s3://$bucket/mi-carpeta/$filename"
```

---

## üìö Recursos Adicionales

- [AWS CLI Documentation](https://docs.aws.amazon.com/cli/)
- [CloudFormation Documentation](https://docs.aws.amazon.com/cloudformation/)
- [S3 Documentation](https://docs.aws.amazon.com/s3/)
- [Bash Scripting Guide](https://www.gnu.org/software/bash/manual/)

---

## ‚úÖ Checklist de Uso

### Antes del Workshop
- [ ] Verificar que AWS CLI est√° configurado
- [ ] Verificar permisos de la cuenta AWS
- [ ] Probar scripts en cuenta de prueba

### Durante el Workshop
- [ ] Usar `upload_sample_pdf.sh` para subir PDFs
- [ ] Verificar procesamiento en CloudWatch
- [ ] Ayudar a participantes con problemas

### Despu√©s del Workshop
- [ ] Ejecutar `cleanup.sh` para eliminar recursos
- [ ] Verificar que no quedan recursos
- [ ] Confirmar que no hay costos inesperados

---

¬øPreguntas? Consulta la [Gu√≠a del Instructor](../INSTRUCTOR_GUIDE.md) o la [Gu√≠a para Participantes](../PARTICIPANT_GUIDE.md).
