# üë®‚Äçüè´ Gu√≠a para Instructor - Medical Reports Automation Workshop

Esta gu√≠a proporciona todo lo necesario para impartir el workshop de **Automatizaci√≥n de Informes M√©dicos con AWS y Amazon Bedrock**.

## üìã Informaci√≥n General

**Duraci√≥n Total:** 3 horas 15 minutos (dividido en 2 d√≠as)
**Nivel:** Intermedio
**Audiencia:** Desarrolladores con conocimientos b√°sicos de AWS
**Tama√±o de grupo:** 10-30 participantes

## üéØ Objetivos de Aprendizaje

Al finalizar el workshop, los participantes podr√°n:

1. Desplegar infraestructura serverless con AWS CDK
2. Integrar Amazon Bedrock en aplicaciones reales
3. Implementar RAG con embeddings vectoriales
4. Aplicar t√©cnicas de prompt engineering
5. Usar Amazon Textract para OCR
6. Implementar clasificaci√≥n con few-shot learning
7. Generar contenido personalizado con LLMs
8. Experimentar con par√°metros de modelos
9. Iterar y mejorar prompts
10. Construir flujos de trabajo de IA end-to-end

## üìö Prerequisitos para Participantes

### Conocimientos T√©cnicos
- ‚úÖ Conocimientos b√°sicos de AWS (Lambda, S3, IAM)
- ‚úÖ Experiencia con l√≠nea de comandos
- ‚úÖ Familiaridad con Python (lectura de c√≥digo)
- ‚úÖ Conceptos b√°sicos de APIs REST

### Herramientas Requeridas
- ‚úÖ **Navegador web** (Chrome, Firefox, Edge, Safari)
- ‚úÖ **Acceso a AWS Console** (proporcionado por ti)

**¬°Eso es todo!** Los participantes usar√°n **AWS CloudShell**, que ya incluye:
- ‚úÖ AWS CLI pre-configurado
- ‚úÖ Node.js y npm
- ‚úÖ Python 3
- ‚úÖ Git
- ‚úÖ Solo necesitan instalar CDK (1 minuto)

**No se requieren instalaciones locales** - Todo funciona desde el navegador.

### Cuenta AWS
- ‚úÖ Cuenta AWS con permisos de administrador
- ‚úÖ Acceso a Amazon Bedrock habilitado
- ‚úÖ L√≠mites de servicio verificados

## üõ†Ô∏è Preparaci√≥n del Instructor

### 1 Semana Antes

- [ ] Verificar acceso a Amazon Bedrock en la regi√≥n del workshop
- [ ] Solicitar aumento de l√≠mites si es necesario (Bedrock, Lambda)
- [ ] Preparar cuenta AWS de demostraci√≥n
- [ ] Probar despliegue completo en cuenta de prueba
- [ ] Preparar slides de presentaci√≥n
- [ ] Enviar email a participantes con:
  - Link a AWS Console
  - Credenciales de acceso (usuario IAM o SSO)
  - Su PARTICIPANT_PREFIX asignado
  - **Nota:** Solo necesitan navegador web, usar√°n CloudShell

### 1 D√≠a Antes

- [ ] Desplegar sistema en cuenta de demostraci√≥n
- [ ] Preparar PDFs de ejemplo adicionales
- [ ] Revisar √∫ltimas actualizaciones de servicios AWS

### D√≠a del Workshop

- [ ] Conectarse 15 minutos antes
- [ ] Tener consola AWS, CloudWatch Logs y terminal listos para compartir
- [ ] Tener documentaci√≥n de Bedrock a mano

---

## üèóÔ∏è Preparaci√≥n de Infraestructura Antes del Workshop (NUEVO)

**‚ö†Ô∏è IMPORTANTE:** El workshop ahora usa una arquitectura optimizada que separa el despliegue en dos fases:

1. **Instructor (ANTES del workshop):** Despliega VPC compartida y LegacyStacks (~30 minutos total)
2. **Participantes (DURANTE el workshop):** Despliegan solo AI Stacks (~5-8 minutos)

Esta separaci√≥n reduce el tiempo de despliegue en vivo de ~25-35 minutos a solo ~5-8 minutos, permitiendo m√°s tiempo para los m√≥dulos pedag√≥gicos.

### Arquitectura Optimizada

```
ANTES DEL WORKSHOP (Instructor):
‚îú‚îÄ‚îÄ SharedNetworkStack (una vez)
‚îÇ   ‚îî‚îÄ‚îÄ VPC compartida para todos
‚îÇ       Tiempo: ~8 minutos
‚îÇ
‚îî‚îÄ‚îÄ LegacyStack √ó N participantes
    ‚îú‚îÄ‚îÄ Aurora Serverless v2
    ‚îú‚îÄ‚îÄ S3 Bucket
    ‚îú‚îÄ‚îÄ API Gateway
    ‚îî‚îÄ‚îÄ Lambdas Legacy
    Tiempo: ~15 min cada uno (en paralelo)

DURANTE EL WORKSHOP (Participantes):
‚îî‚îÄ‚îÄ AI Stacks (5 stacks)
    ‚îú‚îÄ‚îÄ AIExtractionStack
    ‚îú‚îÄ‚îÄ AIRAGStack
    ‚îú‚îÄ‚îÄ AIClassificationStack
    ‚îú‚îÄ‚îÄ AISummaryStack
    ‚îî‚îÄ‚îÄ AIEmailStack
    Tiempo: ~5-8 minutos total
```

### Paso 1: Configurar Lista de Participantes

Edita el archivo [`config/participants.json`](config/participants.json) con usuarios gen√©ricos:

```json
{
  "participants": [
    {
      "prefix": "participant-1",
      "email": "instructor@example.com",
      "iamUsername": "workshop-user-1"
    },
    {
      "prefix": "participant-2",
      "email": "instructor@example.com",
      "iamUsername": "workshop-user-2"
    },
    {
      "prefix": "participant-3",
      "email": "instructor@example.com",
      "iamUsername": "workshop-user-3"
    }
  ]
}
```

**Campos:**
- `prefix`: Identificador √∫nico gen√©rico (`participant-1`, `participant-2`, etc.)
- `email`: **Tu email como instructor** (el mismo para todos)
- `iamUsername`: Usuario IAM gen√©rico del workshop

**üí° Ventaja:** Usas usuarios gen√©ricos reutilizables, no necesitas emails individuales.

### Paso 2: Verificar TU Email en SES (Una Sola Vez)

Solo necesitas verificar **tu email como instructor** (no el de cada participante):

```powershell
# PowerShell - Solo una vez
aws ses verify-email-identity --email-address tu-email-instructor@example.com --profile <tu-perfil-aws> --region us-east-2

# Recibir√°s un email de verificaci√≥n. Haz clic en el enlace para confirmar.
```

**Nota:** Todos los participantes usar√°n el mismo email verificado (el tuyo) para las notificaciones de SES durante el workshop.

### Paso 3: Desplegar SharedNetworkStack (Una Sola Vez)

Despliega la VPC compartida que usar√°n todos los participantes:

```powershell
# PowerShell
.\scripts\instructor-deploy-network.ps1

# O con par√°metros personalizados:
.\scripts\instructor-deploy-network.ps1 -Profile <tu-perfil-aws> -Region us-east-2
```

Ver script: [`scripts/instructor-deploy-network.ps1`](scripts/instructor-deploy-network.ps1)

```bash
# Bash (Linux/Mac)
./scripts/instructor-deploy-network.sh

# O con par√°metros:
./scripts/instructor-deploy-network.sh <tu-perfil-aws> us-east-2
```

Ver script: [`scripts/instructor-deploy-network.sh`](scripts/instructor-deploy-network.sh)

**Tiempo estimado:** ~8 minutos

**Recursos creados:**
- VPC compartida (10.0.0.0/16)
- 2 Subnets p√∫blicas
- 2 Subnets privadas  
- 2 Subnets aisladas
- 1 NAT Gateway
- 1 Internet Gateway

### Paso 4: Desplegar LegacyStacks para Todos los Participantes

Despliega la infraestructura base (Aurora, S3, Lambdas) para cada participante:

```powershell
# PowerShell - Despliega para todos los participantes en config/participants.json
.\scripts\instructor-deploy-legacy.ps1

# Con par√°metros personalizados:
.\scripts\instructor-deploy-legacy.ps1 -ConfigFile config/participants.json -Profile <tu-perfil-aws> -Concurrency 3

# O para participantes espec√≠ficos:
.\scripts\instructor-deploy-legacy.ps1 -Participants "participant-juan","participant-maria"
```

Ver script: [`scripts/instructor-deploy-legacy.ps1`](scripts/instructor-deploy-legacy.ps1)

```bash
# Bash (Linux/Mac)
./scripts/instructor-deploy-legacy.sh

# Con par√°metros:
./scripts/instructor-deploy-legacy.sh config/participants.json <tu-perfil-aws> us-east-2 3
```

Ver script: [`scripts/instructor-deploy-legacy.sh`](scripts/instructor-deploy-legacy.sh)

**Tiempo estimado:** ~15 minutos por participante (se despliegan en paralelo)
- Con 3 participantes y concurrencia 3: ~15 minutos total
- Con 10 participantes y concurrencia 5: ~30 minutos total

**Recursos creados por participante:**
- Aurora Serverless v2 (PostgreSQL con pgvector)
- S3 Bucket individual
- API Gateway
- 3 Lambdas Legacy (register-exam, generate-pdf, generate-test-data)
- Security Groups individuales

**Outputs:**
El script genera un reporte JSON con los outputs de cada stack:
- `deployment-report-legacy-YYYYMMDD-HHMMSS.json`

### Paso 5: Compartir Informaci√≥n con Participantes

Env√≠a a cada participante un email con:

1. **Acceso a AWS Console:**
   - Link: https://console.aws.amazon.com/
   - Usuario gen√©rico: `workshop-user-1` (o el n√∫mero asignado)
   - Contrase√±a: [proporcionada por separado]

2. **Su PARTICIPANT_PREFIX:** `participant-1` (o el n√∫mero asignado)

3. **Email verificado:** `tu-email-instructor@example.com` (el mismo para todos)

4. **Link al repositorio** del workshop

5. **Instrucciones simples:**
   ```
   1. Inicia sesi√≥n en AWS Console con tu usuario
   2. Abre CloudShell (√≠cono >_ en la esquina superior derecha)
   3. Clona el repositorio: git clone <url>
   4. cd medical-reports-automation
   5. Ejecuta: ./scripts/participant-deploy-ai.sh participant-1 instructor@example.com
      (Reemplaza participant-1 con tu n√∫mero asignado)
   6. Espera 5-8 minutos
   ```

**Ventajas de usuarios gen√©ricos:**
- ‚úÖ No necesitas emails individuales de participantes
- ‚úÖ Usuarios reutilizables para futuros workshops
- ‚úÖ Todos usan el mismo email verificado (el tuyo)
- ‚úÖ M√°s f√°cil de gestionar

**Nota para participantes:** No necesitan instalar nada localmente, todo funciona desde CloudShell en el navegador.

### Verificaci√≥n Pre-Workshop

Antes del workshop, verifica que todo est√° listo:

```powershell
# Verificar que SharedNetworkStack existe
aws cloudformation describe-stacks --stack-name SharedNetworkStack --profile <tu-perfil-aws>

# Verificar LegacyStack de un participante
aws cloudformation describe-stacks --stack-name participant-juan-MedicalReportsLegacyStack --profile <tu-perfil-aws>

# Listar todos los stacks
aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE --profile <tu-perfil-aws>
```

### Tiempos Estimados

| Fase | Qui√©n | Cu√°ndo | Tiempo |
|------|-------|--------|--------|
| SharedNetworkStack | Instructor | Antes del workshop | ~8 min |
| LegacyStacks (10 participantes) | Instructor | Antes del workshop | ~20 min |
| AI Stacks | Participantes | Durante D√≠a 1 | ~5-8 min |
| **Total para instructor** | | | **~30 min** |
| **Total para participantes** | | | **~5-8 min** |

### Troubleshooting

**Error: "SharedNetworkStack no encontrado"**
- Aseg√∫rate de haber ejecutado `instructor-deploy-network.ps1` primero

**Error: "Export not found"**
- Verifica que SharedNetworkStack est√° en estado CREATE_COMPLETE
- Ejecuta: `aws cloudformation describe-stacks --stack-name SharedNetworkStack`

**Error: "Token expirado"**
- Los scripts renuevan autom√°ticamente la sesi√≥n SSO
- Si falla, ejecuta manualmente: `aws sso login --profile <tu-perfil-aws>`

**Despliegue lento**
- Aumenta la concurrencia: `-Concurrency 5` (PowerShell)
- Verifica l√≠mites de servicio en tu cuenta AWS

---

## üöÄ Despliegue Completo del Sistema (M√©todo Tradicional)

Esta secci√≥n explica c√≥mo desplegar todo el sistema en tu cuenta de demostraci√≥n **antes del workshop**. Durante el workshop, los participantes desplegar√°n los stacks uno por uno siguiendo los m√≥dulos pedag√≥gicos.

### Paso 1: Configurar Credenciales AWS

**IMPORTANTE:** Debes configurar tus credenciales de AWS antes de continuar.

Tienes dos opciones para configurar el acceso a AWS:

#### Opci√≥n A: Usuario IAM con Credenciales

Si usas un usuario IAM con access keys:

```bash
# Configurar credenciales
aws configure

# Ingresar:
# - AWS Access Key ID
# - AWS Secret Access Key
# - Default region: us-east-2
# - Default output format: json

# Verificar configuraci√≥n
aws sts get-caller-identity
```

Si el comando anterior funciona correctamente, tus credenciales est√°n configuradas.

#### Opci√≥n B: AWS SSO (Identity Center)

Si tu organizaci√≥n usa AWS SSO (recomendado para cuentas empresariales):

```bash
# Configurar perfil SSO
aws configure sso

# Ingresar:
# - SSO start URL: https://tu-organizacion.awsapps.com/start
# - SSO Region: us-east-2 (o tu regi√≥n)
# - Seleccionar cuenta y rol
# - CLI default region: us-east-2
# - CLI output format: json
# - Profile name: workshop-demo (o el nombre que prefieras)

# Iniciar sesi√≥n
aws sso login --profile workshop-demo

# Verificar configuraci√≥n
aws sts get-caller-identity --profile workshop-demo
```

**Nota:** Si usas SSO, deber√°s configurar la variable de entorno antes de cada comando:

```bash
# Linux/Mac
export AWS_PROFILE=workshop-demo

# Windows PowerShell
$env:AWS_PROFILE = "workshop-demo"

# Windows CMD
set AWS_PROFILE=workshop-demo
```

**Troubleshooting:**
- Si recibes "Unable to locate credentials", ejecuta `aws configure` o `aws sso login`
- Si usas SSO y el token expira, ejecuta `aws sso login --profile <tu-perfil>` nuevamente

### Paso 2: Verificar Email en Amazon SES

**Nota:** Aseg√∫rate de haber completado el Paso 1 antes de continuar.

El sistema env√≠a emails personalizados, por lo que necesitas verificar tu direcci√≥n de email:

```bash
# Verificar tu email (reemplaza con tu email real)
aws ses verify-email-identity --email-address tu-email@ejemplo.com --region us-east-2

# Si usas perfil SSO, agrega --profile:
aws ses verify-email-identity --email-address tu-email@ejemplo.com --region us-east-2 --profile workshop-demo

# Recibir√°s un email de verificaci√≥n. Haz clic en el enlace para confirmar.

# Verificar estado de verificaci√≥n
aws ses get-identity-verification-attributes \
  --identities tu-email@ejemplo.com \
  --region us-east-2

# Con perfil espec√≠fico:
aws ses get-identity-verification-attributes \
  --identities tu-email@ejemplo.com \
  --region us-east-2 \
  --profile workshop-demo
```

**Importante:** Si tu cuenta de AWS est√° en el **SES Sandbox** (cuentas nuevas), solo podr√°s enviar emails a direcciones verificadas. Para enviar a cualquier direcci√≥n, solicita salir del sandbox:

1. Consola AWS ‚Üí Amazon SES ‚Üí Account dashboard
2. Haz clic en **Request production access**
3. Completa el formulario (toma ~24 horas)

Para el workshop, puedes quedarte en sandbox y usar solo emails verificados.

### Paso 3: Instalar Dependencias

```bash
# Navegar al directorio CDK
cd cdk

# Instalar dependencias de Node.js
npm install

# Verificar instalaci√≥n de CDK
cdk --version
# Esperado: 2.x.x o superior
```

### Paso 4: Bootstrap CDK (Solo Primera Vez)

Si es la primera vez que usas CDK en esta cuenta/regi√≥n:

```bash
# Bootstrap CDK
cdk bootstrap

# Si usas perfil espec√≠fico:
cdk bootstrap --profile workshop-demo

# Esto crea recursos necesarios para CDK (bucket S3, roles IAM, etc.)
```

### Paso 5: Desplegar Todos los Stacks

Tienes tres opciones para desplegar:

#### Opci√≥n A: Usar el Script de Despliegue (Recomendado para Windows)

```powershell
# Windows PowerShell
cd cdk
.\deploy.ps1
```

**Nota:** El script [`deploy.ps1`](cdk/deploy.ps1) est√° configurado con un perfil espec√≠fico. Ed√≠talo si usas un perfil diferente:

```powershell
# Editar deploy.ps1 y cambiar esta l√≠nea:
$env:AWS_PROFILE = "tu-perfil-aqui"
```

#### Opci√≥n B: Comando CDK Directo

```bash
# Linux/Mac
cd cdk
export AWS_PROFILE=workshop-demo  # Si usas perfil espec√≠fico
cdk deploy --all --require-approval never

# Windows PowerShell
cd cdk
$env:AWS_PROFILE = "workshop-demo"  # Si usas perfil espec√≠fico
cdk deploy --all --require-approval never

# Windows CMD
cd cdk
set AWS_PROFILE=workshop-demo
cdk deploy --all --require-approval never
```

#### Opci√≥n C: Desplegar con Prefijo Personalizado

Si quieres usar un prefijo diferente a 'demo':

```bash
# Con contexto CDK
cdk deploy --all --require-approval never -c participantPrefix=instructor

# O configurar variable de entorno
export PARTICIPANT_PREFIX=instructor
cdk deploy --all --require-approval never
```

### Paso 6: Verificar Despliegue

El despliegue completo toma aproximadamente **25-35 minutos** (el LegacyStack con Aurora puede tomar 15-20 minutos solo). Verifica que todos los stacks se desplegaron correctamente:

```bash
# Listar todos los stacks
aws cloudformation list-stacks \
  --stack-status-filter CREATE_COMPLETE \
  --query 'StackSummaries[?contains(StackName, `Stack`)].StackName'

# Deber√≠as ver 6 stacks:
# - demo-MedicalReportsLegacyStack (o tu-prefijo-MedicalReportsLegacyStack)
# - demo-AIExtractionStack
# - demo-AIRAGStack
# - demo-AIClassificationStack
# - demo-AISummaryStack
# - demo-AIEmailStack
```

### Paso 7: Obtener Informaci√≥n de Despliegue

Guarda esta informaci√≥n para usarla durante el workshop:

```bash
# Obtener URL del API Gateway
aws cloudformation describe-stacks \
  --stack-name demo-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`ApiUrl`].OutputValue' \
  --output text

# Obtener nombre del bucket S3
aws cloudformation describe-stacks \
  --stack-name demo-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`BucketName`].OutputValue' \
  --output text

# Obtener endpoint de Aurora
aws cloudformation describe-stacks \
  --stack-name demo-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`DatabaseEndpoint`].OutputValue' \
  --output text
```

### Paso 8: Inicializar Base de Datos (Opcional)

Si quieres tener datos de ejemplo pre-cargados:

```bash
# Obtener endpoint de Aurora
DB_ENDPOINT=$(aws cloudformation describe-stacks \
  --stack-name demo-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`DatabaseEndpoint`].OutputValue' \
  --output text)

# Conectar a la base de datos
psql -h $DB_ENDPOINT -U postgres -d medical_reports

# Ejecutar scripts SQL
\i ../database/schema.sql
\i ../database/seed_data.sql
```

### Paso 9: Probar el Sistema

Verifica que todo funciona correctamente:

```bash
# 1. Subir un PDF de prueba
aws s3 cp sample_data/informe_alto_riesgo.pdf \
  s3://demo-medical-reports-<account-id>/external-reports/

# 2. Verificar logs de extracci√≥n
aws logs tail /aws/lambda/demo-extract-pdf --follow

# 3. Verificar que se guard√≥ en la base de datos
psql -h $DB_ENDPOINT -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM informes_medicos WHERE origen='EXTERNO';"
```

### Troubleshooting del Despliegue

#### Error: "ExpiredToken" o "InvalidClientTokenId"

**Causa:** Credenciales expiradas (com√∫n con SSO).

**Soluci√≥n:**
```bash
# Renovar sesi√≥n SSO
aws sso login --profile workshop-demo

# Reintentar despliegue
cdk deploy --all --require-approval never
```

#### Error: "Model access denied"

**Causa:** Permisos insuficientes para Bedrock.

**Soluci√≥n:** Verifica que tu usuario/rol tenga permisos `bedrock:InvokeModel`. Los modelos se habilitan autom√°ticamente en la primera invocaci√≥n.

#### Error: "Bucket already exists"

**Causa:** El prefijo 'demo' ya est√° en uso en tu cuenta.

**Soluci√≥n:** Usa un prefijo diferente:
```bash
cdk deploy --all -c participantPrefix=instructor
```

#### Error: "Insufficient permissions"

**Causa:** Tu usuario/rol no tiene permisos suficientes.

**Soluci√≥n:** Necesitas permisos de administrador o al menos:
- CloudFormation: Full access
- Lambda: Full access
- S3: Full access
- RDS: Full access
- IAM: Create roles and policies
- Bedrock: Full access
- SES: Full access

### Resumen del Despliegue

Una vez completados todos los pasos:

- ‚úÖ 6 stacks desplegados en CloudFormation
- ‚úÖ Modelos de Bedrock habilitados
- ‚úÖ Email verificado en SES
- ‚úÖ Base de datos Aurora con schema creado
- ‚úÖ Sistema probado con un PDF de ejemplo

**Tiempo total estimado:** 40-50 minutos (incluyendo esperas de despliegue - Aurora toma 15-20 min)

**Pr√≥ximos pasos:**
1. Preparar slides de presentaci√≥n
2. Preparar PDFs de ejemplo adicionales
3. Tener consola AWS abierta con CloudWatch Logs
4. Revisar el plan detallado del workshop (siguiente secci√≥n)

---

## üìÖ Plan Detallado del Workshop

### D√≠a 1: Fundamentos y Extracci√≥n (1h 15min)

#### M√≥dulo 0: Introducci√≥n y Setup (5 min)

**Objetivos:**
- Dar bienvenida y contexto
- Verificar que todos tienen prerequisitos
- Explicar estructura del workshop

**Script:**

```
¬°Bienvenidos! En este workshop vamos a construir un sistema real de automatizaci√≥n
de informes m√©dicos usando servicios de AWS y Amazon Bedrock.

El caso de uso: Una empresa de salud ocupacional recibe informes m√©dicos en PDF
de diferentes cl√≠nicas. Necesitan:
1. Extraer datos autom√°ticamente
2. Clasificar el nivel de riesgo
3. Generar res√∫menes ejecutivos
4. Enviar notificaciones personalizadas

Vamos a resolver esto usando IA Generativa.

Antes de empezar, verifiquemos que todos tienen:
- AWS CLI configurado ‚úì
- CDK instalado ‚úì
- Acceso a Bedrock habilitado ‚úì
```

**Demostraci√≥n en vivo:**
1. Mostrar arquitectura completa en diagrama
2. Explicar flujo de datos
3. Mostrar resultado final (email recibido)

**Tiempo:** 5 minutos

---

#### M√≥dulo 1: Extracci√≥n con Textract y Bedrock (30 min)

**Objetivos:**
- Entender diferencia entre OCR y estructuraci√≥n
- Aprender a usar Amazon Textract
- Integrar Amazon Bedrock para estructurar datos
- Ver el flujo completo de extracci√≥n

**Conceptos Clave a Explicar:**

1. **Amazon Textract**
   - Servicio de OCR (Optical Character Recognition)
   - Extrae texto, tablas y formularios
   - No entiende el contexto, solo extrae

2. **Amazon Bedrock**
   - Servicio de LLMs (Large Language Models)
   - Entiende contexto y estructura
   - Transforma texto no estructurado en JSON

3. **Por qu√© necesitamos ambos:**
   - Textract: Extrae el texto del PDF
   - Bedrock: Entiende qu√© significa cada dato

**Script:**

```
Imaginen que tienen un PDF m√©dico. Textract es como un esc√°ner inteligente
que lee todo el texto, pero no sabe qu√© es "presi√≥n arterial" vs "peso".

Bedrock es como un m√©dico que lee ese texto y dice: "Ah, esto es presi√≥n
arterial, esto es peso, esto es una observaci√≥n m√©dica".

Juntos, convierten un PDF en datos estructurados que podemos guardar en
una base de datos.
```

**Demostraci√≥n en vivo:**

1. **Desplegar Stack de Extracci√≥n** (5 min)
   ```bash
   cd cdk
   cdk deploy AIExtractionStack
   ```
   
   Mientras despliega, explicar:
   - Lambda con trigger S3
   - Permisos IAM para Textract y Bedrock
   - Variables de entorno

2. **Revisar C√≥digo** (10 min)
   
   Abrir [`lambda/ai/extract_pdf/index.py`](lambda/ai/extract_pdf/index.py):
   
   ```python
   # Paso 1: Textract extrae texto
   response = textract_client.analyze_document(...)
   
   # Paso 2: Construir prompt para Bedrock
   prompt = f"""
   Extrae datos del siguiente texto m√©dico:
   {texto_extraido}
   """
   
   # Paso 3: Bedrock estructura en JSON
   bedrock_response = bedrock_runtime.invoke_model(...)
   ```
   
   **Puntos a destacar:**
   - `analyze_document` vs `detect_document_text`
   - Construcci√≥n del prompt
   - Par√°metros: temperature, maxTokens

3. **Subir PDF y Ver Logs** (10 min)
   ```bash
   aws s3 cp sample_data/informe_alto_riesgo.pdf \
     s3://bucket/external-reports/
   ```
   
   Abrir CloudWatch Logs en vivo:
   - Mostrar log de Textract
   - Mostrar prompt enviado a Bedrock
   - Mostrar JSON estructurado
   - Mostrar inserci√≥n en Aurora

4. **Verificar en Base de Datos** (5 min)
   ```sql
   SELECT * FROM informes_medicos WHERE origen='EXTERNO';
   ```

**Ejercicio para Participantes:**
- Subir su propio PDF
- Verificar en CloudWatch
- Consultar en base de datos

**Tiempo:** 30 minutos

---


#### M√≥dulo 2: Prompt Engineering (30 min)

**Objetivos:**
- Entender qu√© es prompt engineering
- Ver evoluci√≥n de prompts (v1 ‚Üí v2 ‚Üí v3)
- Experimentar con par√°metros
- Aprender mejores pr√°cticas

**Conceptos Clave a Explicar:**

1. **¬øQu√© es un Prompt?**
   - Instrucciones que le das al modelo
   - Como hablarle a un asistente muy inteligente
   - La calidad del prompt determina la calidad de la respuesta

2. **Componentes de un Buen Prompt:**
   - Rol/Contexto: "Eres un experto en..."
   - Tarea: "Extrae los siguientes datos..."
   - Formato: "Devuelve en JSON..."
   - Restricciones: "Si no encuentras un dato, usa null"
   - Ejemplos: "Por ejemplo: {...}"

3. **Par√°metros Importantes:**
   - **temperature**: Control de aleatoriedad (0.0 = determin√≠stico, 1.0 = creativo)
   - **maxTokens**: Longitud m√°xima de respuesta
   - **topP**: Control de diversidad

**Script:**

```
Prompt engineering es el arte de comunicarte efectivamente con un LLM.
Es como aprender a dar instrucciones claras a un asistente muy capaz
pero que necesita contexto espec√≠fico.

Un mal prompt: "Dame los datos"
Un buen prompt: "Eres un experto en informes m√©dicos. Extrae estos campos
espec√≠ficos en formato JSON. Si un campo no existe, usa null."

La diferencia es enorme en la calidad de resultados.
```

**Demostraci√≥n en vivo:**

1. **Comparar Versiones de Prompts** (15 min)
   
   Mostrar lado a lado:
   
   **Versi√≥n 1** ([`prompts/extraction_v1.txt`](prompts/extraction_v1.txt)):
   ```
   Extrae datos del siguiente informe m√©dico.
   ```
   
   Resultado: ‚ùå Inconsistente, formato variable
   
   **Versi√≥n 2** ([`prompts/extraction_v2.txt`](prompts/extraction_v2.txt)):
   ```
   Extrae los siguientes campos:
   - Nombre del trabajador
   - Presi√≥n arterial
   ...
   Devuelve en formato JSON.
   ```
   
   Resultado: ‚ö†Ô∏è Mejor, pero a√∫n inconsistente
   
   **Versi√≥n 3** ([`prompts/extraction.txt`](prompts/extraction.txt)):
   ```
   Eres un asistente especializado en extraer datos de informes m√©dicos.
   
   Extrae la siguiente informaci√≥n y devu√©lvela en formato JSON:
   {
     "trabajador_nombre": "string",
     "presion_arterial": "string",
     ...
   }
   
   IMPORTANTE:
   - Si un campo no est√° presente, usa null
   - Mant√©n el formato exacto del JSON
   - No inventes datos
   ```
   
   Resultado: ‚úÖ Consistente, preciso, confiable

2. **Experimentar con Temperature** (10 min)
   
   Modificar en vivo:
   ```python
   # Temperature baja (0.1) - Determin√≠stico
   "inferenceConfig": {"temperature": 0.1}
   
   # Temperature alta (0.8) - Creativo
   "inferenceConfig": {"temperature": 0.8}
   ```
   
   Desplegar y comparar resultados:
   ```bash
   cdk deploy AIExtractionStack
   aws s3 cp sample_data/informe_medio_riesgo.pdf s3://bucket/external-reports/
   ```
   
   **Mostrar diferencias:**
   - Temperature 0.1: Siempre extrae igual
   - Temperature 0.8: Puede variar en formato

3. **Cu√°ndo Usar Cada Temperature** (5 min)
   
   Mostrar tabla en pantalla compartida:
   ```
   Temperature | Uso Ideal           | Ejemplo
   ------------|---------------------|------------------
   0.0 - 0.2   | Extracci√≥n, datos   | PDFs, formularios
   0.3 - 0.5   | An√°lisis, res√∫menes | Informes ejecutivos
   0.6 - 0.8   | Contenido, emails   | Comunicaciones
   0.9 - 1.0   | Creativo, ideas     | Brainstorming
   ```

**Ejercicio para Participantes:**
1. Modificar temperature en su c√≥digo
2. Re-desplegar
3. Comparar resultados
4. Discutir diferencias

**Tiempo:** 30 minutos

---

#### Checkpoint D√≠a 1 (10 min)

**Objetivos:**
- Verificar que todos completaron los m√≥dulos
- Responder preguntas
- Preparar para D√≠a 2

**Checklist:**
```bash
# 1. Sistema legacy desplegado
aws cloudformation describe-stacks --stack-name LegacyStack

# 2. Sistema de extracci√≥n desplegado
aws cloudformation describe-stacks --stack-name AIExtractionStack

# 3. Al menos 1 PDF procesado
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM informes_medicos WHERE origen='EXTERNO';"
```

**Preguntas para Reflexi√≥n:**
1. ¬øQu√© hace Textract que Bedrock no puede hacer?
2. ¬øPor qu√© usamos temperature baja para extracci√≥n?
3. ¬øQu√© componentes hacen que un prompt sea efectivo?

**Tarea para D√≠a 2:**
- Revisar documentaci√≥n de pgvector
- Leer sobre RAG (Retrieval-Augmented Generation)

**Tiempo:** 10 minutos

---


### D√≠a 2: RAG, Clasificaci√≥n y Personalizaci√≥n (2h)

#### M√≥dulo 3: RAG con Embeddings Vectoriales (30 min)

**Objetivos:**
- Entender qu√© es RAG y por qu√© es importante
- Aprender sobre embeddings vectoriales
- Implementar b√∫squeda por similitud con pgvector
- Ver c√≥mo RAG mejora las respuestas

**Conceptos Clave a Explicar:**

1. **¬øQu√© es RAG?**
   - RAG = Retrieval-Augmented Generation
   - Retrieval: Buscar informaci√≥n relevante
   - Augmented: Agregar esa informaci√≥n al prompt
   - Generation: Generar respuesta con contexto
   
2. **Problema que Resuelve:**
   - LLMs tienen conocimiento limitado (fecha de corte)
   - LLMs pueden "alucinar" (inventar informaci√≥n)
   - RAG proporciona contexto espec√≠fico y verificable

3. **Embeddings Vectoriales:**
   - Representaci√≥n num√©rica de texto
   - Textos similares ‚Üí vectores similares
   - Permite b√∫squeda sem√°ntica (por significado, no por palabras)

**Script:**

```
Imaginen que le preguntan a un m√©dico sobre un paciente sin darle
el historial m√©dico. Puede dar una opini√≥n general, pero no espec√≠fica.

RAG es como darle al m√©dico el historial completo antes de que opine.
El m√©dico (LLM) ahora tiene contexto real y puede dar una respuesta
mucho m√°s precisa y personalizada.

Los embeddings son la forma de buscar ese historial de manera inteligente.
No buscamos por palabras exactas, sino por significado.
```

**Demostraci√≥n en vivo:**

1. **Explicar Embeddings con Ejemplo** (10 min)
   
   Mostrar en pantalla compartida:
   ```
   Texto 1: "Presi√≥n arterial: 140/90 mmHg"
   Embedding 1: [0.123, -0.456, 0.789, ..., 0.234]
   
   Texto 2: "PA: 142/88 mmHg"
   Embedding 2: [0.125, -0.450, 0.792, ..., 0.230]
   
   Similitud: 0.98 (muy similar)
   
   Texto 3: "Peso: 75 kg"
   Embedding 3: [-0.234, 0.567, -0.123, ..., 0.890]
   
   Similitud con Texto 1: 0.12 (muy diferente)
   ```
   
   **Punto clave:** Embeddings capturan el significado, no las palabras exactas.

2. **Desplegar Stack RAG** (5 min)
   ```bash
   cd cdk
   cdk deploy AIRAGStack
   ```
   
   Explicar mientras despliega:
   - Lambda para generar embeddings
   - Uso de Amazon Titan Embeddings v2
   - Tabla informes_embeddings con pgvector

3. **Generar Embeddings** (5 min)
   ```bash
   # Generar embeddings para informes existentes
   aws lambda invoke \
     --function-name generate-embeddings \
     --payload '{"informe_id": 1}' \
     response.json
   ```
   
   Mostrar en CloudWatch:
   - Llamada a Titan Embeddings
   - Vector de 1024 dimensiones
   - Inserci√≥n en pgvector

4. **Demostrar B√∫squeda por Similitud** (10 min)
   
   Abrir [`lambda/shared/similarity_search.py`](lambda/shared/similarity_search.py):
   ```python
   sql = """
       SELECT 
           ie.informe_id,
           ie.contenido,
           1 - (ie.embedding <=> %s::vector) as similarity
       FROM informes_embeddings ie
       WHERE ie.trabajador_id = %s
       ORDER BY ie.embedding <=> %s::vector
       LIMIT 3
   """
   ```
   
   **Explicar:**
   - `<=>` es el operador de distancia coseno
   - Menor distancia = mayor similitud
   - Filtramos por trabajador_id para contexto relevante
   
   Ejecutar b√∫squeda en vivo:
   ```sql
   SELECT 
     informe_id,
     contenido,
     1 - (embedding <=> '[0.123, -0.456, ...]'::vector) as similarity
   FROM informes_embeddings
   WHERE trabajador_id = 1
   ORDER BY embedding <=> '[0.123, -0.456, ...]'::vector
   LIMIT 3;
   ```

**Ejercicio para Participantes:**
1. Generar embeddings para sus informes
2. Ejecutar b√∫squeda por similitud
3. Observar qu√© informes son similares

**Tiempo:** 30 minutos

---


#### M√≥dulo 4: Clasificaci√≥n con Few-Shot Learning (30 min)

**Objetivos:**
- Entender few-shot learning
- Ver c√≥mo RAG mejora la clasificaci√≥n
- Implementar clasificador de riesgo
- Comparar resultados con y sin RAG

**Conceptos Clave a Explicar:**

1. **Few-Shot Learning:**
   - Ense√±ar al modelo con pocos ejemplos
   - Ejemplos en el prompt, no en entrenamiento
   - Muy efectivo para tareas de clasificaci√≥n

2. **Tipos de Learning:**
   - **Zero-shot**: Sin ejemplos (solo instrucciones)
   - **One-shot**: Un ejemplo
   - **Few-shot**: Varios ejemplos (2-5 t√≠picamente)
   - **Fine-tuning**: Entrenar el modelo (no cubierto aqu√≠)

3. **Por qu√© Funciona:**
   - LLMs aprenden patrones de los ejemplos
   - Generalizan a nuevos casos
   - M√°s ejemplos = mejor precisi√≥n (hasta cierto punto)

**Script:**

```
Few-shot learning es como mostrarle a alguien ejemplos antes de pedirle
que haga algo.

Sin ejemplos: "Clasifica este informe" ‚Üí Resultados inconsistentes
Con ejemplos: "Aqu√≠ hay 3 ejemplos de BAJO, MEDIO y ALTO riesgo.
               Ahora clasifica este" ‚Üí Resultados consistentes

Es la diferencia entre decir "dibuja un perro" vs mostrar 3 fotos
de perros y luego decir "dibuja uno similar".
```

**Demostraci√≥n en vivo:**

1. **Desplegar Stack de Clasificaci√≥n** (5 min)
   ```bash
   cd cdk
   cdk deploy AIClassificationStack
   ```

2. **Revisar Prompt de Clasificaci√≥n** (10 min)
   
   Abrir [`prompts/classification.txt`](prompts/classification.txt):
   
   ```
   Eres un m√©dico ocupacional experto en evaluar riesgos laborales.
   
   Clasifica el siguiente informe en uno de estos niveles:
   - BAJO: Par√°metros normales, apto sin restricciones
   - MEDIO: Par√°metros lim√≠trofes, requiere seguimiento
   - ALTO: Par√°metros alterados, requiere atenci√≥n inmediata
   
   EJEMPLOS:
   
   [Ejemplo BAJO]
   Trabajador: Juan P√©rez
   Presi√≥n: 118/75 mmHg
   IMC: 23.5
   Colesterol: 180 mg/dL
   Clasificaci√≥n: BAJO
   Justificaci√≥n: Todos los par√°metros dentro de rangos normales...
   
   [Ejemplo MEDIO]
   Trabajador: Mar√≠a Garc√≠a
   Presi√≥n: 135/85 mmHg
   IMC: 27.2
   Colesterol: 215 mg/dL
   Clasificaci√≥n: MEDIO
   Justificaci√≥n: Presi√≥n en rango de pre-hipertensi√≥n...
   
   [Ejemplo ALTO]
   Trabajador: Carlos L√≥pez
   Presi√≥n: 155/95 mmHg
   IMC: 32.1
   Glucosa: 145 mg/dL
   Clasificaci√≥n: ALTO
   Justificaci√≥n: Hipertensi√≥n grado 1, obesidad...
   
   CONTEXTO HIST√ìRICO:
   [Informes anteriores del trabajador - proporcionado por RAG]
   
   INFORME ACTUAL:
   [Datos del informe]
   
   Responde en formato JSON:
   {
     "nivel_riesgo": "BAJO|MEDIO|ALTO",
     "justificacion": "explicaci√≥n detallada"
   }
   ```
   
   **Puntos a destacar:**
   - Definiciones claras de cada nivel
   - Ejemplos espec√≠ficos con datos reales
   - Contexto hist√≥rico de RAG
   - Formato de salida estructurado

3. **Clasificar Informe** (10 min)
   ```bash
   # Clasificar informe
   aws lambda invoke \
     --function-name classify-risk \
     --payload '{"informe_id": 1}' \
     response.json
   
   # Ver resultado
   cat response.json
   ```
   
   Mostrar en CloudWatch:
   - B√∫squeda RAG de informes anteriores
   - Prompt completo con contexto
   - Respuesta de Bedrock
   - Actualizaci√≥n en Aurora

4. **Comparar Con y Sin RAG** (5 min)
   
   Modificar c√≥digo temporalmente para omitir RAG:
   ```python
   # Sin RAG
   prompt = f"""
   Clasifica este informe:
   {informe_actual}
   """
   
   # Con RAG
   prompt = f"""
   Contexto hist√≥rico:
   {informes_anteriores}
   
   Clasifica este informe:
   {informe_actual}
   ```
   
   **Mostrar diferencia:**
   - Sin RAG: Clasificaci√≥n basada solo en valores actuales
   - Con RAG: Clasificaci√≥n considerando tendencias

**Ejercicio para Participantes:**
1. Clasificar varios informes
2. Observar justificaciones
3. Verificar en base de datos

**Tiempo:** 30 minutos

---


#### M√≥dulo 5: Res√∫menes y Emails Personalizados (30 min)

**Objetivos:**
- Generar res√∫menes ejecutivos concisos
- Personalizar emails seg√∫n nivel de riesgo
- Entender control de tono con prompts
- Ver flujo completo end-to-end

**Conceptos Clave a Explicar:**

1. **Generaci√≥n de Res√∫menes:**
   - Condensar informaci√≥n compleja
   - Lenguaje claro y no t√©cnico
   - Enfoque en lo accionable
   - Incluir tendencias hist√≥ricas

2. **Personalizaci√≥n de Contenido:**
   - Mismo dato, diferentes tonos
   - Adaptaci√≥n a la audiencia
   - Control de urgencia y emoci√≥n
   - Mantener profesionalismo

3. **Temperature para Creatividad:**
   - Res√∫menes: 0.5 (balanceado)
   - Emails: 0.7 (m√°s creativo)
   - Permite variaci√≥n natural

**Script:**

```
Ahora vamos a cerrar el c√≠rculo. Tenemos datos extra√≠dos, clasificados,
y ahora necesitamos comunicarlos efectivamente.

Un resumen ejecutivo es para el gerente que tiene 2 minutos.
Un email es para el contratista que necesita actuar.

La clave es adaptar el mensaje a la audiencia y al nivel de urgencia.
Un informe de ALTO riesgo necesita un tono urgente.
Un informe de BAJO riesgo puede ser tranquilizador.
```

**Demostraci√≥n en vivo:**

1. **Desplegar Stacks** (5 min)
   ```bash
   cd cdk
   cdk deploy AISummaryStack
   cdk deploy AIEmailStack
   ```

2. **Generar Resumen Ejecutivo** (10 min)
   
   ```bash
   aws lambda invoke \
     --function-name generate-summary \
     --payload '{"informe_id": 1}' \
     response.json
   ```
   
   Revisar prompt ([`prompts/summary.txt`](prompts/summary.txt)):
   ```
   Genera un resumen ejecutivo del informe m√©dico.
   
   REQUISITOS:
   - M√°ximo 150 palabras
   - Lenguaje claro, no t√©cnico
   - Enf√≥cate en hallazgos principales
   - Incluye tendencias si hay informes anteriores
   
   CONTEXTO HIST√ìRICO:
   [Informes anteriores - RAG]
   
   INFORME ACTUAL:
   [Datos]
   
   FORMATO:
   P√°rrafo √∫nico, directo y accionable.
   ```
   
   **Mostrar resultado:**
   - Resumen conciso
   - Sin jerga m√©dica
   - Incluye tendencias
   - Accionable

3. **Enviar Emails Personalizados** (15 min)
   
   Mostrar los 3 prompts diferentes:
   
   **ALTO Riesgo** ([`prompts/email_high.txt`](prompts/email_high.txt)):
   ```
   Genera un email URGENTE para el contratista.
   
   TONO: Urgente pero profesional
   OBJETIVO: Acci√≥n inmediata
   
   Incluye:
   - Hallazgos cr√≠ticos destacados
   - Acciones requeridas INMEDIATAMENTE
   - Consecuencias de no actuar
   - Contacto para seguimiento
   
   ESTRUCTURA:
   - Asunto: [URGENTE] ...
   - Saludo formal
   - P√°rrafo de urgencia
   - Lista de acciones
   - Cierre con contacto
   ```
   
   **MEDIO Riesgo** ([`prompts/email_medium.txt`](prompts/email_medium.txt)):
   ```
   Genera un email PROFESIONAL para el contratista.
   
   TONO: Profesional y constructivo
   OBJETIVO: Seguimiento programado
   
   Incluye:
   - Hallazgos que requieren atenci√≥n
   - Recomendaciones de seguimiento
   - Plazo sugerido (30-60 d√≠as)
   - Disponibilidad para consultas
   ```
   
   **BAJO Riesgo** ([`prompts/email_low.txt`](prompts/email_low.txt)):
   ```
   Genera un email TRANQUILIZADOR para el contratista.
   
   TONO: Positivo y alentador
   OBJETIVO: Confirmar estado saludable
   
   Incluye:
   - Confirmaci√≥n de par√°metros normales
   - Felicitaci√≥n por mantener salud
   - Recordatorio de controles peri√≥dicos
   - Mensaje motivacional
   ```
   
   Enviar email:
   ```bash
   aws lambda invoke \
     --function-name send-email \
     --payload '{"informe_id": 1}' \
     response.json
   ```
   
   **Mostrar email recibido (compartir pantalla):**
   - Abrir bandeja de entrada en pantalla compartida
   - Mostrar personalizaci√≥n
   - Destacar tono apropiado
   - Se√±alar elementos clave

**Ejercicio para Participantes:**
1. Generar res√∫menes de sus informes
2. Enviar emails
3. Comparar tonos seg√∫n nivel de riesgo

**Tiempo:** 30 minutos

---

#### Experimentaci√≥n Libre (30 min)

**Objetivos:**
- Permitir exploraci√≥n aut√≥noma
- Responder preguntas espec√≠ficas
- Facilitar experimentaci√≥n con prompts
- Compartir descubrimientos

**Actividades Sugeridas:**

1. **Modificar Prompts:**
   - Cambiar tono de emails
   - Ajustar longitud de res√∫menes
   - Agregar m√°s ejemplos a clasificaci√≥n

2. **Experimentar con Par√°metros:**
   - Probar diferentes temperatures
   - Ajustar maxTokens
   - Comparar resultados

3. **Crear Nuevos Casos:**
   - Subir PDFs propios
   - Generar datos de prueba
   - Ver flujo completo

4. **Optimizar Prompts:**
   - Iterar sobre prompts existentes
   - Medir mejoras
   - Documentar cambios

**Rol del Instructor:**
- Monitorear el chat y preguntas
- Responder preguntas en tiempo real
- Sugerir experimentos
- Facilitar discusiones en grupo
- Compartir mejores pr√°cticas
- Usar breakout rooms si es necesario

**Tiempo:** 30 minutos

---


## üí° Puntos Clave de Explicaci√≥n

### Servicios AWS

#### Amazon Bedrock
**Qu√© es:**
- Servicio totalmente administrado para usar LLMs
- Acceso a m√∫ltiples modelos (Amazon, Anthropic, Meta, etc.)
- Sin necesidad de gestionar infraestructura

**Cu√°ndo explicar:**
- M√≥dulo 1 (primera vez que se usa)
- Enfatizar: "Serverless para IA"

**Puntos clave:**
- No necesitas entrenar modelos
- Pagas por uso (por token)
- Modelos pre-entrenados listos para usar

#### Amazon Nova Pro
**Qu√© es:**
- Modelo de lenguaje de Amazon
- Optimizado para tareas empresariales
- Multimodal (texto, im√°genes)

**Cu√°ndo explicar:**
- M√≥dulo 1 (al invocar por primera vez)

**Puntos clave:**
- Balanceo entre costo y capacidad
- Bueno para tareas complejas
- Soporta espa√±ol nativamente

#### Amazon Titan Embeddings v2
**Qu√© es:**
- Modelo para generar embeddings
- Vectores de 1024 dimensiones
- Optimizado para b√∫squeda sem√°ntica

**Cu√°ndo explicar:**
- M√≥dulo 3 (RAG)

**Puntos clave:**
- Convierte texto en n√∫meros
- Permite b√∫squeda por significado
- Base de RAG

#### Amazon Textract
**Qu√© es:**
- Servicio de OCR (Optical Character Recognition)
- Extrae texto, tablas y formularios
- Entiende estructura de documentos

**Cu√°ndo explicar:**
- M√≥dulo 1 (extracci√≥n)

**Puntos clave:**
- M√°s que OCR simple
- Entiende tablas y formularios
- No entiende contexto (por eso necesitamos Bedrock)

#### Aurora Serverless v2
**Qu√© es:**
- PostgreSQL serverless
- Escala autom√°ticamente
- Soporta pgvector para embeddings

**Cu√°ndo explicar:**
- Setup inicial
- M√≥dulo 3 (cuando se usa pgvector)

**Puntos clave:**
- Escala de 0.5 a 128 ACUs
- Pagas por uso
- pgvector permite b√∫squeda vectorial

---

### Conceptos de IA Generativa

#### LLMs (Large Language Models)
**Explicaci√≥n simple:**
```
Un LLM es como un asistente muy inteligente que ha le√≠do millones
de libros y puede entender y generar texto de manera natural.

No es una base de datos que busca respuestas exactas.
Es un modelo que entiende patrones y genera respuestas coherentes.
```

**Analog√≠a:**
- Base de datos = Biblioteca con √≠ndice
- LLM = Persona que ley√≥ toda la biblioteca y puede conversar

#### Prompt Engineering
**Explicaci√≥n simple:**
```
Prompt engineering es el arte de comunicarte efectivamente con un LLM.
Es como aprender a dar instrucciones claras a un asistente muy capaz.

Mal prompt: "Dame datos"
Buen prompt: "Eres un experto en X. Extrae estos campos espec√≠ficos
              en formato Y. Si no encuentras algo, usa Z."
```

**Mejores pr√°cticas:**
1. Dar contexto/rol
2. Ser espec√≠fico
3. Proporcionar ejemplos
4. Definir formato de salida
5. Establecer restricciones

#### RAG (Retrieval-Augmented Generation)
**Explicaci√≥n simple:**
```
RAG es como darle a un m√©dico el historial del paciente antes
de que d√© su diagn√≥stico.

Sin RAG: Opini√≥n general basada en conocimiento general
Con RAG: Opini√≥n espec√≠fica basada en datos reales del paciente
```

**Componentes:**
1. **Retrieval**: Buscar informaci√≥n relevante
2. **Augmented**: Agregar al prompt
3. **Generation**: Generar respuesta con contexto

**Beneficios:**
- Reduce alucinaciones
- Proporciona contexto espec√≠fico
- Mejora precisi√≥n
- Permite personalizaci√≥n

#### Few-Shot Learning
**Explicaci√≥n simple:**
```
Few-shot learning es ense√±ar con ejemplos en lugar de entrenar.

Es como mostrarle a alguien 3 fotos de perros y luego pedirle
que identifique perros en nuevas fotos.

No necesitas miles de ejemplos, solo unos pocos buenos.
```

**Tipos:**
- **Zero-shot**: Sin ejemplos
- **One-shot**: Un ejemplo
- **Few-shot**: 2-5 ejemplos
- **Many-shot**: 10+ ejemplos

#### Temperature
**Explicaci√≥n simple:**
```
Temperature controla qu√© tan "creativo" o "aleatorio" es el modelo.

Temperature 0.0: Siempre da la misma respuesta (determin√≠stico)
Temperature 1.0: Respuestas muy variadas (creativo)

Es como el volumen de creatividad.
```

**Gu√≠a de uso:**
```
0.0 - 0.2: Extracci√≥n de datos, clasificaci√≥n
0.3 - 0.5: An√°lisis, res√∫menes
0.6 - 0.8: Contenido, emails
0.9 - 1.0: Brainstorming, ideas
```

#### Embeddings Vectoriales
**Explicaci√≥n simple:**
```
Un embedding es una representaci√≥n num√©rica de texto.

Texto: "Presi√≥n arterial alta"
Embedding: [0.123, -0.456, 0.789, ..., 0.234]

Textos similares tienen embeddings similares.
Permite buscar por significado, no por palabras exactas.
```

**Analog√≠a:**
- Palabras = Direcciones
- Embeddings = Coordenadas GPS
- Similitud = Distancia entre coordenadas

---


## üéì Snippets de C√≥digo Comentados

### Extracci√≥n con Textract y Bedrock

```python
def extract_pdf_data(bucket, key):
    """
    Extrae datos estructurados de un PDF m√©dico.
    
    Flujo:
    1. Textract extrae texto del PDF
    2. Bedrock estructura el texto en JSON
    3. Guardar en Aurora
    """
    
    # Paso 1: Extraer texto con Textract
    # analyze_document es m√°s potente que detect_document_text
    # porque entiende tablas y formularios
    response = textract_client.analyze_document(
        Document={'S3Object': {'Bucket': bucket, 'Name': key}},
        FeatureTypes=['TABLES', 'FORMS']  # Extraer tablas y formularios
    )
    
    # Convertir respuesta de Textract a texto plano
    texto_extraido = extract_text_from_textract(response)
    
    # Paso 2: Estructurar con Bedrock
    # Leer prompt desde archivo (facilita iteraci√≥n)
    with open('prompts/extraction.txt', 'r') as f:
        prompt_template = f.read()
    
    # Construir prompt con el texto extra√≠do
    prompt = prompt_template.replace('{texto}', texto_extraido)
    
    # Invocar Bedrock Nova Pro
    bedrock_response = bedrock_runtime.invoke_model(
        modelId='us.amazon.nova-pro-v1:0',
        body=json.dumps({
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "inferenceConfig": {
                "temperature": 0.1,  # Baja para precisi√≥n
                "maxTokens": 2000,   # Suficiente para JSON
                "topP": 0.9
            }
        })
    )
    
    # Parsear respuesta
    response_body = json.loads(bedrock_response['body'].read())
    datos_estructurados = json.loads(response_body['output']['message']['content'][0]['text'])
    
    # Paso 3: Guardar en Aurora
    save_to_aurora(datos_estructurados)
    
    return datos_estructurados
```

### Generaci√≥n de Embeddings

```python
def generate_embedding(texto):
    """
    Genera embedding vectorial de un texto usando Titan.
    
    Retorna un vector de 1024 dimensiones que representa
    el significado sem√°ntico del texto.
    """
    
    # Invocar Titan Embeddings v2
    response = bedrock_runtime.invoke_model(
        modelId='amazon.titan-embed-text-v2:0',
        body=json.dumps({
            "inputText": texto,
            "dimensions": 1024,  # Dimensiones del vector
            "normalize": True    # Normalizar para cosine similarity
        })
    )
    
    # Extraer embedding
    response_body = json.loads(response['body'].read())
    embedding = response_body['embedding']
    
    return embedding  # Lista de 1024 n√∫meros
```

### B√∫squeda RAG con pgvector

```python
def buscar_informes_similares(trabajador_id, embedding_actual, limit=3):
    """
    Busca informes anteriores similares usando pgvector.
    
    Usa distancia coseno para encontrar embeddings similares.
    Menor distancia = mayor similitud.
    """
    
    sql = """
        SELECT 
            ie.informe_id,
            ie.contenido,
            ie.fecha_examen,
            1 - (ie.embedding <=> %s::vector) as similarity
        FROM informes_embeddings ie
        WHERE ie.trabajador_id = %s
          AND ie.informe_id != %s
        ORDER BY ie.embedding <=> %s::vector  -- Ordenar por distancia
        LIMIT %s
    """
    
    # <=> es el operador de distancia coseno de pgvector
    # 1 - distancia = similitud (0 = diferente, 1 = id√©ntico)
    
    cursor.execute(sql, (
        embedding_actual,
        trabajador_id,
        informe_actual_id,
        embedding_actual,
        limit
    ))
    
    return cursor.fetchall()
```

### Clasificaci√≥n con Few-Shot Learning

```python
def classify_risk(informe_id):
    """
    Clasifica nivel de riesgo usando few-shot learning y RAG.
    
    Combina:
    1. Ejemplos en el prompt (few-shot)
    2. Contexto hist√≥rico (RAG)
    3. Datos actuales
    """
    
    # Obtener datos del informe
    informe = get_informe(informe_id)
    
    # Buscar informes anteriores (RAG)
    embedding = generate_embedding(informe['contenido'])
    informes_anteriores = buscar_informes_similares(
        informe['trabajador_id'],
        embedding,
        limit=3
    )
    
    # Construir contexto hist√≥rico
    contexto = "\n".join([
        f"Fecha: {inf['fecha']}, Riesgo: {inf['nivel']}, "
        f"Observaciones: {inf['obs']}"
        for inf in informes_anteriores
    ])
    
    # Leer prompt con ejemplos (few-shot)
    with open('prompts/classification.txt', 'r') as f:
        prompt_template = f.read()
    
    # Reemplazar placeholders
    prompt = prompt_template.replace('{contexto}', contexto)
    prompt = prompt.replace('{informe}', json.dumps(informe))
    
    # Invocar Bedrock
    response = bedrock_runtime.invoke_model(
        modelId='us.amazon.nova-pro-v1:0',
        body=json.dumps({
            "messages": [{"role": "user", "content": prompt}],
            "inferenceConfig": {
                "temperature": 0.3,  # Baja pero no 0 para variaci√≥n
                "maxTokens": 500
            }
        })
    )
    
    # Parsear y guardar
    result = parse_response(response)
    update_informe(informe_id, result)
    
    return result
```

---

## ‚ùì FAQ con Respuestas T√©cnicas

### Sobre Amazon Bedrock

**P: ¬øPor qu√© usar Bedrock en lugar de llamar directamente a OpenAI?**

R: Varias razones:
1. **Integraci√≥n nativa con AWS**: Permisos IAM, VPC, CloudWatch
2. **M√∫ltiples modelos**: Amazon, Anthropic, Meta, Cohere en un solo lugar
3. **Cumplimiento**: Datos no se usan para entrenar modelos
4. **Soporte empresarial**: SLA, soporte t√©cnico de AWS
5. **Costos**: Competitivos y facturados con AWS

**P: ¬øCu√°nto cuesta usar Bedrock?**

R: Precios aproximados (us-east-1):
- Nova Pro: $0.80 por 1M tokens de entrada, $3.20 por 1M tokens de salida
- Titan Embeddings: $0.10 por 1M tokens
- Para este workshop: ~$2-5 USD por participante

**P: ¬øQu√© modelos est√°n disponibles en Bedrock?**

R: Principales modelos:
- **Amazon**: Nova Pro, Nova Lite, Titan
- **Anthropic**: Claude 3 (Opus, Sonnet, Haiku)
- **Meta**: Llama 3
- **Cohere**: Command, Embed
- **Stability AI**: Stable Diffusion (im√°genes)

**P: ¬øC√≥mo accedo a los modelos de Bedrock?**

R: Los modelos serverless se habilitan autom√°ticamente en la primera invocaci√≥n. Solo necesitas permisos IAM adecuados (`bedrock:InvokeModel`). No requiere activaci√≥n manual.

### Sobre Prompts

**P: ¬øCu√°l es la longitud ideal de un prompt?**

R: Depende de la tarea:
- **Extracci√≥n simple**: 200-500 tokens
- **Clasificaci√≥n con ejemplos**: 500-1000 tokens
- **An√°lisis complejo**: 1000-2000 tokens
- **L√≠mite pr√°ctico**: 4000-8000 tokens (depende del modelo)

**P: ¬øC√≥mo s√© si mi prompt es bueno?**

R: Criterios:
1. **Consistencia**: ¬øDa resultados similares con inputs similares?
2. **Precisi√≥n**: ¬øLos resultados son correctos?
3. **Formato**: ¬øRespeta el formato solicitado?
4. **Completitud**: ¬øIncluye toda la informaci√≥n necesaria?

Prueba con 10-20 casos y mide estos criterios.

**P: ¬øDebo usar JSON mode o parsear la respuesta?**

R: Depende:
- **JSON mode** (si est√° disponible): Garantiza JSON v√°lido
- **Parsear**: M√°s flexible, permite explicaciones adicionales

En este workshop usamos parseo porque queremos ver el proceso.

### Sobre RAG

**P: ¬øCu√°ntos documentos debo recuperar en RAG?**

R: Regla general:
- **3-5 documentos**: Balance entre contexto y ruido
- **Menos de 3**: Puede faltar contexto
- **M√°s de 10**: Puede confundir al modelo

En este workshop usamos 3.

**P: ¬øC√≥mo s√© si RAG est√° mejorando los resultados?**

R: Prueba A/B:
1. Clasificar 20 informes sin RAG
2. Clasificar los mismos 20 con RAG
3. Comparar precisi√≥n con evaluaci√≥n humana

T√≠picamente RAG mejora 10-30% la precisi√≥n.

**P: ¬øPuedo usar RAG con otros tipos de datos?**

R: S√≠, RAG funciona con:
- Documentos (PDFs, Word)
- C√≥digo fuente
- Logs de sistema
- Conversaciones
- Cualquier texto estructurado

### Sobre Embeddings

**P: ¬øPor qu√© 1024 dimensiones?**

R: Balance entre:
- **M√°s dimensiones**: Mayor precisi√≥n, m√°s costo de almacenamiento
- **Menos dimensiones**: Menor precisi√≥n, menos costo

1024 es un buen balance para la mayor√≠a de casos.

**P: ¬øPuedo usar embeddings de OpenAI con pgvector?**

R: S√≠, pgvector es agn√≥stico al modelo:
- OpenAI: 1536 dimensiones
- Titan v2: 1024 dimensiones
- Cohere: 768 dimensiones

Solo ajusta la dimensi√≥n en la tabla.

**P: ¬øC√≥mo actualizo embeddings cuando cambia el contenido?**

R: Estrategias:
1. **Regenerar todo**: Simple pero costoso
2. **Incremental**: Solo nuevos/modificados
3. **Batch nocturno**: Actualizar en horario de baja demanda

En producci√≥n, usa estrategia incremental.

### Sobre Debugging

**P: ¬øC√≥mo debuggeo prompts que no funcionan?**

R: Pasos:
1. **Ver logs en CloudWatch**: Prompt completo y respuesta
2. **Probar en consola de Bedrock**: Playground para iteraci√≥n r√°pida
3. **Simplificar**: Remover complejidad hasta que funcione
4. **Agregar ejemplos**: Few-shot learning ayuda mucho
5. **Ajustar temperature**: Probar valores diferentes

**P: ¬øQu√© hago si Bedrock da errores de throttling?**

R: Soluciones:
1. **Implementar retry con backoff exponencial**
2. **Solicitar aumento de l√≠mites** (Service Quotas)
3. **Usar batch processing** en lugar de tiempo real
4. **Distribuir carga** entre m√∫ltiples regiones

**P: ¬øC√≥mo monitoreo costos de Bedrock?**

R: Herramientas:
1. **Cost Explorer**: Ver costos por servicio
2. **CloudWatch Metrics**: Tokens procesados
3. **Budgets**: Alertas de presupuesto
4. **Tags**: Etiquetar recursos para tracking

---


## ‚è±Ô∏è Tiempos Estimados por M√≥dulo

### D√≠a 1 (1h 15min)

| M√≥dulo | Actividad | Tiempo | Acumulado |
|--------|-----------|--------|-----------|
| 0 | Introducci√≥n y bienvenida | 5 min | 5 min |
| 1 | Desplegar stack extracci√≥n | 5 min | 10 min |
| 1 | Explicar Textract vs Bedrock | 5 min | 15 min |
| 1 | Revisar c√≥digo de extracci√≥n | 10 min | 25 min |
| 1 | Subir PDF y ver logs | 10 min | 35 min |
| 2 | Comparar versiones de prompts | 15 min | 50 min |
| 2 | Experimentar con temperature | 10 min | 60 min |
| 2 | Ejercicio participantes | 5 min | 65 min |
| - | Checkpoint y Q&A | 10 min | 75 min |

**Total D√≠a 1:** 1h 15min

### D√≠a 2 (2h)

| M√≥dulo | Actividad | Tiempo | Acumulado |
|--------|-----------|--------|-----------|
| 3 | Explicar RAG y embeddings | 10 min | 10 min |
| 3 | Desplegar stack RAG | 5 min | 15 min |
| 3 | Generar embeddings | 5 min | 20 min |
| 3 | Demostrar b√∫squeda similitud | 10 min | 30 min |
| 4 | Explicar few-shot learning | 5 min | 35 min |
| 4 | Desplegar stack clasificaci√≥n | 5 min | 40 min |
| 4 | Revisar prompt clasificaci√≥n | 10 min | 50 min |
| 4 | Clasificar y comparar con/sin RAG | 10 min | 60 min |
| 5 | Desplegar stacks resumen y email | 5 min | 65 min |
| 5 | Generar resumen ejecutivo | 10 min | 75 min |
| 5 | Revisar prompts de email | 5 min | 80 min |
| 5 | Enviar emails y mostrar resultados | 10 min | 90 min |
| - | Experimentaci√≥n libre | 30 min | 120 min |

**Total D√≠a 2:** 2h

**Total Workshop:** 3h 15min

---

## üéØ Checkpoints Funcionales

### Checkpoint D√≠a 1

**Objetivo:** Verificar que el flujo de extracci√≥n funciona end-to-end.

**Verificaciones:**

```bash
# 1. Stacks desplegados
aws cloudformation describe-stacks \
  --stack-name LegacyStack \
  --query 'Stacks[0].StackStatus'
# Esperado: CREATE_COMPLETE

aws cloudformation describe-stacks \
  --stack-name AIExtractionStack \
  --query 'Stacks[0].StackStatus'
# Esperado: CREATE_COMPLETE

# 2. PDF procesado
aws s3 ls s3://<bucket>/external-reports/
# Esperado: Ver al menos 1 PDF

# 3. Datos en Aurora
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM informes_medicos WHERE origen='EXTERNO';"
# Esperado: >= 1

# 4. Logs en CloudWatch
aws logs tail /aws/lambda/extract-pdf --since 10m
# Esperado: Ver logs de procesamiento exitoso
```

**Criterios de √âxito:**
- ‚úÖ Todos los stacks desplegados
- ‚úÖ Al menos 1 PDF procesado
- ‚úÖ Datos guardados en Aurora
- ‚úÖ Logs muestran √©xito

**Si algo falla:**
1. Verificar permisos IAM
2. Verificar modelos habilitados en Bedrock
3. Revisar logs de CloudWatch para errores
4. Verificar conectividad a Aurora

### Checkpoint D√≠a 2

**Objetivo:** Verificar que el flujo completo funciona end-to-end.

**Verificaciones:**

```bash
# 1. Todos los stacks desplegados
aws cloudformation list-stacks \
  --stack-status-filter CREATE_COMPLETE \
  --query 'StackSummaries[?contains(StackName, `Stack`)].StackName'
# Esperado: 6 stacks (Legacy, Extraction, RAG, Classification, Summary, Email)

# 2. Embeddings generados
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM informes_embeddings;"
# Esperado: >= 1

# 3. Informes clasificados
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM informes_medicos WHERE nivel_riesgo IS NOT NULL;"
# Esperado: >= 1

# 4. Res√∫menes generados
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM informes_medicos WHERE resumen_ejecutivo IS NOT NULL;"
# Esperado: >= 1

# 5. Emails enviados
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM historial_emails WHERE estado='ENVIADO';"
# Esperado: >= 1
```

**Criterios de √âxito:**
- ‚úÖ Todos los stacks desplegados
- ‚úÖ Embeddings generados
- ‚úÖ Clasificaci√≥n funcionando
- ‚úÖ Res√∫menes generados
- ‚úÖ Emails enviados

**Si algo falla:**
1. Verificar que D√≠a 1 funcion√≥ correctamente
2. Verificar email verificado en SES
3. Revisar logs de cada Lambda
4. Verificar datos en Aurora

---

## üìä M√©tricas de √âxito del Workshop

### M√©tricas T√©cnicas

- ‚úÖ **100% de participantes** completan despliegue del sistema legacy
- ‚úÖ **90%+ de participantes** procesan al menos 1 PDF exitosamente
- ‚úÖ **80%+ de participantes** completan flujo end-to-end
- ‚úÖ **70%+ de participantes** experimentan con prompts

### M√©tricas de Aprendizaje

Al final del workshop, los participantes deben poder:

- ‚úÖ Explicar diferencia entre Textract y Bedrock
- ‚úÖ Escribir un prompt efectivo
- ‚úÖ Explicar qu√© es RAG y por qu√© es √∫til
- ‚úÖ Describir few-shot learning
- ‚úÖ Ajustar temperature seg√∫n el caso de uso
- ‚úÖ Desplegar infraestructura con CDK

### M√©tricas de Satisfacci√≥n

- ‚úÖ **4.5+/5** en encuesta de satisfacci√≥n
- ‚úÖ **90%+** recomendar√≠an el workshop
- ‚úÖ **80%+** sienten que pueden aplicar lo aprendido

---

## üõ†Ô∏è Troubleshooting para el Instructor

### Problema: Error "Model access denied" en Bedrock

**Causa:** Permisos IAM insuficientes.

**Soluci√≥n:**
1. Verificar que el usuario tiene permisos `bedrock:InvokeModel`
2. Verificar regi√≥n (us-east-2 o us-east-1 recomendadas)
3. Si es cuenta organizacional, verificar SCPs
4. Los modelos se habilitan autom√°ticamente en la primera invocaci√≥n

### Problema: Credenciales AWS expiradas durante el workshop

**Causa:** Sesi√≥n SSO expirada (com√∫n despu√©s de 8-12 horas).

**Soluci√≥n:**
```bash
# Renovar sesi√≥n SSO
aws sso login --profile <nombre-perfil>

# Verificar que funciona
aws sts get-caller-identity --profile <nombre-perfil>

# Reintentar comando que fall√≥
```

### Problema: CDK deploy falla con "bucket already exists"

**Causa:** Prefijo no √∫nico entre participantes.

**Soluci√≥n:**
1. Pedir a participante cambiar prefijo en [`cdk/bin/app.ts`](cdk/bin/app.ts)
2. Sugerir formato: `participant-nombre-numero`
3. Verificar que sea √∫nico antes de re-desplegar

### Problema: Lambda no puede conectar a Aurora

**Causa:** Security group o VPC mal configurado.

**Soluci√≥n:**
1. Verificar que Lambda est√° en la misma VPC que Aurora
2. Verificar security group permite tr√°fico desde Lambda
3. Verificar subnet tiene ruta a internet (para Bedrock)
4. Revisar logs de CloudWatch para error espec√≠fico

### Problema: Textract falla con "InvalidS3ObjectException"

**Causa:** PDF corrupto o formato no soportado.

**Soluci√≥n:**
1. Verificar que el archivo es un PDF v√°lido
2. Probar con PDFs de ejemplo del repositorio
3. Verificar permisos de S3
4. Verificar que el PDF no est√° encriptado

### Problema: Bedrock responde con JSON inv√°lido

**Causa:** Prompt no es suficientemente espec√≠fico.

**Soluci√≥n:**
1. Agregar m√°s ejemplos al prompt
2. Bajar temperature a 0.1
3. Agregar instrucci√≥n expl√≠cita: "Responde SOLO con JSON v√°lido"
4. Implementar retry con validaci√≥n

### Problema: Emails no se env√≠an

**Causa:** Email no verificado en SES o cuenta en sandbox.

**Soluci√≥n:**
1. Verificar email en SES
2. Si est√° en sandbox, solo puede enviar a emails verificados
3. Solicitar salir de sandbox (toma 24h)
4. Como alternativa, usar SNS para notificaciones

### Problema: Costos m√°s altos de lo esperado

**Causa:** Muchas invocaciones o tokens excesivos.

**Soluci√≥n:**
1. Revisar CloudWatch Metrics para uso de Bedrock
2. Optimizar prompts para usar menos tokens
3. Implementar caching de respuestas
4. Configurar alertas de presupuesto

---

## üìö Recursos Adicionales para el Instructor

### Documentaci√≥n Oficial

- [Amazon Bedrock Documentation](https://docs.aws.amazon.com/bedrock/)
- [Amazon Textract Documentation](https://docs.aws.amazon.com/textract/)
- [AWS CDK Documentation](https://docs.aws.amazon.com/cdk/)
- [pgvector Documentation](https://github.com/pgvector/pgvector)

### Gu√≠as de Prompt Engineering

- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [OpenAI Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)
- [Anthropic Prompt Library](https://docs.anthropic.com/claude/prompt-library)

### Papers y Art√≠culos

- [RAG: Retrieval-Augmented Generation](https://arxiv.org/abs/2005.11401)
- [Few-Shot Learning](https://arxiv.org/abs/2005.14165)
- [In-Context Learning](https://arxiv.org/abs/2301.00234)

### Comunidades

- [AWS re:Post - Bedrock](https://repost.aws/tags/TA4IHBWMFxRRKzKzuCJAV_Aw/amazon-bedrock)
- [AWS Samples GitHub](https://github.com/aws-samples)
- [Bedrock Workshop](https://catalog.workshops.aws/building-with-amazon-bedrock)

---

## ‚úÖ Checklist Final

### Antes del Workshop

- [ ] Sistema desplegado en cuenta de demostraci√≥n
- [ ] Email a participantes enviado con prerequisitos

### Durante el Workshop

- [ ] Conectarse 15 minutos antes
- [ ] Tener consola AWS, CloudWatch Logs y terminal listos

### Despu√©s del Workshop

- [ ] Enviar encuesta de satisfacci√≥n
- [ ] Compartir recursos adicionales
- [ ] Responder preguntas pendientes
- [ ] Recopilar feedback para mejoras
- [ ] Limpiar recursos de demostraci√≥n

---

## üéâ Conclusi√≥n

Este workshop proporciona una experiencia pr√°ctica completa de IA Generativa con AWS. Los participantes no solo aprenden conceptos, sino que construyen un sistema real end-to-end.

**Puntos clave para el √©xito:**
1. Mantener el ritmo (3h 15min es ajustado)
2. Enfocarse en conceptos, no solo en c√≥digo
3. Permitir experimentaci√≥n
4. Responder preguntas con ejemplos pr√°cticos
5. Conectar cada m√≥dulo con el caso de uso real

**Recuerda:** El objetivo no es que memoricen comandos, sino que entiendan los conceptos y puedan aplicarlos en sus propios proyectos.

¬°Buena suerte con el workshop! üöÄ


---

## üßπ Limpieza de Recursos Despu√©s del Workshop

**‚ö†Ô∏è IMPORTANTE:** Elimina todos los recursos despu√©s del workshop para evitar costos innecesarios.

### Opci√≥n A: Script Automatizado (Recomendado)

El script elimina todos los recursos en el orden correcto: AI Stacks ‚Üí Legacy Stacks ‚Üí Network Stack

```powershell
# PowerShell - Elimina todos los recursos
.\scripts\instructor-cleanup.ps1

# Con par√°metros personalizados:
.\scripts\instructor-cleanup.ps1 -ConfigFile config/participants.json -Profile <tu-perfil-aws> -Concurrency 5

# Para participantes espec√≠ficos:
.\scripts\instructor-cleanup.ps1 -Participants "participant-juan","participant-maria"

# Sin confirmaci√≥n (para automatizaci√≥n):
.\scripts\instructor-cleanup.ps1 -SkipConfirmation
```

Ver script: [`scripts/instructor-cleanup.ps1`](scripts/instructor-cleanup.ps1)

```bash
# Bash (Linux/Mac)
./scripts/instructor-cleanup.sh

# Con par√°metros:
./scripts/instructor-cleanup.sh config/participants.json <tu-perfil-aws> us-east-2
```

Ver script: [`scripts/instructor-cleanup.sh`](scripts/instructor-cleanup.sh)

**Tiempo estimado:** Variable seg√∫n n√∫mero de participantes (~5-15 minutos)

**El script:**
- ‚úÖ Elimina en el orden correcto (AI ‚Üí Legacy ‚Üí Network)
- ‚úÖ Contin√∫a si un stack falla
- ‚úÖ Genera reporte de errores
- ‚úÖ Verifica recursos hu√©rfanos

### Opci√≥n B: Limpieza Manual

Si prefieres eliminar manualmente o el script falla:

#### 1. Eliminar AI Stacks de Cada Participante

```powershell
# PowerShell - Para cada participante
$env:DEPLOY_MODE = "ai"
$env:PARTICIPANT_PREFIX = "participant-juan"
cd cdk
cdk destroy --all --force --profile <tu-perfil-aws>
```

#### 2. Eliminar LegacyStacks

```powershell
# PowerShell - Para cada participante
$env:DEPLOY_MODE = "legacy"
$env:PARTICIPANT_PREFIX = "participant-juan"
cd cdk
cdk destroy participant-juan-MedicalReportsLegacyStack --force --profile <tu-perfil-aws>
```

#### 3. Eliminar SharedNetworkStack

```powershell
# PowerShell - Una sola vez al final
$env:DEPLOY_MODE = "network"
cd cdk
cdk destroy SharedNetworkStack --force --profile <tu-perfil-aws>
```

### Verificaci√≥n de Limpieza

Verifica que no quedan recursos:

```powershell
# Listar stacks restantes
aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE --profile <tu-perfil-aws>

# Verificar buckets S3 (deben estar vac√≠os)
aws s3 ls --profile <tu-perfil-aws>

# Verificar bases de datos Aurora
aws rds describe-db-clusters --profile <tu-perfil-aws>
```

### Recursos que se Eliminan

Por cada participante:
- ‚úÖ 5 AI Stacks (Lambdas de IA)
- ‚úÖ 1 LegacyStack (Aurora, S3, API Gateway, Lambdas)
- ‚úÖ Security Groups
- ‚úÖ Roles y pol√≠ticas IAM

Infraestructura compartida:
- ‚úÖ SharedNetworkStack (VPC, NAT Gateway, subnets)

### Troubleshooting de Limpieza

**Error: "Stack cannot be deleted while it has dependent stacks"**
- Elimina primero los AI Stacks, luego Legacy, luego Network
- El script automatizado ya maneja este orden

**Error: "Bucket not empty"**
- Los buckets S3 tienen `autoDeleteObjects: true`
- Si falla, vac√≠a manualmente: `aws s3 rm s3://bucket-name --recursive`

**Error: "Resource being used by another resource"**
- Espera unos minutos y reintenta
- Verifica en la consola de CloudFormation qu√© recurso est√° bloqueando

**Stacks en estado DELETE_FAILED**
- Revisa los eventos en CloudFormation para ver qu√© fall√≥
- Elimina manualmente el recurso problem√°tico
- Reintenta la eliminaci√≥n del stack

### Costos Estimados

Si olvidas eliminar los recursos, los costos aproximados son:

| Recurso | Costo por hora | Costo por d√≠a |
|---------|----------------|---------------|
| Aurora Serverless v2 (0.5 ACU) | ~$0.06 | ~$1.44 |
| NAT Gateway | ~$0.045 | ~$1.08 |
| Lambdas (idle) | $0 | $0 |
| S3 (storage) | M√≠nimo | M√≠nimo |
| **Total por participante** | **~$0.06** | **~$1.44** |
| **10 participantes + VPC** | **~$0.65** | **~$15.60** |

**‚ö†Ô∏è Recomendaci√≥n:** Elimina los recursos inmediatamente despu√©s del workshop para evitar costos innecesarios.

---

## üìä Resumen de Comandos R√°pidos

### Preparaci√≥n Antes del Workshop

```powershell
# 1. Configurar participantes
# Editar: config/participants.json

# 2. Verificar emails en SES
aws ses verify-email-identity --email-address EMAIL --profile <tu-perfil-aws>

# 3. Desplegar VPC compartida (~8 min)
.\scripts\instructor-deploy-network.ps1

# 4. Desplegar LegacyStacks (~20 min para 10 participantes)
.\scripts\instructor-deploy-legacy.ps1

# 5. Verificar despliegue
aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE --profile <tu-perfil-aws>
```

### Durante el Workshop (Participantes)

```powershell
# Participantes despliegan AI Stacks (~5-8 min)
.\scripts\participant-deploy-ai.ps1 -ParticipantPrefix "participant-X" -VerifiedEmail "email@example.com"
```

### Despu√©s del Workshop

```powershell
# Limpieza completa
.\scripts\instructor-cleanup.ps1
```

---

## üìö Documentaci√≥n Adicional

- **Modos de despliegue:** Ver [`cdk/DEPLOY_MODES.md`](cdk/DEPLOY_MODES.md)
- **Configuraci√≥n de participantes:** Ver [`config/README.md`](config/README.md)
- **Arquitectura t√©cnica:** Ver [`.kiro/specs/workshop-deployment-optimization/design.md`](.kiro/specs/workshop-deployment-optimization/design.md)
- **Gu√≠a para participantes:** Ver [`PARTICIPANT_GUIDE.md`](PARTICIPANT_GUIDE.md)

---

## üÜò Soporte Durante el Workshop

### Problemas Comunes

**"Mi despliegue est√° tardando mucho"**
- Tiempo normal: 5-8 minutos
- Si tarda >10 minutos, verificar CloudFormation en consola
- Posible causa: L√≠mites de servicio alcanzados

**"Error: LegacyStack no encontrado"**
- El instructor debe haber desplegado el LegacyStack primero
- Verificar: `aws cloudformation describe-stacks --stack-name participant-X-MedicalReportsLegacyStack`

**"Error: Token expirado"**
- Renovar sesi√≥n: `aws sso login --profile <tu-perfil-aws>`
- Los scripts lo hacen autom√°ticamente

**"No puedo enviar emails"**
- Verificar que el email est√° verificado en SES
- Si la cuenta est√° en SES Sandbox, solo se pueden enviar a emails verificados

### Contacto de Emergencia

Durante el workshop, ten a mano:
- Consola de CloudFormation
- CloudWatch Logs
- Documentaci√≥n de Bedrock
- Este INSTRUCTOR_GUIDE.md

---

**¬°√âxito con tu workshop! üöÄ**
