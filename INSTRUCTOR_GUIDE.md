# üë®‚Äçüè´ Gu√≠a para Instructor - Medical Reports Automation Workshop

Esta gu√≠a proporciona todo lo necesario para impartir el workshop de **Automatizaci√≥n de Informes M√©dicos con AWS y Amazon Bedrock**.

## üìã Informaci√≥n General

**Duraci√≥n Total:** 3 horas 15 minutos (dividido en 2 d√≠as)
**Nivel:** Intermedio
**Audiencia:** Desarrolladores con conocimientos b√°sicos de AWS
**Tama√±o de grupo:** 10-30 participantes

## üéØ Enfoque del Workshop

El workshop est√° dise√±ado para enfocarse en el **valor de negocio** desde el D√≠a 1, permitiendo a los participantes ver resultados tangibles inmediatamente.

### Caracter√≠sticas Principales

1. **Valor de negocio claro:** Los participantes ven ROI inmediato (125 horas/mes ‚Üí 16 horas/mes)
2. **Menos tiempo de setup:** M√°s tiempo para aprender conceptos de IA (despliegue de 3-5 minutos)
3. **Enfoque en IA:** Few-shot learning, RAG, temperature, maxTokens
4. **Experiencia visual:** App web para interactuar con el sistema
5. **Progresi√≥n l√≥gica:** D√≠a 1 (clasificaci√≥n + res√∫menes) ‚Üí D√≠a 2 (emails + PDFs + RAG avanzado)

## üéØ Objetivos de Aprendizaje

### D√≠a 1 (Enfoque de esta gu√≠a)

Al finalizar el D√≠a 1, los participantes podr√°n:

1. **Entender el problema de negocio:** Optimizaci√≥n del env√≠o de informes m√©dicos
2. **Implementar clasificaci√≥n con few-shot learning:** Clasificar riesgo (BAJO/MEDIO/ALTO)
3. **Generar res√∫menes ejecutivos con IA:** Res√∫menes de 100-150 palabras
4. **Aplicar RAG simple:** B√∫squeda SQL para contexto hist√≥rico
5. **Ajustar par√°metros de Bedrock:** Temperature y maxTokens seg√∫n caso de uso
6. **Usar prompt engineering:** Dise√±ar prompts efectivos
7. **Calcular ROI:** Entender el impacto de automatizaci√≥n con IA
8. **Interactuar con app web:** Usar interfaz visual para clasificar y generar res√∫menes

### D√≠a 2 (Capacidades avanzadas)

9. Implementar RAG avanzado con embeddings vectoriales
10. Generar emails personalizados seg√∫n nivel de riesgo
11. Integrar Amazon Textract para PDFs externos
12. Experimentar con diferentes prompts y par√°metros

## ‚è±Ô∏è Timing Detallado del D√≠a 1

**Duraci√≥n Total:** 1 hora 15 minutos de contenido + 45 minutos de buffer = 2 horas

### Desglose por M√≥dulo

| M√≥dulo | Duraci√≥n | Actividad | Notas |
|--------|----------|-----------|-------|
| **Setup** | 5 min | Despliegue de AI Stacks | Participantes ejecutan script, t√∫ explicas arquitectura |
| **M√≥dulo 0** | 10 min | Introducci√≥n al problema | Presentaci√≥n del caso de negocio con m√©tricas |
| **M√≥dulo 1** | 30 min | Clasificaci√≥n de riesgo | Few-shot learning + RAG + hands-on |
| **M√≥dulo 2** | 30 min | Generaci√≥n de res√∫menes | Temperature + maxTokens + hands-on |
| **Checkpoint** | 10 min | ROI y reflexi√≥n | C√°lculos de ahorro + preguntas |
| **Buffer** | 45 min | Troubleshooting + Q&A | Tiempo para resolver problemas |

### Timing Detallado por Secci√≥n

#### Setup Inicial (5 minutos)
- **0:00-0:02** - Participantes abren CloudShell y clonan repo
- **0:02-0:03** - Instalan dependencias (`npm install`)
- **0:03-0:05** - Ejecutan script de despliegue
- **0:05-0:08** - Mientras despliega, t√∫ explicas arquitectura en pantalla compartida

**üí° Tip:** Inicia el despliegue r√°pido para que corra en background mientras explicas.

#### M√≥dulo 0: Introducci√≥n (10 minutos)
- **0:08-0:13** - Presentaci√≥n del problema de negocio
  - 500 informes/mes
  - 125 horas/mes de trabajo manual
  - $6,250-10,400/mes de costo
- **0:13-0:18** - Explicaci√≥n de la soluci√≥n con IA
  - Clasificaci√≥n autom√°tica
  - Res√∫menes ejecutivos
  - ROI: 87-92% ahorro

#### M√≥dulo 1: Clasificaci√≥n (30 minutos)
- **0:18-0:23** - Parte 1: Ver datos en Aurora (5 min)
  - Comandos AWS CLI
  - Exploraci√≥n de datos
- **0:23-0:33** - Parte 2: Clasificar con Lambda (10 min)
  - Invocar classify-risk
  - Ver logs en tiempo real
  - Verificar resultado en Aurora
- **0:33-0:43** - Parte 3: Entender el c√≥digo (10 min)
  - Ver prompt de clasificaci√≥n
  - Explicar few-shot learning
  - Explicar RAG con SQL
  - Ver c√≥digo de la Lambda
- **0:43-0:48** - Parte 4: Usar App Web (5 min)
  - Abrir app web
  - Clasificar desde interfaz visual
  - Comparar CLI vs App Web

#### M√≥dulo 2: Res√∫menes (30 minutos)
- **0:48-0:58** - Parte 1: Generar resumen (10 min)
  - Invocar generate-summary
  - Ver logs
  - Verificar resultado
- **0:58-1:06** - Parte 2: Entender el prompt (8 min)
  - Ver prompt de resumen
  - Comparar con clasificaci√≥n
  - Ver c√≥digo
- **1:06-1:13** - Parte 3: Entender par√°metros (7 min)
  - Explicar temperature (tabla comparativa)
  - Explicar maxTokens (tabla comparativa)
  - Explicar prompt engineering
- **1:13-1:18** - Parte 4: Usar App Web (5 min)
  - Generar res√∫menes desde interfaz
  - Analizar calidad
  - Ejercicio individual

#### Checkpoint (10 minutos)
- **1:18-1:21** - Verificaci√≥n (3 min)
  - Revisar que todos tienen 3+ informes clasificados
  - Revisar que todos tienen 3+ res√∫menes generados
- **1:21-1:26** - C√°lculo de ROI (5 min)
  - Presentar tabla comparativa
  - Mostrar ahorro de tiempo y costo
  - Destacar beneficios adicionales
- **1:26-1:28** - Preguntas de reflexi√≥n (2 min)
  - T√©cnicas: temperature, RAG, prompts
  - Negocio: otros procesos, medici√≥n, riesgos

### Gesti√≥n del Tiempo

**Si vas adelantado (>10 min):**
- ‚úÖ Profundiza en conceptos t√©cnicos
- ‚úÖ Muestra m√°s ejemplos de prompts
- ‚úÖ Permite m√°s experimentaci√≥n individual
- ‚úÖ Responde preguntas en detalle

**Si vas atrasado (>10 min):**
- ‚ö†Ô∏è Reduce tiempo de experimentaci√≥n individual
- ‚ö†Ô∏è Muestra comandos en lugar de que todos los ejecuten
- ‚ö†Ô∏è Combina Parte 3 y 4 de cada m√≥dulo
- ‚ö†Ô∏è Acorta el checkpoint a 5 minutos

**Si hay problemas t√©cnicos:**
- üö® Usa tu cuenta de demostraci√≥n para continuar
- üö® Comparte pantalla con tu ejecuci√≥n
- üö® Resuelve problemas individuales en el buffer time
- üö® Documenta problemas para mejorar pr√≥xima sesi√≥n

### Se√±ales de que vas bien

- ‚úÖ Participantes hacen preguntas relevantes
- ‚úÖ Ves actividad en el chat (compartiendo resultados)
- ‚úÖ Los comandos funcionan para la mayor√≠a
- ‚úÖ Hay "aha moments" visibles (reacciones positivas)

### Se√±ales de alerta

- ‚ö†Ô∏è Silencio prolongado (>2 min sin interacci√≥n)
- ‚ö†Ô∏è M√∫ltiples participantes con el mismo error
- ‚ö†Ô∏è Preguntas sobre conceptos b√°sicos de AWS
- ‚ö†Ô∏è Participantes perdidos en qu√© paso est√°n

**Acci√≥n:** Pausa, verifica que todos est√©n en el mismo punto, resuelve el bloqueador com√∫n.

---

## üìö Prerequisitos para Participantes

### Conocimientos T√©cnicos
- ‚úÖ Conocimientos b√°sicos de AWS (Lambda, S3, IAM)
- ‚úÖ Experiencia con l√≠nea de comandos
- ‚úÖ Familiaridad con Python (lectura de c√≥digo)
- ‚úÖ Conceptos b√°sicos de APIs REST

### Herramientas Requeridas
- ‚úÖ **Navegador web** (Chrome, Firefox, Edge, Safari)
- ‚úÖ **Acceso a AWS Console** (proporcionado por ti)

**¬°Eso es todo!** Los participantes usar√°n **AWS CloudShell**, que ya incluye:
- ‚úÖ AWS CLI pre-configurado
- ‚úÖ Node.js y npm
- ‚úÖ Python 3
- ‚úÖ Git
- ‚úÖ Solo necesitan instalar CDK (1 minuto)

**No se requieren instalaciones locales** - Todo funciona desde el navegador.

### Cuenta AWS
- ‚úÖ Cuenta AWS con permisos de administrador
- ‚úÖ Acceso a Amazon Bedrock habilitado
- ‚úÖ L√≠mites de servicio verificados

## üõ†Ô∏è Preparaci√≥n del Instructor

### 1 Semana Antes

- [ ] Verificar acceso a Amazon Bedrock en la regi√≥n del workshop
- [ ] Solicitar aumento de l√≠mites si es necesario (Bedrock, Lambda)
- [ ] Preparar cuenta AWS de demostraci√≥n
- [ ] Probar despliegue completo en cuenta de prueba
- [ ] Preparar slides de presentaci√≥n
- [ ] Enviar email a participantes con:
  - Link a AWS Console
  - Credenciales de acceso (usuario IAM o SSO)
  - Su PARTICIPANT_PREFIX asignado
  - **Nota:** Solo necesitan navegador web, usar√°n CloudShell

### 1 D√≠a Antes

- [ ] Desplegar sistema en cuenta de demostraci√≥n
- [ ] Preparar PDFs de ejemplo adicionales
- [ ] Revisar √∫ltimas actualizaciones de servicios AWS

### D√≠a del Workshop

- [ ] Conectarse 15 minutos antes
- [ ] Tener consola AWS, CloudWatch Logs y terminal listos para compartir
- [ ] Tener documentaci√≥n de Bedrock a mano

---

## üèóÔ∏è Preparaci√≥n de Infraestructura Antes del Workshop (NUEVO)

**‚ö†Ô∏è IMPORTANTE:** El workshop ahora usa una arquitectura optimizada que separa el despliegue en dos fases:

1. **Instructor (ANTES del workshop):** Despliega VPC compartida y LegacyStacks (~30 minutos total)
2. **Participantes (DURANTE el workshop):** Despliegan solo AI Stacks (~5-8 minutos)

Esta separaci√≥n reduce el tiempo de despliegue en vivo de ~25-35 minutos a solo ~5-8 minutos, permitiendo m√°s tiempo para los m√≥dulos pedag√≥gicos.

### Arquitectura Optimizada

```
ANTES DEL WORKSHOP (Instructor):
‚îú‚îÄ‚îÄ SharedNetworkStack (una vez)
‚îÇ   ‚îî‚îÄ‚îÄ VPC compartida para todos
‚îÇ       Tiempo: ~8 minutos
‚îÇ
‚îî‚îÄ‚îÄ LegacyStack √ó N participantes
    ‚îú‚îÄ‚îÄ Aurora Serverless v2
    ‚îú‚îÄ‚îÄ S3 Bucket
    ‚îú‚îÄ‚îÄ API Gateway
    ‚îî‚îÄ‚îÄ Lambdas Legacy
    Tiempo: ~15 min cada uno (en paralelo)

DURANTE EL WORKSHOP (Participantes):
‚îî‚îÄ‚îÄ AI Stacks (5 stacks)
    ‚îú‚îÄ‚îÄ AIExtractionStack
    ‚îú‚îÄ‚îÄ AIRAGStack
    ‚îú‚îÄ‚îÄ AIClassificationStack
    ‚îú‚îÄ‚îÄ AISummaryStack
    ‚îî‚îÄ‚îÄ AIEmailStack
    Tiempo: ~5-8 minutos total
```

### Paso 1: Configurar Lista de Participantes

Edita el archivo [`config/participants.json`](config/participants.json) con usuarios gen√©ricos:

```json
{
  "participants": [
    {
      "prefix": "participant-1",
      "email": "instructor@example.com",
      "iamUsername": "workshop-user-1"
    },
    {
      "prefix": "participant-2",
      "email": "instructor@example.com",
      "iamUsername": "workshop-user-2"
    },
    {
      "prefix": "participant-3",
      "email": "instructor@example.com",
      "iamUsername": "workshop-user-3"
    }
  ]
}
```

**Campos:**
- `prefix`: Identificador √∫nico gen√©rico (`participant-1`, `participant-2`, etc.)
- `email`: **Tu email como instructor** (el mismo para todos)
- `iamUsername`: Usuario IAM gen√©rico del workshop

**üí° Ventaja:** Usas usuarios gen√©ricos reutilizables, no necesitas emails individuales.

### Paso 2: Verificar TU Email en SES (Una Sola Vez)

Solo necesitas verificar **tu email como instructor** (no el de cada participante):

```powershell
# PowerShell - Solo una vez
aws ses verify-email-identity --email-address tu-email-instructor@example.com --profile <tu-perfil-aws> --region us-east-2

# Recibir√°s un email de verificaci√≥n. Haz clic en el enlace para confirmar.
```

**Nota:** Todos los participantes usar√°n el mismo email verificado (el tuyo) para las notificaciones de SES durante el workshop.

### Paso 3: Desplegar SharedNetworkStack (Una Sola Vez)

Despliega la VPC compartida que usar√°n todos los participantes:

```powershell
# PowerShell
.\scripts\instructor-deploy-network.ps1

# O con par√°metros personalizados:
.\scripts\instructor-deploy-network.ps1 -Profile <tu-perfil-aws> -Region us-east-2
```

Ver script: [`scripts/instructor-deploy-network.ps1`](scripts/instructor-deploy-network.ps1)

```bash
# Bash (Linux/Mac)
./scripts/instructor-deploy-network.sh

# O con par√°metros:
./scripts/instructor-deploy-network.sh <tu-perfil-aws> us-east-2
```

Ver script: [`scripts/instructor-deploy-network.sh`](scripts/instructor-deploy-network.sh)

**Tiempo estimado:** ~8 minutos

**Recursos creados:**
- VPC compartida (10.0.0.0/16)
- 2 Subnets p√∫blicas
- 2 Subnets privadas  
- 2 Subnets aisladas
- 1 NAT Gateway
- 1 Internet Gateway

### Paso 4: Desplegar LegacyStacks para Todos los Participantes

Despliega la infraestructura base (Aurora, S3, Lambdas) para cada participante:

```powershell
# PowerShell - Despliega para todos los participantes en config/participants.json
.\scripts\instructor-deploy-legacy.ps1

# Con par√°metros personalizados:
.\scripts\instructor-deploy-legacy.ps1 -ConfigFile config/participants.json -Profile <tu-perfil-aws> -Concurrency 3

# O para participantes espec√≠ficos:
.\scripts\instructor-deploy-legacy.ps1 -Participants "participant-juan","participant-maria"
```

Ver script: [`scripts/instructor-deploy-legacy.ps1`](scripts/instructor-deploy-legacy.ps1)

```bash
# Bash (Linux/Mac)
./scripts/instructor-deploy-legacy.sh

# Con par√°metros:
./scripts/instructor-deploy-legacy.sh config/participants.json <tu-perfil-aws> us-east-2 3
```

Ver script: [`scripts/instructor-deploy-legacy.sh`](scripts/instructor-deploy-legacy.sh)

**Tiempo estimado:** ~15 minutos por participante (se despliegan en paralelo)
- Con 3 participantes y concurrencia 3: ~15 minutos total
- Con 10 participantes y concurrencia 5: ~30 minutos total

**Recursos creados por participante:**
- Aurora Serverless v2 (PostgreSQL con pgvector)
- S3 Bucket individual
- API Gateway
- 3 Lambdas Legacy (register-exam, generate-pdf, generate-test-data)
- Security Groups individuales

**Outputs:**
El script genera un reporte JSON con los outputs de cada stack:
- `deployment-report-legacy-YYYYMMDD-HHMMSS.json`

### Paso 5: Compartir Informaci√≥n con Participantes

Env√≠a a cada participante un email con:

1. **Acceso a AWS Console:**
   - Link: https://console.aws.amazon.com/
   - Usuario gen√©rico: `workshop-user-1` (o el n√∫mero asignado)
   - Contrase√±a: [proporcionada por separado]

2. **Su PARTICIPANT_PREFIX:** `participant-1` (o el n√∫mero asignado)

3. **Email verificado:** `tu-email-instructor@example.com` (el mismo para todos)

4. **Link al repositorio** del workshop

5. **Instrucciones simples:**
   ```
   1. Inicia sesi√≥n en AWS Console con tu usuario
   2. Abre CloudShell (√≠cono >_ en la esquina superior derecha)
   3. Clona el repositorio: git clone <url>
   4. cd medical-reports-automation
   5. Ejecuta: ./scripts/participant-deploy-ai.sh participant-1 instructor@example.com
      (Reemplaza participant-1 con tu n√∫mero asignado)
   6. Espera 5-8 minutos
   ```

**Ventajas de usuarios gen√©ricos:**
- ‚úÖ No necesitas emails individuales de participantes
- ‚úÖ Usuarios reutilizables para futuros workshops
- ‚úÖ Todos usan el mismo email verificado (el tuyo)
- ‚úÖ M√°s f√°cil de gestionar

**Nota para participantes:** No necesitan instalar nada localmente, todo funciona desde CloudShell en el navegador.

### Verificaci√≥n Pre-Workshop

Antes del workshop, verifica que todo est√° listo:

```powershell
# Verificar que SharedNetworkStack existe
aws cloudformation describe-stacks --stack-name SharedNetworkStack --profile <tu-perfil-aws>

# Verificar LegacyStack de un participante
aws cloudformation describe-stacks --stack-name participant-juan-MedicalReportsLegacyStack --profile <tu-perfil-aws>

# Listar todos los stacks
aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE --profile <tu-perfil-aws>
```

### Tiempos Estimados

| Fase | Qui√©n | Cu√°ndo | Tiempo |
|------|-------|--------|--------|
| SharedNetworkStack | Instructor | Antes del workshop | ~8 min |
| LegacyStacks (10 participantes) | Instructor | Antes del workshop | ~20 min |
| AI Stacks | Participantes | Durante D√≠a 1 | ~5-8 min |
| **Total para instructor** | | | **~30 min** |
| **Total para participantes** | | | **~5-8 min** |

### Troubleshooting

**Error: "SharedNetworkStack no encontrado"**
- Aseg√∫rate de haber ejecutado `instructor-deploy-network.ps1` primero

**Error: "Export not found"**
- Verifica que SharedNetworkStack est√° en estado CREATE_COMPLETE
- Ejecuta: `aws cloudformation describe-stacks --stack-name SharedNetworkStack`

**Error: "Token expirado"**
- Los scripts renuevan autom√°ticamente la sesi√≥n SSO
- Si falla, ejecuta manualmente: `aws sso login --profile <tu-perfil-aws>`

**Despliegue lento**
- Aumenta la concurrencia: `-Concurrency 5` (PowerShell)
- Verifica l√≠mites de servicio en tu cuenta AWS

---

## üöÄ Despliegue Completo del Sistema (M√©todo Tradicional)

Esta secci√≥n explica c√≥mo desplegar todo el sistema en tu cuenta de demostraci√≥n **antes del workshop**. Durante el workshop, los participantes desplegar√°n los stacks uno por uno siguiendo los m√≥dulos pedag√≥gicos.

### Paso 1: Configurar Credenciales AWS

**IMPORTANTE:** Debes configurar tus credenciales de AWS antes de continuar.

Tienes dos opciones para configurar el acceso a AWS:

#### Opci√≥n A: Usuario IAM con Credenciales

Si usas un usuario IAM con access keys:

```bash
# Configurar credenciales
aws configure

# Ingresar:
# - AWS Access Key ID
# - AWS Secret Access Key
# - Default region: us-east-2
# - Default output format: json

# Verificar configuraci√≥n
aws sts get-caller-identity
```

Si el comando anterior funciona correctamente, tus credenciales est√°n configuradas.

#### Opci√≥n B: AWS SSO (Identity Center)

Si tu organizaci√≥n usa AWS SSO (recomendado para cuentas empresariales):

```bash
# Configurar perfil SSO
aws configure sso

# Ingresar:
# - SSO start URL: https://tu-organizacion.awsapps.com/start
# - SSO Region: us-east-2 (o tu regi√≥n)
# - Seleccionar cuenta y rol
# - CLI default region: us-east-2
# - CLI output format: json
# - Profile name: workshop-demo (o el nombre que prefieras)

# Iniciar sesi√≥n
aws sso login --profile workshop-demo

# Verificar configuraci√≥n
aws sts get-caller-identity --profile workshop-demo
```

**Nota:** Si usas SSO, deber√°s configurar la variable de entorno antes de cada comando:

```bash
# Linux/Mac
export AWS_PROFILE=workshop-demo

# Windows PowerShell
$env:AWS_PROFILE = "workshop-demo"

# Windows CMD
set AWS_PROFILE=workshop-demo
```

**Troubleshooting:**
- Si recibes "Unable to locate credentials", ejecuta `aws configure` o `aws sso login`
- Si usas SSO y el token expira, ejecuta `aws sso login --profile <tu-perfil>` nuevamente

### Paso 2: Verificar Email en Amazon SES

**Nota:** Aseg√∫rate de haber completado el Paso 1 antes de continuar.

El sistema env√≠a emails personalizados, por lo que necesitas verificar tu direcci√≥n de email:

```bash
# Verificar tu email (reemplaza con tu email real)
aws ses verify-email-identity --email-address tu-email@ejemplo.com --region us-east-2

# Si usas perfil SSO, agrega --profile:
aws ses verify-email-identity --email-address tu-email@ejemplo.com --region us-east-2 --profile workshop-demo

# Recibir√°s un email de verificaci√≥n. Haz clic en el enlace para confirmar.

# Verificar estado de verificaci√≥n
aws ses get-identity-verification-attributes \
  --identities tu-email@ejemplo.com \
  --region us-east-2

# Con perfil espec√≠fico:
aws ses get-identity-verification-attributes \
  --identities tu-email@ejemplo.com \
  --region us-east-2 \
  --profile workshop-demo
```

**Importante:** Si tu cuenta de AWS est√° en el **SES Sandbox** (cuentas nuevas), solo podr√°s enviar emails a direcciones verificadas. Para enviar a cualquier direcci√≥n, solicita salir del sandbox:

1. Consola AWS ‚Üí Amazon SES ‚Üí Account dashboard
2. Haz clic en **Request production access**
3. Completa el formulario (toma ~24 horas)

Para el workshop, puedes quedarte en sandbox y usar solo emails verificados.

### Paso 3: Instalar Dependencias

```bash
# Navegar al directorio CDK
cd cdk

# Instalar dependencias de Node.js
npm install

# Verificar instalaci√≥n de CDK
cdk --version
# Esperado: 2.x.x o superior
```

### Paso 4: Bootstrap CDK (Solo Primera Vez)

Si es la primera vez que usas CDK en esta cuenta/regi√≥n:

```bash
# Bootstrap CDK
cdk bootstrap

# Si usas perfil espec√≠fico:
cdk bootstrap --profile workshop-demo

# Esto crea recursos necesarios para CDK (bucket S3, roles IAM, etc.)
```

### Paso 5: Desplegar Todos los Stacks

Tienes tres opciones para desplegar:

#### Opci√≥n A: Usar el Script de Despliegue (Recomendado para Windows)

```powershell
# Windows PowerShell
cd cdk
.\deploy.ps1
```

**Nota:** El script [`deploy.ps1`](cdk/deploy.ps1) est√° configurado con un perfil espec√≠fico. Ed√≠talo si usas un perfil diferente:

```powershell
# Editar deploy.ps1 y cambiar esta l√≠nea:
$env:AWS_PROFILE = "tu-perfil-aqui"
```

#### Opci√≥n B: Comando CDK Directo

```bash
# Linux/Mac
cd cdk
export AWS_PROFILE=workshop-demo  # Si usas perfil espec√≠fico
cdk deploy --all --require-approval never

# Windows PowerShell
cd cdk
$env:AWS_PROFILE = "workshop-demo"  # Si usas perfil espec√≠fico
cdk deploy --all --require-approval never

# Windows CMD
cd cdk
set AWS_PROFILE=workshop-demo
cdk deploy --all --require-approval never
```

#### Opci√≥n C: Desplegar con Prefijo Personalizado

Si quieres usar un prefijo diferente a 'demo':

```bash
# Con contexto CDK
cdk deploy --all --require-approval never -c participantPrefix=instructor

# O configurar variable de entorno
export PARTICIPANT_PREFIX=instructor
cdk deploy --all --require-approval never
```

### Paso 6: Verificar Despliegue

El despliegue completo toma aproximadamente **25-35 minutos** (el LegacyStack con Aurora puede tomar 15-20 minutos solo). Verifica que todos los stacks se desplegaron correctamente:

```bash
# Listar todos los stacks
aws cloudformation list-stacks \
  --stack-status-filter CREATE_COMPLETE \
  --query 'StackSummaries[?contains(StackName, `Stack`)].StackName'

# Deber√≠as ver 6 stacks:
# - demo-MedicalReportsLegacyStack (o tu-prefijo-MedicalReportsLegacyStack)
# - demo-AIExtractionStack
# - demo-AIRAGStack
# - demo-AIClassificationStack
# - demo-AISummaryStack
# - demo-AIEmailStack
```

### Paso 7: Obtener Informaci√≥n de Despliegue

Guarda esta informaci√≥n para usarla durante el workshop:

```bash
# Obtener URL del API Gateway
aws cloudformation describe-stacks \
  --stack-name demo-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`ApiUrl`].OutputValue' \
  --output text

# Obtener nombre del bucket S3
aws cloudformation describe-stacks \
  --stack-name demo-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`BucketName`].OutputValue' \
  --output text

# Obtener endpoint de Aurora
aws cloudformation describe-stacks \
  --stack-name demo-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`DatabaseEndpoint`].OutputValue' \
  --output text
```

### Paso 8: Inicializar Base de Datos (Opcional)

Si quieres tener datos de ejemplo pre-cargados:

```bash
# Obtener endpoint de Aurora
DB_ENDPOINT=$(aws cloudformation describe-stacks \
  --stack-name demo-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`DatabaseEndpoint`].OutputValue' \
  --output text)

# Conectar a la base de datos
psql -h $DB_ENDPOINT -U postgres -d medical_reports

# Ejecutar scripts SQL
\i ../database/schema.sql
\i ../database/seed_data.sql
```

### Paso 9: Probar el Sistema

Verifica que todo funciona correctamente:

```bash
# 1. Subir un PDF de prueba
aws s3 cp sample_data/informe_alto_riesgo.pdf \
  s3://demo-medical-reports-<account-id>/external-reports/

# 2. Verificar logs de extracci√≥n
aws logs tail /aws/lambda/demo-extract-pdf --follow

# 3. Verificar que se guard√≥ en la base de datos
psql -h $DB_ENDPOINT -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM informes_medicos WHERE origen='EXTERNO';"
```

### Troubleshooting del Despliegue

#### Error: "ExpiredToken" o "InvalidClientTokenId"

**Causa:** Credenciales expiradas (com√∫n con SSO).

**Soluci√≥n:**
```bash
# Renovar sesi√≥n SSO
aws sso login --profile workshop-demo

# Reintentar despliegue
cdk deploy --all --require-approval never
```

#### Error: "Model access denied"

**Causa:** Permisos insuficientes para Bedrock.

**Soluci√≥n:** Verifica que tu usuario/rol tenga permisos `bedrock:InvokeModel`. Los modelos se habilitan autom√°ticamente en la primera invocaci√≥n.

#### Error: "Bucket already exists"

**Causa:** El prefijo 'demo' ya est√° en uso en tu cuenta.

**Soluci√≥n:** Usa un prefijo diferente:
```bash
cdk deploy --all -c participantPrefix=instructor
```

#### Error: "Insufficient permissions"

**Causa:** Tu usuario/rol no tiene permisos suficientes.

**Soluci√≥n:** Necesitas permisos de administrador o al menos:
- CloudFormation: Full access
- Lambda: Full access
- S3: Full access
- RDS: Full access
- IAM: Create roles and policies
- Bedrock: Full access
- SES: Full access

### Resumen del Despliegue

Una vez completados todos los pasos:

- ‚úÖ 6 stacks desplegados en CloudFormation
- ‚úÖ Modelos de Bedrock habilitados
- ‚úÖ Email verificado en SES
- ‚úÖ Base de datos Aurora con schema creado
- ‚úÖ Sistema probado con un PDF de ejemplo

**Tiempo total estimado:** 40-50 minutos (incluyendo esperas de despliegue - Aurora toma 15-20 min)

**Pr√≥ximos pasos:**
1. Preparar slides de presentaci√≥n
2. Preparar PDFs de ejemplo adicionales
3. Tener consola AWS abierta con CloudWatch Logs
4. Revisar el plan detallado del workshop (siguiente secci√≥n)

---

## ÔøΩ Fllujo del Workshop: Despu√©s del Despliegue

Este diagrama muestra qu√© sucede despu√©s de que los participantes despliegan sus stacks:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         FLUJO COMPLETO: DESPLIEGUE ‚Üí PR√ÅCTICA                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

M√ìDULO 0.5: Despliegue (8 min)
‚îú‚îÄ Participantes ejecutan: ./scripts/participant-deploy-ai.sh
‚îú‚îÄ Mientras despliega (5-8 min):
‚îÇ  ‚îú‚îÄ Instructor explica arquitectura de alto nivel
‚îÇ  ‚îú‚îÄ Discusi√≥n de casos de uso reales
‚îÇ  ‚îî‚îÄ Valor de negocio y ROI
‚îî‚îÄ Verificar que todos los stacks est√°n desplegados ‚úì

        ‚Üì

M√ìDULO 1: Primera Prueba del Sistema (25 min)
‚îú‚îÄ 1. Demo en Vivo del Instructor (10 min)
‚îÇ  ‚îú‚îÄ Subir PDF a S3
‚îÇ  ‚îú‚îÄ Mostrar logs en CloudWatch (tiempo real)
‚îÇ  ‚îî‚îÄ Verificar datos en Aurora
‚îÇ
‚îú‚îÄ 2. Explicar el C√≥digo (8 min)
‚îÇ  ‚îú‚îÄ Paso 1: Textract extrae texto
‚îÇ  ‚îú‚îÄ Paso 2: Bedrock estructura datos
‚îÇ  ‚îî‚îÄ Paso 3: Guardar en base de datos
‚îÇ
‚îî‚îÄ 3. Ejercicio Pr√°ctico (7 min)
   ‚îú‚îÄ Cada participante obtiene su bucket
   ‚îú‚îÄ Sube su propio PDF
   ‚îú‚îÄ Ve los logs en tiempo real
   ‚îî‚îÄ Confirma que funcion√≥ ‚úì

        ‚Üì

M√ìDULO 2: Prompt Engineering (30 min)
‚îî‚îÄ [Contin√∫a con mejora de prompts...]
```

### Puntos Clave para el Instructor

**Despu√©s del despliegue, el enfoque cambia de "configurar" a "usar":**

‚úÖ **Hacer:**
- Mostrar el sistema funcionando en tiempo real
- Narrar lo que est√° pasando paso a paso
- Que cada participante procese su primer PDF
- Celebrar los √©xitos
- Resolver problemas en vivo

‚ùå **No hacer:**
- Explicar detalles de infraestructura
- Entrar en configuraciones t√©cnicas
- Asumir que todos entienden sin ver
- Avanzar sin verificar que todos completaron

**Filosof√≠a:** "Ver para creer, hacer para aprender"

---

## üé¨ Scripts de M√≥dulos del D√≠a 1

Esta secci√≥n proporciona scripts detallados para cada m√≥dulo del D√≠a 1, con el lenguaje exacto que puedes usar y las explicaciones t√©cnicas clave.

### M√≥dulo 0: Introducci√≥n al Problema de Negocio (10 min)

**Objetivo:** Establecer el contexto de negocio y el valor de la automatizaci√≥n con IA.

**Script de Apertura:**

```
¬°Bienvenidos al workshop de Automatizaci√≥n de Informes M√©dicos con AWS y Amazon Bedrock!

Hoy vamos a resolver un problema real de negocio usando IA Generativa.

D√©jenme presentarles el caso...
```

**Presentaci√≥n del Problema (5 min):**

```
Tenemos una empresa de salud ocupacional que realiza ex√°menes m√©dicos 
a trabajadores de empresas contratistas: mineras, constructoras, etc.

[Mostrar slide o diagrama]

Su situaci√≥n actual:
‚Ä¢ Realizan 500+ ex√°menes m√©dicos por mes
‚Ä¢ Cada informe requiere trabajo manual:
  - Revisi√≥n por m√©dico: 10-15 minutos
  - Clasificaci√≥n de riesgo: BAJO, MEDIO o ALTO
  - Creaci√≥n de resumen ejecutivo: 5-10 minutos
  - Redacci√≥n de email personalizado: 5 minutos

[Pausa para que procesen]

Hagamos las matem√°ticas:
‚Ä¢ 20-30 minutos por informe √ó 500 informes = 125-208 horas/mes
‚Ä¢ A $50/hora de tiempo m√©dico = $6,250-10,400/mes
‚Ä¢ Eso es casi 1 m√©dico a tiempo completo solo procesando informes!

[Pausa]

Y hay m√°s problemas:
‚Ä¢ Inconsistencia en criterios entre m√©dicos
‚Ä¢ Retrasos en identificar casos cr√≠ticos
‚Ä¢ Res√∫menes de calidad variable
‚Ä¢ Proceso repetitivo y tedioso

¬øLes suena familiar? Muchas organizaciones tienen procesos similares.
```

**Presentaci√≥n de la Soluci√≥n (5 min):**

```
Hoy vamos a automatizar este proceso usando Amazon Bedrock.

[Mostrar arquitectura simple]

Nuestra soluci√≥n:
1. Clasificaci√≥n autom√°tica de riesgo usando few-shot learning
2. Generaci√≥n de res√∫menes ejecutivos con IA
3. Todo integrado con datos legacy en Aurora

El resultado:
‚Ä¢ Tiempo: 20-30 min ‚Üí 2 minutos por informe (87-92% reducci√≥n)
‚Ä¢ Costo: $6,250-10,400/mes ‚Üí $800/mes
‚Ä¢ Consistencia: 100% en criterios
‚Ä¢ Identificaci√≥n inmediata de casos cr√≠ticos

[Pausa para preguntas]

Y lo mejor: No necesitamos entrenar un modelo custom. Usaremos t√©cnicas 
como few-shot learning y RAG que veremos hoy.

¬øListos para empezar?
```

**Transici√≥n al Setup:**

```
Perfecto. Vamos a empezar desplegando la infraestructura de IA.
El instructor ya despleg√≥ la base de datos y la app web antes del workshop.
Ustedes solo necesitan desplegar 2 stacks de IA, toma 3-5 minutos.

Mientras despliega, les voy a explicar la arquitectura...
```

---

### M√≥dulo 1: Clasificaci√≥n Autom√°tica de Riesgo (30 min)

**Objetivo:** Ense√±ar few-shot learning y RAG mediante clasificaci√≥n de informes m√©dicos.

#### Parte 1: Introducci√≥n al M√≥dulo (2 min)

**Script:**

```
Ahora vamos a ver la primera capacidad: clasificaci√≥n autom√°tica de riesgo.

El problema: Un m√©dico debe revisar cada informe y decidir si es riesgo 
BAJO, MEDIO o ALTO. Esto toma 10-15 minutos por informe.

La soluci√≥n: Amazon Bedrock puede hacer esto en 30 segundos con consistencia 
del 100%.

¬øC√≥mo? Con dos t√©cnicas clave:
1. Few-shot learning: Ense√±ar al modelo con solo 3 ejemplos
2. RAG: Buscar informes anteriores del mismo trabajador para contexto

Vamos a verlo en acci√≥n.
```

#### Parte 2: Demo en Vivo - Clasificar un Informe (8 min)

**Script mientras ejecutas comandos:**

```
[Ejecutar comando para ver datos en Aurora]

Primero, veamos los datos que tenemos. Estos son informes m√©dicos reales 
con presi√≥n arterial, peso, altura, antecedentes...

[Mostrar output]

Observen que algunos tienen nivel_riesgo NULL - no est√°n clasificados a√∫n.

[Ejecutar comando classify-risk]

Ahora voy a clasificar el informe ID 1. Observen que solo paso el ID del informe.

[Mientras ejecuta, explicar]

Detr√°s de escena, la Lambda est√°:
1. Buscando informes anteriores del mismo trabajador (RAG)
2. Cargando el prompt con ejemplos (few-shot learning)
3. Llamando a Bedrock Nova Pro
4. Guardando el resultado en Aurora

[Mostrar resultado]

¬°Listo! En 2-3 segundos clasific√≥ el informe como ALTO riesgo.
Lean la justificaci√≥n... tiene sentido m√©dicamente, ¬øverdad?

[Abrir CloudWatch Logs]

Ahora veamos qu√© pas√≥ internamente...
```

**Explicaci√≥n de Logs (mientras los muestras):**

```
[Se√±alar en los logs]

Aqu√≠ ven:
‚Ä¢ "RAG: Retrieved 2 previous reports" - Encontr√≥ informes anteriores
‚Ä¢ "Few-shot examples loaded: 3 examples" - Carg√≥ los ejemplos
‚Ä¢ "Invoking Bedrock" - Llam√≥ a la IA
‚Ä¢ "Classification result: ALTO" - Resultado

Todo esto en 2.3 segundos. Un m√©dico tomar√≠a 10-15 minutos.
```

#### Parte 3: Explicar Few-Shot Learning (5 min)

**Script:**

```
Ahora, la pregunta clave: ¬øC√≥mo sabe Bedrock clasificar informes m√©dicos?

No entrenamos un modelo custom. Usamos "few-shot learning".

[Mostrar el prompt]

Miren este prompt. Tiene 3 secciones importantes:

1. CRITERIOS:
   - BAJO: Par√°metros normales
   - MEDIO: Par√°metros lim√≠trofes  
   - ALTO: Par√°metros alterados

2. EJEMPLOS (esto es few-shot learning):
   [Leer un ejemplo]
   
   "Presi√≥n: 118/75, IMC: 23.5, sin antecedentes ‚Üí BAJO"
   
   Solo con 3 ejemplos, el modelo aprende el patr√≥n.

3. CONTEXTO HIST√ìRICO (esto es RAG):
   "Informes anteriores: Presi√≥n 140/88 hace 6 meses..."
   
   Esto le da contexto para detectar tendencias.

[Pausa]

Ventajas de few-shot learning:
‚Ä¢ No requiere entrenar un modelo (ahorra tiempo y dinero)
‚Ä¢ F√°cil de actualizar (solo editas el prompt)
‚Ä¢ Resultados inmediatos

¬øPreguntas sobre few-shot learning?
```

#### Parte 4: Explicar RAG (5 min)

**Script:**

```
Ahora hablemos de RAG - Retrieval-Augmented Generation.

RAG = Buscar informaci√≥n relevante + Agregar al prompt + Generar respuesta

[Mostrar c√≥digo de la Lambda]

Miren esta funci√≥n: buscar_informes_similares()

[Leer el SQL]

SELECT * FROM informes_medicos 
WHERE trabajador_id = :id 
ORDER BY fecha_examen DESC 
LIMIT 3

Simple, ¬øverdad? Busca los √∫ltimos 3 informes del mismo trabajador.

[Mostrar ejemplo de contexto hist√≥rico]

Luego agrega esto al prompt:
"CONTEXTO HIST√ìRICO:
- 2024-06-15: Presi√≥n 140/88, Riesgo MEDIO
- 2024-03-10: Presi√≥n 135/85, Riesgo MEDIO"

Ahora cuando ve el informe actual con presi√≥n 165/102, puede decir:
"Se observa deterioro progresivo ‚Üí ALTO riesgo"

[Pausa]

Ventajas de RAG:
‚Ä¢ Reduce alucinaciones (no inventa datos)
‚Ä¢ Proporciona contexto espec√≠fico
‚Ä¢ Permite detectar tendencias

En el D√≠a 2 veremos RAG avanzado con b√∫squeda vectorial.
Hoy usamos SQL simple, pero funciona muy bien.

¬øPreguntas sobre RAG?
```

#### Parte 5: Hands-On - Participantes Clasifican (10 min)

**Script:**

```
Perfecto. Ahora es su turno.

Tarea:
1. Abran su App Web (ya tienen la URL)
2. Seleccionen un informe sin clasificar
3. Hagan clic en "Clasificar con IA"
4. Observen el resultado

[Dar 5 minutos]

Mientras trabajan, estoy disponible para preguntas en el chat.

[Despu√©s de 5 minutos]

¬øQui√©n quiere compartir su resultado? ¬øQu√© nivel de riesgo obtuvieron?

[Escuchar 2-3 respuestas]

Excelente. Noten que:
‚Ä¢ Los resultados tienen sentido m√©dicamente
‚Ä¢ La justificaci√≥n es clara y detallada
‚Ä¢ Fue instant√°neo (2-3 segundos)

Ahora clasifiquen 2-3 informes m√°s para que vean diferentes niveles de riesgo.

[Dar 3 minutos m√°s]
```

**Cierre del M√≥dulo 1:**

```
Perfecto. Recapitulemos lo que aprendimos:

‚úì Few-shot learning: Ense√±ar al modelo con pocos ejemplos
‚úì RAG: Buscar contexto relevante para mejorar respuestas
‚úì Temperature baja (0.1): Para precisi√≥n y consistencia
‚úì Valor de negocio: 10-15 min ‚Üí 30 segundos por informe

En el siguiente m√≥dulo vamos a generar res√∫menes ejecutivos.
Ah√≠ veremos c√≥mo ajustar par√°metros para diferentes casos de uso.

¬øPreguntas antes de continuar?
```

---

### M√≥dulo 2: Generaci√≥n de Res√∫menes Ejecutivos (30 min)

**Objetivo:** Ense√±ar ajuste de par√°metros (temperature, maxTokens) y prompt engineering.

#### Parte 1: Introducci√≥n al M√≥dulo (2 min)

**Script:**

```
Ahora el segundo desaf√≠o: res√∫menes ejecutivos.

El problema: Los gerentes de empresas clientes NO leen informes m√©dicos 
completos de 5-10 p√°ginas. Necesitan res√∫menes de 2-3 p√°rrafos.

Crear estos res√∫menes manualmente toma 5-10 minutos por informe.

La soluci√≥n: Bedrock puede generar res√∫menes en 15 segundos.

Pero aqu√≠ hay un detalle importante: Los par√°metros que usamos para 
clasificaci√≥n NO funcionan bien para res√∫menes.

¬øPor qu√©? Porque son casos de uso diferentes.

Vamos a ver la diferencia.
```

#### Parte 2: Demo - Generar Resumen (5 min)

**Script:**

```
[Ejecutar comando generate-summary]

Voy a generar un resumen del informe que clasificamos.

[Mostrar resultado]

Lean este resumen... 

[Leer en voz alta el primer p√°rrafo]

Noten:
‚Ä¢ Lenguaje claro, NO t√©cnico (para gerentes, no m√©dicos)
‚Ä¢ Menciona el nivel de riesgo
‚Ä¢ Incluye acciones recomendadas
‚Ä¢ Tiene ~100-150 palabras (conciso pero completo)

[Si hay contexto hist√≥rico]

Y miren esto: "Comparado con su examen anterior hace 6 meses..."

Eso es RAG en acci√≥n. Agreg√≥ tendencias hist√≥ricas autom√°ticamente.

[Mostrar logs]

Tiempo de procesamiento: 1.8 segundos.
Un m√©dico tomar√≠a 5-10 minutos escribiendo esto.
```

#### Parte 3: Explicar Temperature (8 min)

**Script:**

```
Ahora la pregunta clave: ¬øPor qu√© este resumen suena m√°s natural que 
la clasificaci√≥n?

La respuesta: Temperature.

[Mostrar tabla comparativa]

Temperature controla la "creatividad" del modelo.

Escala:
0.0 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0.5 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1.0
Preciso    Balance    Creativo

Para clasificaci√≥n usamos 0.1 (muy preciso):
‚Ä¢ Mismo input ‚Üí mismo output
‚Ä¢ Consistencia 100%
‚Ä¢ Lenguaje t√©cnico y directo

Para res√∫menes usamos 0.5 (balanceado):
‚Ä¢ Mismo input ‚Üí variaciones naturales
‚Ä¢ Mantiene precisi√≥n pero con fluidez
‚Ä¢ Lenguaje m√°s humano

[Mostrar ejemplos]

Temperature 0.1 (Clasificaci√≥n):
"ALTO - Hipertensi√≥n severa requiere atenci√≥n inmediata"
[Ejecutar 3 veces, mismo resultado]

Temperature 0.5 (Resumen):
"El trabajador presenta hipertensi√≥n severa..."
"Se detecta presi√≥n arterial elevada..."
"Los par√°metros indican hipertensi√≥n grado 2..."
[Variaciones naturales pero mismo mensaje]

[Pausa]

¬øCu√°ndo usar cada valor?

Temperature 0.1-0.2: Clasificaci√≥n, extracci√≥n, decisiones
Temperature 0.5-0.6: Res√∫menes, an√°lisis, reportes
Temperature 0.7-0.8: Emails, contenido creativo
Temperature 0.9-1.0: Brainstorming, ideas

No hay un valor "correcto" universal. Depende del caso de uso.

¬øPreguntas sobre temperature?
```

#### Parte 4: Explicar maxTokens (5 min)

**Script:**

```
El segundo par√°metro importante: maxTokens.

maxTokens limita la longitud de la respuesta.

Conversi√≥n aproximada:
‚Ä¢ 100 tokens ‚âà 75 palabras ‚âà 1 p√°rrafo corto
‚Ä¢ 300 tokens ‚âà 225 palabras ‚âà 2-3 p√°rrafos
‚Ä¢ 1000 tokens ‚âà 750 palabras ‚âà 1 p√°gina

[Mostrar tabla]

Para clasificaci√≥n: 1000 tokens
‚Ä¢ Permite justificaci√≥n detallada (~500 palabras)

Para res√∫menes: 300 tokens
‚Ä¢ Fuerza concisi√≥n (~150 palabras)

[Pausa]

Pero maxTokens no solo limita, tambi√©n GU√çA al modelo.

Si le dices "m√°ximo 300 tokens", el modelo ajusta su estilo para 
ser m√°s conciso desde el principio.

[Mostrar ejemplo]

Con maxTokens 1000:
"El trabajador presenta m√∫ltiples factores de riesgo cardiovascular 
que requieren evaluaci√≥n m√©dica inmediata. Se detecta hipertensi√≥n 
arterial severa con valores de 165/102 mmHg que superan 
significativamente los par√°metros normales establecidos en 120/80 mmHg..."
[Contin√∫a con mucho detalle]

Con maxTokens 300:
"El trabajador presenta hipertensi√≥n severa y obesidad. Se recomienda 
restricci√≥n de actividades de riesgo y evaluaci√≥n m√©dica urgente."
[Directo al punto]

¬øVen la diferencia? No es solo m√°s corto, es m√°s conciso desde el inicio.

¬øPreguntas sobre maxTokens?
```

#### Parte 5: Hands-On - Participantes Generan Res√∫menes (10 min)

**Script:**

```
Excelente. Ahora practiquen ustedes.

Tarea:
1. Abran su App Web
2. Seleccionen un informe YA CLASIFICADO (importante!)
3. Hagan clic en "Generar Resumen"
4. Lean el resumen y verifiquen:
   - ¬øEs claro y no t√©cnico?
   - ¬øMenciona el nivel de riesgo?
   - ¬øTiene ~100-150 palabras?

[Dar 5 minutos]

[Despu√©s de 5 minutos]

¬øAlguien quiere compartir su resumen? ¬øQu√© les pareci√≥ la calidad?

[Escuchar 2-3 respuestas]

Ahora generen 2-3 res√∫menes m√°s. Intenten con diferentes niveles de riesgo.
¬øNotan diferencia en el tono entre BAJO, MEDIO y ALTO?

[Dar 3 minutos m√°s]
```

**Cierre del M√≥dulo 2:**

```
Perfecto. Recapitulemos:

‚úì Temperature: Ajustar seg√∫n caso de uso (0.1 preciso, 0.5 balance, 0.7 creativo)
‚úì maxTokens: Limita y gu√≠a la longitud de respuesta
‚úì Prompt engineering: Especificar audiencia, formato, restricciones
‚úì Valor de negocio: 5-10 min ‚Üí 15 segundos por resumen

Ahora tienen las herramientas para ajustar Bedrock seg√∫n sus necesidades.

Vamos al checkpoint final para calcular el ROI total.
```

---

### Checkpoint: ROI y Reflexi√≥n (10 min)

**Objetivo:** Consolidar aprendizaje y mostrar valor de negocio.

#### Parte 1: Verificaci√≥n (2 min)

**Script:**

```
Antes de calcular el ROI, verifiquemos que todos completaron las actividades.

Levanten la mano (o reaccionen en el chat) si:
‚Ä¢ Tienen al menos 3 informes clasificados ‚úã
‚Ä¢ Tienen al menos 3 res√∫menes generados ‚úã
‚Ä¢ Entienden la diferencia entre temperature 0.1 y 0.5 ‚úã

[Esperar respuestas]

Excelente. Si alguien necesita ayuda, escr√≠banme en privado y lo resolvemos 
en el tiempo de buffer.
```

#### Parte 2: C√°lculo de ROI (5 min)

**Script:**

```
Ahora lo m√°s importante: ¬øCu√°l es el impacto real de esta automatizaci√≥n?

[Mostrar tabla comparativa]

PROCESO MANUAL (ANTES):
Por cada informe:
‚Ä¢ Revisi√≥n y clasificaci√≥n: 10-15 min
‚Ä¢ Creaci√≥n de resumen: 5-10 min
‚Ä¢ Total: 15-25 min por informe

Con 500 informes/mes:
‚Ä¢ Tiempo: 125-208 horas/mes
‚Ä¢ Costo: $6,250-10,400/mes (a $50/hora m√©dico)

[Pausa para que procesen]

PROCESO AUTOMATIZADO (AHORA):
Por cada informe:
‚Ä¢ Clasificaci√≥n autom√°tica: 30 segundos
‚Ä¢ Generaci√≥n de resumen: 15 segundos
‚Ä¢ Revisi√≥n m√©dica (solo ALTO riesgo): 5 min
‚Ä¢ Total: ~1 min + revisi√≥n de cr√≠ticos

Con 500 informes/mes (20% ALTO riesgo):
‚Ä¢ Tiempo: 8 horas clasificaci√≥n + 8 horas revisi√≥n = 16 horas/mes
‚Ä¢ Costo: $800/mes

[Mostrar el ahorro]

AHORRO:
‚Ä¢ Tiempo: 125-208 horas ‚Üí 16 horas (87-92% reducci√≥n!)
‚Ä¢ Costo: $6,250-10,400 ‚Üí $800 (87-92% ahorro!)
‚Ä¢ Eso es $5,450-9,600/mes de ahorro

[Pausa]

Y los beneficios adicionales:
‚úì Identificaci√≥n inmediata de casos cr√≠ticos
‚úì Consistencia 100% en criterios
‚úì Res√∫menes profesionales y estandarizados
‚úì Tendencias hist√≥ricas autom√°ticas

[Pausa]

Piensen en sus propias organizaciones: ¬øQu√© procesos repetitivos tienen 
que podr√≠an automatizar con este patr√≥n?
```

#### Parte 3: Preguntas de Reflexi√≥n (3 min)

**Script:**

```
Antes de terminar, algunas preguntas para reflexionar:

T√©cnicas:
‚Ä¢ ¬øPor qu√© usamos temperature 0.1 para clasificaci√≥n y 0.5 para res√∫menes?
‚Ä¢ ¬øC√≥mo ayuda RAG a mejorar la precisi√≥n?
‚Ä¢ ¬øQu√© hace que un prompt sea efectivo?

[Esperar 2-3 respuestas]

De negocio:
‚Ä¢ ¬øQu√© otros procesos en su organizaci√≥n podr√≠an automatizarse as√≠?
‚Ä¢ ¬øC√≥mo medir√≠an el √©xito de esta automatizaci√≥n?
‚Ä¢ ¬øQu√© riesgos ven en automatizar decisiones m√©dicas?

[Esperar 2-3 respuestas]

Excelentes reflexiones. Estas son las preguntas que deben hacerse al 
implementar IA en producci√≥n.
```

**Cierre del D√≠a 1:**

```
¬°Felicitaciones! Completaron el D√≠a 1 del workshop.

Hoy aprendieron:
‚úì Few-shot learning para clasificaci√≥n
‚úì RAG para agregar contexto
‚úì Ajuste de par√°metros (temperature, maxTokens)
‚úì Prompt engineering efectivo
‚úì C√°lculo de ROI de automatizaci√≥n con IA

Ma√±ana en el D√≠a 2 veremos:
‚Ä¢ Emails personalizados seg√∫n nivel de riesgo
‚Ä¢ RAG avanzado con embeddings vectoriales
‚Ä¢ Integraci√≥n de PDFs externos con Textract
‚Ä¢ Experimentaci√≥n libre

Nos vemos ma√±ana. ¬°Excelente trabajo!
```

---

## üõ†Ô∏è Troubleshooting Durante el D√≠a 1

Esta secci√≥n cubre los problemas m√°s comunes que encontrar√°s durante el D√≠a 1 y c√≥mo resolverlos r√°pidamente.

### Problema 1: "Lambda not found" durante clasificaci√≥n

**S√≠ntomas:**
- Participante ejecuta `aws lambda invoke --function-name participant-X-classify-risk` y recibe error "Function not found"

**Causas comunes:**
1. Prefijo incorrecto (us√≥ participant-1 pero es participant-2)
2. AI Stacks no se desplegaron correctamente
3. Regi√≥n incorrecta

**Soluci√≥n r√°pida:**

```
[En el chat]
Verifica tu prefijo. ¬øUsaste participant-X donde X es tu n√∫mero asignado?

Ejecuta este comando para ver tus Lambdas:
aws lambda list-functions --query 'Functions[?contains(FunctionName, `participant-X`)].FunctionName'

Si no aparecen, re-despliega:
cd cdk
npx cdk deploy participant-X-AIClassificationStack participant-X-AISummaryStack --require-approval never
```

**Prevenci√≥n:**
- Al inicio del workshop, pide a todos que verifiquen su prefijo
- Comparte un comando de verificaci√≥n en el chat

---

### Problema 2: "Access denied to Aurora" al clasificar

**S√≠ntomas:**
- Lambda se ejecuta pero falla con error de conexi√≥n a base de datos
- Logs muestran "Database connection failed"

**Causas comunes:**
1. LegacyStack no se despleg√≥ correctamente (responsabilidad del instructor)
2. Security groups mal configurados
3. Lambda no est√° en la VPC correcta

**Soluci√≥n r√°pida:**

```
[Verificar en tu consola]
1. Abre CloudFormation
2. Busca participant-X-MedicalReportsLegacyStack
3. Verifica que est√° en estado CREATE_COMPLETE

Si no existe o fall√≥:
[Ejecutar en tu terminal]
./scripts/instructor-deploy-legacy.ps1 participant-X

[Informar al participante]
"Estoy re-desplegando tu LegacyStack. Toma 15 minutos. 
Mientras tanto, puedes seguir con la explicaci√≥n te√≥rica."
```

**Prevenci√≥n:**
- Despliega todos los LegacyStacks ANTES del workshop
- Verifica que todos est√°n en CREATE_COMPLETE antes de empezar

---

### Problema 3: "Bedrock access denied"

**S√≠ntomas:**
- Lambda se ejecuta pero falla al llamar a Bedrock
- Error: "Model access denied" o "AccessDeniedException"

**Causas comunes:**
1. Modelo Nova Pro no habilitado en la cuenta
2. Regi√≥n incorrecta
3. Permisos IAM insuficientes

**Soluci√≥n r√°pida:**

```
[Verificar en tu consola]
1. Abre Bedrock console
2. Ve a "Model access"
3. Verifica que "Amazon Nova Pro" est√° habilitado

Si no est√° habilitado:
1. Click en "Manage model access"
2. Selecciona "Amazon Nova Pro"
3. Click "Save changes"
4. Espera 2-3 minutos

[Informar al participante]
"Estoy habilitando el modelo. Toma 2-3 minutos. Reintenta en un momento."
```

**Prevenci√≥n:**
- Habilita todos los modelos necesarios ANTES del workshop
- Verifica acceso con un comando de prueba

---

### Problema 4: Logs no aparecen en CloudWatch

**S√≠ntomas:**
- Participante ejecuta `aws logs tail` pero no ve output
- Dice "No log groups found"

**Causas comunes:**
1. Lambda no se ha ejecutado a√∫n (logs no existen)
2. Nombre del log group incorrecto
3. Logs tardan 1-2 minutos en aparecer

**Soluci√≥n r√°pida:**

```
[En el chat]
Los logs pueden tardar 1-2 minutos en aparecer despu√©s de invocar la Lambda.

Primero, verifica que la Lambda se ejecut√≥:
aws lambda invoke --function-name participant-X-classify-risk --payload '{"informe_id": 1}' response.json

Luego espera 1 minuto y reintenta:
aws logs tail /aws/lambda/participant-X-classify-risk --since 5m
```

**Prevenci√≥n:**
- Explica al inicio que los logs tardan 1-2 minutos
- Muestra primero el resultado JSON, luego los logs

---

### Problema 5: App Web no carga o muestra error 403

**S√≠ntomas:**
- Participante abre la URL de la app web y ve error 403 o p√°gina en blanco

**Causas comunes:**
1. URL incorrecta
2. S3 bucket no configurado correctamente
3. API Gateway URL no inyectada

**Soluci√≥n r√°pida:**

```
[Pedir al participante que ejecute]
aws cloudformation describe-stacks \
  --stack-name participant-X-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`WebsiteURL`].OutputValue' \
  --output text

[Verificar que la URL es correcta]
Debe ser algo como: http://participant-X-medical-reports-XXXXX.s3-website.us-east-2.amazonaws.com

Si el problema persiste:
[En tu consola, re-desplegar LegacyStack]
```

**Prevenci√≥n:**
- Comparte las URLs de las apps web al inicio del workshop
- Verifica que todas cargan antes de empezar

---

### Problema 6: "Informe not classified" al generar resumen

**S√≠ntomas:**
- Participante intenta generar resumen pero recibe error
- Error: "El informe debe ser clasificado primero"

**Causas comunes:**
1. Intent√≥ generar resumen antes de clasificar
2. Clasificaci√≥n fall√≥ silenciosamente

**Soluci√≥n r√°pida:**

```
[En el chat]
Recuerda: Primero debes CLASIFICAR el informe, luego generar el resumen.

Paso 1 - Clasificar:
aws lambda invoke --function-name participant-X-classify-risk --payload '{"informe_id": 1}' response.json

Paso 2 - Verificar:
cat response.json
(Debe mostrar nivel_riesgo: BAJO/MEDIO/ALTO)

Paso 3 - Generar resumen:
aws lambda invoke --function-name participant-X-generate-summary --payload '{"informe_id": 1}' summary.json
```

**Prevenci√≥n:**
- Explica claramente el flujo: clasificar ‚Üí resumen
- Muestra el flujo visualmente en un diagrama

---

### Problema 7: Comandos de CloudShell no funcionan

**S√≠ntomas:**
- Participante copia comandos pero recibe errores de sintaxis
- Variables de entorno no definidas

**Causas comunes:**
1. No defini√≥ variables CLUSTER_ARN y SECRET_ARN
2. Copi√≥ comandos incorrectamente (espacios extra, saltos de l√≠nea)
3. Us√≥ PowerShell en lugar de Bash

**Soluci√≥n r√°pida:**

```
[En el chat]
CloudShell usa Bash. Aseg√∫rate de definir las variables primero:

CLUSTER_ARN=$(aws cloudformation describe-stacks \
  --stack-name participant-X-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`ClusterArn`].OutputValue' \
  --output text)

SECRET_ARN=$(aws cloudformation describe-stacks \
  --stack-name participant-X-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`SecretArn`].OutputValue' \
  --output text)

Verifica que tienen valores:
echo $CLUSTER_ARN
echo $SECRET_ARN
```

**Prevenci√≥n:**
- Comparte los comandos en un archivo de texto
- Explica que deben definir variables al inicio

---

### Estrategias Generales de Troubleshooting

#### Cuando m√∫ltiples participantes tienen el mismo problema:

1. **Pausa el workshop**
   ```
   "Veo que varios tienen el mismo problema. Vamos a resolverlo juntos."
   ```

2. **Comparte tu pantalla**
   - Muestra c√≥mo diagnosticar el problema
   - Ejecuta los comandos de verificaci√≥n
   - Explica qu√© est√°s buscando

3. **Proporciona soluci√≥n en el chat**
   - Comandos exactos para copiar/pegar
   - Explicaci√≥n breve de qu√© hace cada comando

4. **Verifica que se resolvi√≥**
   ```
   "¬øQui√©n ya lo resolvi√≥? Reaccionen con ‚úÖ"
   ```

#### Cuando un participante individual tiene un problema √∫nico:

1. **No detengas el workshop**
   ```
   "Juan, veo tu problema. Te ayudo en privado mientras continuamos."
   ```

2. **Usa chat privado o breakout room**
   - Diagnostica el problema espec√≠fico
   - Proporciona soluci√≥n personalizada

3. **Documenta el problema**
   - Anota para mejorar el workshop
   - Comparte la soluci√≥n si es relevante para otros

#### Cuando no puedes resolver un problema r√°pidamente:

1. **Usa tu cuenta de demostraci√≥n**
   ```
   "Mientras resolvemos tu problema, sigue con mi pantalla para no perderte el contenido."
   ```

2. **Programa ayuda para el buffer time**
   ```
   "Lo resolveremos en los pr√≥ximos 45 minutos de tiempo libre."
   ```

3. **Proporciona alternativa**
   - Acceso a tu app web de demostraci√≥n
   - Pairing con otro participante

---

### Comandos de Verificaci√≥n R√°pida

Comparte estos comandos al inicio del workshop para que los participantes puedan auto-diagnosticar:

```bash
# Verificar autenticaci√≥n AWS
aws sts get-caller-identity

# Verificar regi√≥n
aws configure get region

# Listar tus stacks
aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE --query 'StackSummaries[?contains(StackName, `participant-X`)].StackName'

# Listar tus Lambdas
aws lambda list-functions --query 'Functions[?contains(FunctionName, `participant-X`)].FunctionName'

# Verificar acceso a Bedrock
aws bedrock list-foundation-models --region us-east-2 --query 'modelSummaries[?contains(modelId, `nova-pro`)].modelId'

# Ver outputs de tu LegacyStack
aws cloudformation describe-stacks --stack-name participant-X-MedicalReportsLegacyStack --query 'Stacks[0].Outputs'
```

---

## üìÖ Plan Detallado del Workshop

### D√≠a 1: Fundamentos y Extracci√≥n (1h 15min)

#### M√≥dulo 0: Introducci√≥n y Setup (5 min)

**Objetivos:**
- Dar bienvenida y contexto
- Verificar que todos tienen prerequisitos
- Explicar estructura del workshop

**Script:**

```
¬°Bienvenidos! En este workshop vamos a construir un sistema real de automatizaci√≥n
de informes m√©dicos usando servicios de AWS y Amazon Bedrock.

El caso de uso: Una empresa de salud ocupacional recibe informes m√©dicos en PDF
de diferentes cl√≠nicas. Necesitan:
1. Extraer datos autom√°ticamente
2. Clasificar el nivel de riesgo
3. Generar res√∫menes ejecutivos
4. Enviar notificaciones personalizadas

Vamos a resolver esto usando IA Generativa.

Antes de empezar, verifiquemos que todos tienen:
- AWS CLI configurado ‚úì
- CDK instalado ‚úì
- Acceso a Bedrock habilitado ‚úì
```

**Demostraci√≥n en vivo:**
1. Mostrar arquitectura completa en diagrama
2. Explicar flujo de datos
3. Mostrar resultado final (email recibido)

**Tiempo:** 5 minutos

---

#### M√≥dulo 0.5: Despliegue de AI Stacks (8 min)

**Objetivos:**
- Que todos los participantes inicien el despliegue
- Explicar la arquitectura de alto nivel (qu√© hace cada componente)
- Conectar con casos de uso reales
- Generar expectativa sobre lo que van a construir

**Script:**

```
Perfecto, ahora todos van a ejecutar este comando en CloudShell:

./scripts/participant-deploy-ai.sh participant-1 instructor@example.com

[Esperar a que todos ejecuten el comando]

Excelente. El despliegue tomar√° entre 5 y 8 minutos. Mientras tanto, 
d√©jenme mostrarles qu√© es lo que est√°n desplegando.
```

---

### Durante el Despliegue (5-8 min)

#### 1. Arquitectura de Alto Nivel (3 min)

**[Mostrar diagrama en pantalla compartida]**

```
Vamos a construir un sistema de automatizaci√≥n de documentos con 4 componentes principales:

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FLUJO DE AUTOMATIZACI√ìN                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. EXTRACCI√ìN üìÑ ‚Üí üìä
   PDF entra ‚Üí Textract lee el texto ‚Üí Bedrock lo estructura en datos
   
   ¬øPor qu√©? Porque Textract solo "lee", pero Bedrock "entiende"
   qu√© significa cada dato.

2. B√öSQUEDA INTELIGENTE üîç
   Embeddings vectoriales ‚Üí Buscar informes similares del pasado
   
   ¬øPor qu√©? Para darle contexto hist√≥rico al sistema. Como un m√©dico
   que revisa el historial antes de dar un diagn√≥stico.

3. CLASIFICACI√ìN üéØ
   Analiza datos + historial ‚Üí Clasifica riesgo (BAJO/MEDIO/ALTO)
   
   ¬øPor qu√©? Para priorizar autom√°ticamente qu√© casos necesitan
   atenci√≥n inmediata.

4. GENERACI√ìN DE CONTENIDO ‚úâÔ∏è
   Crea resumen ejecutivo + email personalizado seg√∫n el nivel de riesgo
   
   ¬øPor qu√©? Para comunicar autom√°ticamente a las personas correctas
   con el tono correcto.
```

**Diagrama Visual Simplificado:**

```
PDF ‚Üí [Textract] ‚Üí Texto ‚Üí [Bedrock] ‚Üí Datos Estructurados
                                              ‚Üì
                                         [Base de Datos]
                                              ‚Üì
                                    [Buscar Similares - RAG]
                                              ‚Üì
                                    [Clasificar Riesgo]
                                              ‚Üì
                              [Generar Resumen + Email]
                                              ‚Üì
                                    üìß Email Personalizado
```

**Puntos Clave a Enfatizar:**

```
Lo importante aqu√≠ no son los servicios espec√≠ficos, sino el PATR√ìN:

1. Extraer informaci√≥n no estructurada
2. Darle contexto con datos hist√≥ricos
3. Tomar decisiones inteligentes
4. Generar comunicaci√≥n personalizada

Este patr√≥n lo pueden aplicar a cualquier tipo de documento.
```

---

#### 2. Conectar con Casos de Uso Reales (2 min)

```
Ahora, pregunta para ustedes: ¬øQu√© documentos procesan manualmente 
en sus organizaciones que podr√≠an automatizar con este mismo patr√≥n?

[Escuchar respuestas - anotar en pantalla compartida si es posible]

Ejemplos comunes:
- Facturas: Extraer ‚Üí Validar contra historial ‚Üí Aprobar/Rechazar ‚Üí Notificar
- Contratos: Extraer ‚Üí Comparar con t√©rminos est√°ndar ‚Üí Clasificar riesgo ‚Üí Alertar
- Formularios RH: Extraer ‚Üí Verificar completitud ‚Üí Clasificar urgencia ‚Üí Asignar
- √ìrdenes de compra: Extraer ‚Üí Validar inventario ‚Üí Aprobar ‚Üí Confirmar

El patr√≥n es el mismo, solo cambian los datos y las reglas de negocio.
```

---

#### 3. Valor Tangible (1-2 min)

```
N√∫meros r√°pidos para que vean el impacto:

- Tiempo manual por documento: ~30 minutos
- Tiempo automatizado: ~2 minutos
- Costo: $2-5 USD por 1000 documentos
- Reducci√≥n de errores: 30-40%

Si procesan 100 documentos al mes:
‚Üí 50 horas recuperadas
‚Üí M√°s de una semana de trabajo
‚Üí Que su equipo puede usar en tareas de mayor valor
```

---

#### 4. Verificar Progreso y Preparar para M√≥dulo 1 (1 min)

```
[Revisar en pantalla compartida CloudFormation console]

Perfecto, veo que varios ya est√°n completando. Vamos a verificar 
que todos tengan sus 5 stacks desplegados:

- AIExtractionStack ‚úì
- AIRAGStack ‚úì
- AIClassificationStack ‚úì
- AISummaryStack ‚úì
- AIEmailStack ‚úì

Excelente. Ahora que tenemos todo desplegado, vamos a PROBAR el sistema.
Vamos a subir un PDF real y ver c√≥mo el sistema lo procesa autom√°ticamente.
```

**Instrucciones para Participantes:**

```
Antes de continuar, aseg√∫rense de tener a mano:

1. La consola de AWS abierta en otra pesta√±a
2. CloudWatch Logs listo para ver logs en tiempo real
3. El repositorio clonado en CloudShell

Vamos a hacer esto juntos paso a paso.
```

---

### Diagrama Sugerido para Mostrar (Crear en Slides)

**Opci√≥n 1: Diagrama de Flujo Simple**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PDF    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. EXTRACCI√ìN   ‚îÇ  ‚Üê Textract + Bedrock
‚îÇ  PDF ‚Üí Datos     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. CONTEXTO     ‚îÇ  ‚Üê Embeddings + RAG
‚îÇ  Buscar Similar  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. CLASIFICACI√ìN ‚îÇ  ‚Üê Bedrock + Few-Shot
‚îÇ BAJO/MEDIO/ALTO  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. COMUNICACI√ìN ‚îÇ  ‚Üê Bedrock + Prompts
‚îÇ  Resumen + Email ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  üìß Email ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Opci√≥n 2: Diagrama de Componentes (M√°s Visual)**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SISTEMA DE IA                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  üìÑ Documento  ‚Üí  üîç Extraer  ‚Üí  üíæ Guardar             ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  üíæ Historial  ‚Üí  üß† Analizar  ‚Üí  üéØ Clasificar         ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  üéØ Decisi√≥n   ‚Üí  ‚úçÔ∏è Redactar  ‚Üí  üìß Enviar             ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Servicios AWS:
üîç Amazon Textract + Bedrock
üíæ Aurora + pgvector
üß† Amazon Bedrock (RAG)
üéØ Amazon Bedrock (Clasificaci√≥n)
‚úçÔ∏è Amazon Bedrock (Generaci√≥n)
üìß Amazon SES
```

---

### Notas para el Instructor

**Preparaci√≥n:**
- Tener el diagrama listo en slides o en una herramienta de dibujo
- Practicar la explicaci√≥n para que sea fluida y no t√©cnica
- Tener ejemplos de casos de uso preparados por si nadie responde

**Tono:**
- Entusiasta pero no abrumador
- Enfocado en "qu√© hace" no en "c√≥mo lo hace"
- Usar analog√≠as simples (m√©dico con historial, etc.)

**Lo que S√ç mencionar:**
- ‚úÖ Qu√© hace cada componente (en t√©rminos de negocio)
- ‚úÖ Por qu√© cada paso es importante
- ‚úÖ C√≥mo se conecta con sus casos de uso
- ‚úÖ El patr√≥n reutilizable

**Lo que NO mencionar (a menos que pregunten):**
- ‚ùå VPCs, subnets, security groups
- ‚ùå Detalles de CloudFormation
- ‚ùå Configuraciones de Lambda
- ‚ùå ACUs de Aurora
- ‚ùå Cualquier detalle de infraestructura

**Tiempo:** 8 minutos

---

#### M√≥dulo 1: Extracci√≥n con Textract y Bedrock (25 min)

**Objetivos:**
- Ver el sistema funcionando en tiempo real
- Entender diferencia entre OCR y estructuraci√≥n
- Aprender c√≥mo Textract y Bedrock trabajan juntos
- Que cada participante procese su primer PDF

**Conceptos Clave:**

```
Textract = "Lee" el texto del PDF (como un esc√°ner inteligente)
Bedrock = "Entiende" qu√© significa cada dato (como un experto m√©dico)

Juntos convierten un PDF en datos estructurados.
```

---

### 1. Demostraci√≥n en Vivo del Instructor (10 min)

**Preparaci√≥n del Instructor:**
- Tener 3 ventanas visibles en pantalla compartida:
  - S3 Console (para subir PDF)
  - CloudWatch Logs (para ver procesamiento)
  - Aurora Query Editor o terminal con psql

**Script:**

```
Ahora voy a mostrarles el sistema en acci√≥n. Voy a subir un PDF 
y vamos a ver en tiempo real c√≥mo se procesa autom√°ticamente.

Presten atenci√≥n a los 3 pasos:
1. PDF entra a S3
2. Lambda procesa con Textract y Bedrock
3. Datos estructurados se guardan en Aurora
```

**Paso a Paso:**

**a) Subir PDF (2 min)**

```bash
# En CloudShell o terminal
aws s3 cp sample_data/informe_alto_riesgo.pdf \
  s3://demo-medical-reports-XXXXX/external-reports/

# Confirmar que se subi√≥
aws s3 ls s3://demo-medical-reports-XXXXX/external-reports/
```

**Narraci√≥n mientras subes:**
```
"Estoy subiendo un informe m√©dico de alto riesgo. En cuanto llegue a S3,
autom√°ticamente se va a disparar la Lambda de extracci√≥n..."
```

**b) Mostrar Logs en Tiempo Real (5 min)**

Abrir CloudWatch Logs ‚Üí `/aws/lambda/demo-extract-pdf` ‚Üí Click "Tail logs"

**Narrar lo que aparece:**

```
"Aqu√≠ vemos que la Lambda se activ√≥...

[Se√±alar en pantalla]
- Textract est√° extrayendo el texto del PDF
- Miren, aqu√≠ est√° el texto completo que extrajo
- Ahora Bedrock est√° estructurando esos datos
- Aqu√≠ est√° el prompt que le enviamos a Bedrock
- Y aqu√≠ est√° el JSON estructurado que nos devolvi√≥
- Finalmente, se est√° guardando en Aurora"
```

**Puntos a destacar en los logs:**
- Tiempo de procesamiento (~30-60 segundos)
- Texto extra√≠do por Textract
- Prompt enviado a Bedrock
- JSON estructurado recibido
- Confirmaci√≥n de inserci√≥n en base de datos

**c) Verificar Resultado en Base de Datos (3 min)**

```sql
-- Mostrar en Aurora Query Editor o psql
SELECT 
  trabajador_nombre,
  presion_arterial,
  nivel_riesgo,
  fecha_examen,
  fecha_creacion
FROM informes_medicos 
WHERE origen='EXTERNO'
ORDER BY fecha_creacion DESC
LIMIT 1;
```

**Narraci√≥n:**
```
"Y aqu√≠ est√° el resultado final. El PDF se convirti√≥ en datos estructurados
que podemos consultar, analizar y usar para tomar decisiones.

Esto que tom√≥ 1 minuto automatizado, manualmente tomar√≠a 30 minutos."
```

---

### 2. Explicar el C√≥digo (8 min)

**Script:**

```
Ahora que vieron c√≥mo funciona, d√©jenme mostrarles el c√≥digo 
que hace esto posible. No se preocupen por memorizar, solo 
entiendan la l√≥gica.
```

**Abrir en pantalla compartida:** `lambda/ai/extract_pdf/index.py`

**Explicar los 3 pasos clave:**

**Paso 1: Textract Extrae Texto (2 min)**

```python
# Textract lee el PDF
response = textract_client.analyze_document(
    Document={'S3Object': {'Bucket': bucket, 'Name': key}},
    FeatureTypes=['TABLES', 'FORMS']
)

# Convertir a texto plano
texto_extraido = extract_text_from_textract(response)
```

**Narraci√≥n:**
```
"Textract lee el PDF y extrae TODO el texto, incluyendo tablas.
Pero solo extrae, no entiende qu√© significa cada cosa."
```

**Paso 2: Bedrock Estructura Datos (4 min)**

```python
# Leer prompt desde archivo
with open('prompts/extraction.txt', 'r') as f:
    prompt_template = f.read()

# Construir prompt con el texto
prompt = prompt_template.replace('{texto}', texto_extraido)

# Invocar Bedrock
bedrock_response = bedrock_runtime.invoke_model(
    modelId='us.amazon.nova-pro-v1:0',
    body=json.dumps({
        "messages": [{"role": "user", "content": prompt}],
        "inferenceConfig": {
            "temperature": 0.1,  # Baja para precisi√≥n
            "maxTokens": 2000
        }
    })
)

# Parsear respuesta JSON
datos_estructurados = json.loads(response_body['output']['message']['content'][0]['text'])
```

**Narraci√≥n:**
```
"Aqu√≠ es donde la magia ocurre. Le decimos a Bedrock:
'Toma este texto y extrae estos campos espec√≠ficos en formato JSON'

Bedrock ENTIENDE el contexto y sabe que '140/90' es presi√≥n arterial,
no un n√∫mero de tel√©fono o una fecha."
```

**Paso 3: Guardar en Aurora (2 min)**

```python
# Insertar en base de datos
cursor.execute("""
    INSERT INTO informes_medicos 
    (trabajador_nombre, presion_arterial, ...)
    VALUES (%s, %s, ...)
""", (datos['trabajador_nombre'], datos['presion_arterial'], ...))
```

**Narraci√≥n:**
```
"Y finalmente guardamos en la base de datos para poder consultarlo despu√©s."
```

---

### 3. Ejercicio Pr√°ctico para Participantes (7 min)

**Script:**

```
Ahora es su turno. Cada uno va a subir un PDF y verificar 
que se proces√≥ correctamente. Vamos paso a paso.
```

**Instrucciones para Participantes:**

**Paso 1: Obtener el nombre de su bucket (1 min)**

```bash
# En CloudShell
aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`BucketName`].OutputValue' \
  --output text

# Guardar este nombre, lo van a usar
```

**Paso 2: Subir un PDF de prueba (2 min)**

```bash
# Reemplazar [TU-BUCKET] con el nombre que obtuvieron
aws s3 cp sample_data/informe_medio_riesgo.pdf \
  s3://[TU-BUCKET]/external-reports/
```

**Paso 3: Ver los logs en tiempo real (3 min)**

```bash
# Reemplazar participant-1 con su prefijo
aws logs tail /aws/lambda/participant-1-extract-pdf --follow

# Presionar Ctrl+C para salir cuando termine
```

**Paso 4: Verificar √©xito (1 min)**

```
Si ven en los logs:
‚úì "Textract completed"
‚úì "Bedrock response received"
‚úì "Data inserted successfully"

¬°Felicidades! Su primer PDF fue procesado autom√°ticamente.
```

---

### Rol del Instructor Durante el Ejercicio

**Mientras los participantes trabajan:**

- Monitorear el chat para preguntas
- Compartir pantalla de alguien que lo logr√≥ (con permiso)
- Ayudar a resolver problemas comunes
- Celebrar los √©xitos: "¬°Excelente, Juan ya proces√≥ su primer PDF!"

**Problemas Comunes y Soluciones:**

| Problema | Soluci√≥n |
|----------|----------|
| "No encuentro mi bucket" | Verificar que usaron su prefijo correcto en el comando |
| "No veo logs" | Verificar nombre de la funci√≥n Lambda con su prefijo |
| "El PDF no se proces√≥" | Verificar que el PDF est√° en la carpeta `external-reports/` |
| "Error de permisos" | Verificar que est√°n usando su usuario correcto |

---

### Cierre del M√≥dulo 1

**Script:**

```
Perfecto, veo que la mayor√≠a ya proces√≥ su primer PDF exitosamente.

Recapitulemos lo que logramos:
‚úì Subimos un PDF no estructurado
‚úì Textract extrajo el texto autom√°ticamente
‚úì Bedrock lo estructur√≥ en datos utilizables
‚úì Se guard√≥ en una base de datos

Este es el primer paso del flujo. En el siguiente m√≥dulo vamos a ver
c√≥mo mejorar la calidad de extracci√≥n con prompt engineering.

¬øAlguna pregunta antes de continuar?
```

**Tiempo Total:** 25 minutos (10 + 8 + 7)

---

### Checklist para el Instructor

**Antes de empezar M√≥dulo 1:**
- [ ] Todos los participantes tienen stacks desplegados
- [ ] Tienes 3 ventanas abiertas: S3, CloudWatch, Aurora
- [ ] Tienes el c√≥digo de la Lambda abierto en otra pesta√±a
- [ ] Tienes los comandos preparados para copiar/pegar en el chat

**Durante M√≥dulo 1:**
- [ ] Narrar lo que est√° pasando en tiempo real
- [ ] Hacer pausas para preguntas
- [ ] Poner comandos en el chat para que copien/peguen
- [ ] Verificar que todos completaron el ejercicio
- [ ] Resolver problemas comunes en vivo

**Despu√©s de M√≥dulo 1:**
- [ ] Confirmar que todos procesaron al menos 1 PDF
- [ ] Responder preguntas pendientes
- [ ] Hacer transici√≥n clara al M√≥dulo 2

---


#### M√≥dulo 2: Prompt Engineering (30 min)

**Objetivos:**
- Entender qu√© es prompt engineering
- Ver evoluci√≥n de prompts (v1 ‚Üí v2 ‚Üí v3)
- Experimentar con par√°metros
- Aprender mejores pr√°cticas

**Conceptos Clave a Explicar:**

1. **¬øQu√© es un Prompt?**
   - Instrucciones que le das al modelo
   - Como hablarle a un asistente muy inteligente
   - La calidad del prompt determina la calidad de la respuesta

2. **Componentes de un Buen Prompt:**
   - Rol/Contexto: "Eres un experto en..."
   - Tarea: "Extrae los siguientes datos..."
   - Formato: "Devuelve en JSON..."
   - Restricciones: "Si no encuentras un dato, usa null"
   - Ejemplos: "Por ejemplo: {...}"

3. **Par√°metros Importantes:**
   - **temperature**: Control de aleatoriedad (0.0 = determin√≠stico, 1.0 = creativo)
   - **maxTokens**: Longitud m√°xima de respuesta
   - **topP**: Control de diversidad

**Script:**

```
Prompt engineering es el arte de comunicarte efectivamente con un LLM.
Es como aprender a dar instrucciones claras a un asistente muy capaz
pero que necesita contexto espec√≠fico.

Un mal prompt: "Dame los datos"
Un buen prompt: "Eres un experto en informes m√©dicos. Extrae estos campos
espec√≠ficos en formato JSON. Si un campo no existe, usa null."

La diferencia es enorme en la calidad de resultados.
```

**Demostraci√≥n en vivo:**

1. **Comparar Versiones de Prompts** (15 min)
   
   Mostrar lado a lado:
   
   **Versi√≥n 1** ([`prompts/extraction_v1.txt`](prompts/extraction_v1.txt)):
   ```
   Extrae datos del siguiente informe m√©dico.
   ```
   
   Resultado: ‚ùå Inconsistente, formato variable
   
   **Versi√≥n 2** ([`prompts/extraction_v2.txt`](prompts/extraction_v2.txt)):
   ```
   Extrae los siguientes campos:
   - Nombre del trabajador
   - Presi√≥n arterial
   ...
   Devuelve en formato JSON.
   ```
   
   Resultado: ‚ö†Ô∏è Mejor, pero a√∫n inconsistente
   
   **Versi√≥n 3** ([`prompts/extraction.txt`](prompts/extraction.txt)):
   ```
   Eres un asistente especializado en extraer datos de informes m√©dicos.
   
   Extrae la siguiente informaci√≥n y devu√©lvela en formato JSON:
   {
     "trabajador_nombre": "string",
     "presion_arterial": "string",
     ...
   }
   
   IMPORTANTE:
   - Si un campo no est√° presente, usa null
   - Mant√©n el formato exacto del JSON
   - No inventes datos
   ```
   
   Resultado: ‚úÖ Consistente, preciso, confiable

2. **Experimentar con Temperature** (10 min)
   
   Modificar en vivo:
   ```python
   # Temperature baja (0.1) - Determin√≠stico
   "inferenceConfig": {"temperature": 0.1}
   
   # Temperature alta (0.8) - Creativo
   "inferenceConfig": {"temperature": 0.8}
   ```
   
   Desplegar y comparar resultados:
   ```bash
   cdk deploy AIExtractionStack
   aws s3 cp sample_data/informe_medio_riesgo.pdf s3://bucket/external-reports/
   ```
   
   **Mostrar diferencias:**
   - Temperature 0.1: Siempre extrae igual
   - Temperature 0.8: Puede variar en formato

3. **Cu√°ndo Usar Cada Temperature** (5 min)
   
   Mostrar tabla en pantalla compartida:
   ```
   Temperature | Uso Ideal           | Ejemplo
   ------------|---------------------|------------------
   0.0 - 0.2   | Extracci√≥n, datos   | PDFs, formularios
   0.3 - 0.5   | An√°lisis, res√∫menes | Informes ejecutivos
   0.6 - 0.8   | Contenido, emails   | Comunicaciones
   0.9 - 1.0   | Creativo, ideas     | Brainstorming
   ```

**Ejercicio para Participantes:**
1. Modificar temperature en su c√≥digo
2. Re-desplegar
3. Comparar resultados
4. Discutir diferencias

**Tiempo:** 30 minutos

---

#### Checkpoint D√≠a 1 (10 min)

**Objetivos:**
- Verificar que todos completaron los m√≥dulos
- Responder preguntas
- Preparar para D√≠a 2

**Checklist:**
```bash
# 1. Sistema legacy desplegado
aws cloudformation describe-stacks --stack-name LegacyStack

# 2. Sistema de extracci√≥n desplegado
aws cloudformation describe-stacks --stack-name AIExtractionStack

# 3. Al menos 1 PDF procesado
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM informes_medicos WHERE origen='EXTERNO';"
```

**Preguntas para Reflexi√≥n:**
1. ¬øQu√© hace Textract que Bedrock no puede hacer?
2. ¬øPor qu√© usamos temperature baja para extracci√≥n?
3. ¬øQu√© componentes hacen que un prompt sea efectivo?

**Tarea para D√≠a 2:**
- Revisar documentaci√≥n de pgvector
- Leer sobre RAG (Retrieval-Augmented Generation)

**Tiempo:** 10 minutos

---


### D√≠a 2: RAG, Clasificaci√≥n y Personalizaci√≥n (2h)

#### M√≥dulo 3: RAG con Embeddings Vectoriales (30 min)

**Objetivos:**
- Entender qu√© es RAG y por qu√© es importante
- Aprender sobre embeddings vectoriales
- Implementar b√∫squeda por similitud con pgvector
- Ver c√≥mo RAG mejora las respuestas

**Conceptos Clave a Explicar:**

1. **¬øQu√© es RAG?**
   - RAG = Retrieval-Augmented Generation
   - Retrieval: Buscar informaci√≥n relevante
   - Augmented: Agregar esa informaci√≥n al prompt
   - Generation: Generar respuesta con contexto
   
2. **Problema que Resuelve:**
   - LLMs tienen conocimiento limitado (fecha de corte)
   - LLMs pueden "alucinar" (inventar informaci√≥n)
   - RAG proporciona contexto espec√≠fico y verificable

3. **Embeddings Vectoriales:**
   - Representaci√≥n num√©rica de texto
   - Textos similares ‚Üí vectores similares
   - Permite b√∫squeda sem√°ntica (por significado, no por palabras)

**Script:**

```
Imaginen que le preguntan a un m√©dico sobre un paciente sin darle
el historial m√©dico. Puede dar una opini√≥n general, pero no espec√≠fica.

RAG es como darle al m√©dico el historial completo antes de que opine.
El m√©dico (LLM) ahora tiene contexto real y puede dar una respuesta
mucho m√°s precisa y personalizada.

Los embeddings son la forma de buscar ese historial de manera inteligente.
No buscamos por palabras exactas, sino por significado.
```

**Demostraci√≥n en vivo:**

1. **Explicar Embeddings con Ejemplo** (10 min)
   
   Mostrar en pantalla compartida:
   ```
   Texto 1: "Presi√≥n arterial: 140/90 mmHg"
   Embedding 1: [0.123, -0.456, 0.789, ..., 0.234]
   
   Texto 2: "PA: 142/88 mmHg"
   Embedding 2: [0.125, -0.450, 0.792, ..., 0.230]
   
   Similitud: 0.98 (muy similar)
   
   Texto 3: "Peso: 75 kg"
   Embedding 3: [-0.234, 0.567, -0.123, ..., 0.890]
   
   Similitud con Texto 1: 0.12 (muy diferente)
   ```
   
   **Punto clave:** Embeddings capturan el significado, no las palabras exactas.

2. **Desplegar Stack RAG** (5 min)
   ```bash
   cd cdk
   cdk deploy AIRAGStack
   ```
   
   Explicar mientras despliega:
   - Lambda para generar embeddings
   - Uso de Amazon Titan Embeddings v2
   - Tabla informes_embeddings con pgvector

3. **Generar Embeddings** (5 min)
   ```bash
   # Generar embeddings para informes existentes
   aws lambda invoke \
     --function-name generate-embeddings \
     --payload '{"informe_id": 1}' \
     response.json
   ```
   
   Mostrar en CloudWatch:
   - Llamada a Titan Embeddings
   - Vector de 1024 dimensiones
   - Inserci√≥n en pgvector

4. **Demostrar B√∫squeda por Similitud** (10 min)
   
   Abrir [`lambda/shared/similarity_search.py`](lambda/shared/similarity_search.py):
   ```python
   sql = """
       SELECT 
           ie.informe_id,
           ie.contenido,
           1 - (ie.embedding <=> %s::vector) as similarity
       FROM informes_embeddings ie
       WHERE ie.trabajador_id = %s
       ORDER BY ie.embedding <=> %s::vector
       LIMIT 3
   """
   ```
   
   **Explicar:**
   - `<=>` es el operador de distancia coseno
   - Menor distancia = mayor similitud
   - Filtramos por trabajador_id para contexto relevante
   
   Ejecutar b√∫squeda en vivo:
   ```sql
   SELECT 
     informe_id,
     contenido,
     1 - (embedding <=> '[0.123, -0.456, ...]'::vector) as similarity
   FROM informes_embeddings
   WHERE trabajador_id = 1
   ORDER BY embedding <=> '[0.123, -0.456, ...]'::vector
   LIMIT 3;
   ```

**Ejercicio para Participantes:**
1. Generar embeddings para sus informes
2. Ejecutar b√∫squeda por similitud
3. Observar qu√© informes son similares

**Tiempo:** 30 minutos

---


#### M√≥dulo 4: Clasificaci√≥n con Few-Shot Learning (30 min)

**Objetivos:**
- Entender few-shot learning
- Ver c√≥mo RAG mejora la clasificaci√≥n
- Implementar clasificador de riesgo
- Comparar resultados con y sin RAG

**Conceptos Clave a Explicar:**

1. **Few-Shot Learning:**
   - Ense√±ar al modelo con pocos ejemplos
   - Ejemplos en el prompt, no en entrenamiento
   - Muy efectivo para tareas de clasificaci√≥n

2. **Tipos de Learning:**
   - **Zero-shot**: Sin ejemplos (solo instrucciones)
   - **One-shot**: Un ejemplo
   - **Few-shot**: Varios ejemplos (2-5 t√≠picamente)
   - **Fine-tuning**: Entrenar el modelo (no cubierto aqu√≠)

3. **Por qu√© Funciona:**
   - LLMs aprenden patrones de los ejemplos
   - Generalizan a nuevos casos
   - M√°s ejemplos = mejor precisi√≥n (hasta cierto punto)

**Script:**

```
Few-shot learning es como mostrarle a alguien ejemplos antes de pedirle
que haga algo.

Sin ejemplos: "Clasifica este informe" ‚Üí Resultados inconsistentes
Con ejemplos: "Aqu√≠ hay 3 ejemplos de BAJO, MEDIO y ALTO riesgo.
               Ahora clasifica este" ‚Üí Resultados consistentes

Es la diferencia entre decir "dibuja un perro" vs mostrar 3 fotos
de perros y luego decir "dibuja uno similar".
```

**Demostraci√≥n en vivo:**

1. **Desplegar Stack de Clasificaci√≥n** (5 min)
   ```bash
   cd cdk
   cdk deploy AIClassificationStack
   ```

2. **Revisar Prompt de Clasificaci√≥n** (10 min)
   
   Abrir [`prompts/classification.txt`](prompts/classification.txt):
   
   ```
   Eres un m√©dico ocupacional experto en evaluar riesgos laborales.
   
   Clasifica el siguiente informe en uno de estos niveles:
   - BAJO: Par√°metros normales, apto sin restricciones
   - MEDIO: Par√°metros lim√≠trofes, requiere seguimiento
   - ALTO: Par√°metros alterados, requiere atenci√≥n inmediata
   
   EJEMPLOS:
   
   [Ejemplo BAJO]
   Trabajador: Juan P√©rez
   Presi√≥n: 118/75 mmHg
   IMC: 23.5
   Colesterol: 180 mg/dL
   Clasificaci√≥n: BAJO
   Justificaci√≥n: Todos los par√°metros dentro de rangos normales...
   
   [Ejemplo MEDIO]
   Trabajador: Mar√≠a Garc√≠a
   Presi√≥n: 135/85 mmHg
   IMC: 27.2
   Colesterol: 215 mg/dL
   Clasificaci√≥n: MEDIO
   Justificaci√≥n: Presi√≥n en rango de pre-hipertensi√≥n...
   
   [Ejemplo ALTO]
   Trabajador: Carlos L√≥pez
   Presi√≥n: 155/95 mmHg
   IMC: 32.1
   Glucosa: 145 mg/dL
   Clasificaci√≥n: ALTO
   Justificaci√≥n: Hipertensi√≥n grado 1, obesidad...
   
   CONTEXTO HIST√ìRICO:
   [Informes anteriores del trabajador - proporcionado por RAG]
   
   INFORME ACTUAL:
   [Datos del informe]
   
   Responde en formato JSON:
   {
     "nivel_riesgo": "BAJO|MEDIO|ALTO",
     "justificacion": "explicaci√≥n detallada"
   }
   ```
   
   **Puntos a destacar:**
   - Definiciones claras de cada nivel
   - Ejemplos espec√≠ficos con datos reales
   - Contexto hist√≥rico de RAG
   - Formato de salida estructurado

3. **Clasificar Informe** (10 min)
   ```bash
   # Clasificar informe
   aws lambda invoke \
     --function-name classify-risk \
     --payload '{"informe_id": 1}' \
     response.json
   
   # Ver resultado
   cat response.json
   ```
   
   Mostrar en CloudWatch:
   - B√∫squeda RAG de informes anteriores
   - Prompt completo con contexto
   - Respuesta de Bedrock
   - Actualizaci√≥n en Aurora

4. **Comparar Con y Sin RAG** (5 min)
   
   Modificar c√≥digo temporalmente para omitir RAG:
   ```python
   # Sin RAG
   prompt = f"""
   Clasifica este informe:
   {informe_actual}
   """
   
   # Con RAG
   prompt = f"""
   Contexto hist√≥rico:
   {informes_anteriores}
   
   Clasifica este informe:
   {informe_actual}
   ```
   
   **Mostrar diferencia:**
   - Sin RAG: Clasificaci√≥n basada solo en valores actuales
   - Con RAG: Clasificaci√≥n considerando tendencias

**Ejercicio para Participantes:**
1. Clasificar varios informes
2. Observar justificaciones
3. Verificar en base de datos

**Tiempo:** 30 minutos

---


#### M√≥dulo 5: Res√∫menes y Emails Personalizados (30 min)

**Objetivos:**
- Generar res√∫menes ejecutivos concisos
- Personalizar emails seg√∫n nivel de riesgo
- Entender control de tono con prompts
- Ver flujo completo end-to-end

**Conceptos Clave a Explicar:**

1. **Generaci√≥n de Res√∫menes:**
   - Condensar informaci√≥n compleja
   - Lenguaje claro y no t√©cnico
   - Enfoque en lo accionable
   - Incluir tendencias hist√≥ricas

2. **Personalizaci√≥n de Contenido:**
   - Mismo dato, diferentes tonos
   - Adaptaci√≥n a la audiencia
   - Control de urgencia y emoci√≥n
   - Mantener profesionalismo

3. **Temperature para Creatividad:**
   - Res√∫menes: 0.5 (balanceado)
   - Emails: 0.7 (m√°s creativo)
   - Permite variaci√≥n natural

**Script:**

```
Ahora vamos a cerrar el c√≠rculo. Tenemos datos extra√≠dos, clasificados,
y ahora necesitamos comunicarlos efectivamente.

Un resumen ejecutivo es para el gerente que tiene 2 minutos.
Un email es para el contratista que necesita actuar.

La clave es adaptar el mensaje a la audiencia y al nivel de urgencia.
Un informe de ALTO riesgo necesita un tono urgente.
Un informe de BAJO riesgo puede ser tranquilizador.
```

**Demostraci√≥n en vivo:**

1. **Desplegar Stacks** (5 min)
   ```bash
   cd cdk
   cdk deploy AISummaryStack
   cdk deploy AIEmailStack
   ```

2. **Generar Resumen Ejecutivo** (10 min)
   
   ```bash
   aws lambda invoke \
     --function-name generate-summary \
     --payload '{"informe_id": 1}' \
     response.json
   ```
   
   Revisar prompt ([`prompts/summary.txt`](prompts/summary.txt)):
   ```
   Genera un resumen ejecutivo del informe m√©dico.
   
   REQUISITOS:
   - M√°ximo 150 palabras
   - Lenguaje claro, no t√©cnico
   - Enf√≥cate en hallazgos principales
   - Incluye tendencias si hay informes anteriores
   
   CONTEXTO HIST√ìRICO:
   [Informes anteriores - RAG]
   
   INFORME ACTUAL:
   [Datos]
   
   FORMATO:
   P√°rrafo √∫nico, directo y accionable.
   ```
   
   **Mostrar resultado:**
   - Resumen conciso
   - Sin jerga m√©dica
   - Incluye tendencias
   - Accionable

3. **Enviar Emails Personalizados** (15 min)
   
   Mostrar los 3 prompts diferentes:
   
   **ALTO Riesgo** ([`prompts/email_high.txt`](prompts/email_high.txt)):
   ```
   Genera un email URGENTE para el contratista.
   
   TONO: Urgente pero profesional
   OBJETIVO: Acci√≥n inmediata
   
   Incluye:
   - Hallazgos cr√≠ticos destacados
   - Acciones requeridas INMEDIATAMENTE
   - Consecuencias de no actuar
   - Contacto para seguimiento
   
   ESTRUCTURA:
   - Asunto: [URGENTE] ...
   - Saludo formal
   - P√°rrafo de urgencia
   - Lista de acciones
   - Cierre con contacto
   ```
   
   **MEDIO Riesgo** ([`prompts/email_medium.txt`](prompts/email_medium.txt)):
   ```
   Genera un email PROFESIONAL para el contratista.
   
   TONO: Profesional y constructivo
   OBJETIVO: Seguimiento programado
   
   Incluye:
   - Hallazgos que requieren atenci√≥n
   - Recomendaciones de seguimiento
   - Plazo sugerido (30-60 d√≠as)
   - Disponibilidad para consultas
   ```
   
   **BAJO Riesgo** ([`prompts/email_low.txt`](prompts/email_low.txt)):
   ```
   Genera un email TRANQUILIZADOR para el contratista.
   
   TONO: Positivo y alentador
   OBJETIVO: Confirmar estado saludable
   
   Incluye:
   - Confirmaci√≥n de par√°metros normales
   - Felicitaci√≥n por mantener salud
   - Recordatorio de controles peri√≥dicos
   - Mensaje motivacional
   ```
   
   Enviar email:
   ```bash
   aws lambda invoke \
     --function-name send-email \
     --payload '{"informe_id": 1}' \
     response.json
   ```
   
   **Mostrar email recibido (compartir pantalla):**
   - Abrir bandeja de entrada en pantalla compartida
   - Mostrar personalizaci√≥n
   - Destacar tono apropiado
   - Se√±alar elementos clave

**Ejercicio para Participantes:**
1. Generar res√∫menes de sus informes
2. Enviar emails
3. Comparar tonos seg√∫n nivel de riesgo

**Tiempo:** 30 minutos

---

#### Experimentaci√≥n Libre (30 min)

**Objetivos:**
- Permitir exploraci√≥n aut√≥noma
- Responder preguntas espec√≠ficas
- Facilitar experimentaci√≥n con prompts
- Compartir descubrimientos

**Actividades Sugeridas:**

1. **Modificar Prompts:**
   - Cambiar tono de emails
   - Ajustar longitud de res√∫menes
   - Agregar m√°s ejemplos a clasificaci√≥n

2. **Experimentar con Par√°metros:**
   - Probar diferentes temperatures
   - Ajustar maxTokens
   - Comparar resultados

3. **Crear Nuevos Casos:**
   - Subir PDFs propios
   - Generar datos de prueba
   - Ver flujo completo

4. **Optimizar Prompts:**
   - Iterar sobre prompts existentes
   - Medir mejoras
   - Documentar cambios

**Rol del Instructor:**
- Monitorear el chat y preguntas
- Responder preguntas en tiempo real
- Sugerir experimentos
- Facilitar discusiones en grupo
- Compartir mejores pr√°cticas
- Usar breakout rooms si es necesario

**Tiempo:** 30 minutos

---


## üí° Puntos Clave de Explicaci√≥n

### Servicios AWS

#### Amazon Bedrock
**Qu√© es:**
- Servicio totalmente administrado para usar LLMs
- Acceso a m√∫ltiples modelos (Amazon, Anthropic, Meta, etc.)
- Sin necesidad de gestionar infraestructura

**Cu√°ndo explicar:**
- M√≥dulo 1 (primera vez que se usa)
- Enfatizar: "Serverless para IA"

**Puntos clave:**
- No necesitas entrenar modelos
- Pagas por uso (por token)
- Modelos pre-entrenados listos para usar

#### Amazon Nova Pro
**Qu√© es:**
- Modelo de lenguaje de Amazon
- Optimizado para tareas empresariales
- Multimodal (texto, im√°genes)

**Cu√°ndo explicar:**
- M√≥dulo 1 (al invocar por primera vez)

**Puntos clave:**
- Balanceo entre costo y capacidad
- Bueno para tareas complejas
- Soporta espa√±ol nativamente

#### Amazon Titan Embeddings v2
**Qu√© es:**
- Modelo para generar embeddings
- Vectores de 1024 dimensiones
- Optimizado para b√∫squeda sem√°ntica

**Cu√°ndo explicar:**
- M√≥dulo 3 (RAG)

**Puntos clave:**
- Convierte texto en n√∫meros
- Permite b√∫squeda por significado
- Base de RAG

#### Amazon Textract
**Qu√© es:**
- Servicio de OCR (Optical Character Recognition)
- Extrae texto, tablas y formularios
- Entiende estructura de documentos

**Cu√°ndo explicar:**
- M√≥dulo 1 (extracci√≥n)

**Puntos clave:**
- M√°s que OCR simple
- Entiende tablas y formularios
- No entiende contexto (por eso necesitamos Bedrock)

#### Aurora Serverless v2
**Qu√© es:**
- PostgreSQL serverless
- Escala autom√°ticamente
- Soporta pgvector para embeddings

**Cu√°ndo explicar:**
- Setup inicial
- M√≥dulo 3 (cuando se usa pgvector)

**Puntos clave:**
- Escala de 0.5 a 128 ACUs
- Pagas por uso
- pgvector permite b√∫squeda vectorial

---

### Conceptos de IA Generativa

#### LLMs (Large Language Models)
**Explicaci√≥n simple:**
```
Un LLM es como un asistente muy inteligente que ha le√≠do millones
de libros y puede entender y generar texto de manera natural.

No es una base de datos que busca respuestas exactas.
Es un modelo que entiende patrones y genera respuestas coherentes.
```

**Analog√≠a:**
- Base de datos = Biblioteca con √≠ndice
- LLM = Persona que ley√≥ toda la biblioteca y puede conversar

#### Prompt Engineering
**Explicaci√≥n simple:**
```
Prompt engineering es el arte de comunicarte efectivamente con un LLM.
Es como aprender a dar instrucciones claras a un asistente muy capaz.

Mal prompt: "Dame datos"
Buen prompt: "Eres un experto en X. Extrae estos campos espec√≠ficos
              en formato Y. Si no encuentras algo, usa Z."
```

**Mejores pr√°cticas:**
1. Dar contexto/rol
2. Ser espec√≠fico
3. Proporcionar ejemplos
4. Definir formato de salida
5. Establecer restricciones

#### RAG (Retrieval-Augmented Generation)
**Explicaci√≥n simple:**
```
RAG es como darle a un m√©dico el historial del paciente antes
de que d√© su diagn√≥stico.

Sin RAG: Opini√≥n general basada en conocimiento general
Con RAG: Opini√≥n espec√≠fica basada en datos reales del paciente
```

**Componentes:**
1. **Retrieval**: Buscar informaci√≥n relevante
2. **Augmented**: Agregar al prompt
3. **Generation**: Generar respuesta con contexto

**Beneficios:**
- Reduce alucinaciones
- Proporciona contexto espec√≠fico
- Mejora precisi√≥n
- Permite personalizaci√≥n

#### Few-Shot Learning
**Explicaci√≥n simple:**
```
Few-shot learning es ense√±ar con ejemplos en lugar de entrenar.

Es como mostrarle a alguien 3 fotos de perros y luego pedirle
que identifique perros en nuevas fotos.

No necesitas miles de ejemplos, solo unos pocos buenos.
```

**Tipos:**
- **Zero-shot**: Sin ejemplos
- **One-shot**: Un ejemplo
- **Few-shot**: 2-5 ejemplos
- **Many-shot**: 10+ ejemplos

#### Temperature
**Explicaci√≥n simple:**
```
Temperature controla qu√© tan "creativo" o "aleatorio" es el modelo.

Temperature 0.0: Siempre da la misma respuesta (determin√≠stico)
Temperature 1.0: Respuestas muy variadas (creativo)

Es como el volumen de creatividad.
```

**Gu√≠a de uso:**
```
0.0 - 0.2: Extracci√≥n de datos, clasificaci√≥n
0.3 - 0.5: An√°lisis, res√∫menes
0.6 - 0.8: Contenido, emails
0.9 - 1.0: Brainstorming, ideas
```

#### Embeddings Vectoriales
**Explicaci√≥n simple:**
```
Un embedding es una representaci√≥n num√©rica de texto.

Texto: "Presi√≥n arterial alta"
Embedding: [0.123, -0.456, 0.789, ..., 0.234]

Textos similares tienen embeddings similares.
Permite buscar por significado, no por palabras exactas.
```

**Analog√≠a:**
- Palabras = Direcciones
- Embeddings = Coordenadas GPS
- Similitud = Distancia entre coordenadas

---


## üéì Snippets de C√≥digo Comentados

### Extracci√≥n con Textract y Bedrock

```python
def extract_pdf_data(bucket, key):
    """
    Extrae datos estructurados de un PDF m√©dico.
    
    Flujo:
    1. Textract extrae texto del PDF
    2. Bedrock estructura el texto en JSON
    3. Guardar en Aurora
    """
    
    # Paso 1: Extraer texto con Textract
    # analyze_document es m√°s potente que detect_document_text
    # porque entiende tablas y formularios
    response = textract_client.analyze_document(
        Document={'S3Object': {'Bucket': bucket, 'Name': key}},
        FeatureTypes=['TABLES', 'FORMS']  # Extraer tablas y formularios
    )
    
    # Convertir respuesta de Textract a texto plano
    texto_extraido = extract_text_from_textract(response)
    
    # Paso 2: Estructurar con Bedrock
    # Leer prompt desde archivo (facilita iteraci√≥n)
    with open('prompts/extraction.txt', 'r') as f:
        prompt_template = f.read()
    
    # Construir prompt con el texto extra√≠do
    prompt = prompt_template.replace('{texto}', texto_extraido)
    
    # Invocar Bedrock Nova Pro
    bedrock_response = bedrock_runtime.invoke_model(
        modelId='us.amazon.nova-pro-v1:0',
        body=json.dumps({
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "inferenceConfig": {
                "temperature": 0.1,  # Baja para precisi√≥n
                "maxTokens": 2000,   # Suficiente para JSON
                "topP": 0.9
            }
        })
    )
    
    # Parsear respuesta
    response_body = json.loads(bedrock_response['body'].read())
    datos_estructurados = json.loads(response_body['output']['message']['content'][0]['text'])
    
    # Paso 3: Guardar en Aurora
    save_to_aurora(datos_estructurados)
    
    return datos_estructurados
```

### Generaci√≥n de Embeddings

```python
def generate_embedding(texto):
    """
    Genera embedding vectorial de un texto usando Titan.
    
    Retorna un vector de 1024 dimensiones que representa
    el significado sem√°ntico del texto.
    """
    
    # Invocar Titan Embeddings v2
    response = bedrock_runtime.invoke_model(
        modelId='amazon.titan-embed-text-v2:0',
        body=json.dumps({
            "inputText": texto,
            "dimensions": 1024,  # Dimensiones del vector
            "normalize": True    # Normalizar para cosine similarity
        })
    )
    
    # Extraer embedding
    response_body = json.loads(response['body'].read())
    embedding = response_body['embedding']
    
    return embedding  # Lista de 1024 n√∫meros
```

### B√∫squeda RAG con pgvector

```python
def buscar_informes_similares(trabajador_id, embedding_actual, limit=3):
    """
    Busca informes anteriores similares usando pgvector.
    
    Usa distancia coseno para encontrar embeddings similares.
    Menor distancia = mayor similitud.
    """
    
    sql = """
        SELECT 
            ie.informe_id,
            ie.contenido,
            ie.fecha_examen,
            1 - (ie.embedding <=> %s::vector) as similarity
        FROM informes_embeddings ie
        WHERE ie.trabajador_id = %s
          AND ie.informe_id != %s
        ORDER BY ie.embedding <=> %s::vector  -- Ordenar por distancia
        LIMIT %s
    """
    
    # <=> es el operador de distancia coseno de pgvector
    # 1 - distancia = similitud (0 = diferente, 1 = id√©ntico)
    
    cursor.execute(sql, (
        embedding_actual,
        trabajador_id,
        informe_actual_id,
        embedding_actual,
        limit
    ))
    
    return cursor.fetchall()
```

### Clasificaci√≥n con Few-Shot Learning

```python
def classify_risk(informe_id):
    """
    Clasifica nivel de riesgo usando few-shot learning y RAG.
    
    Combina:
    1. Ejemplos en el prompt (few-shot)
    2. Contexto hist√≥rico (RAG)
    3. Datos actuales
    """
    
    # Obtener datos del informe
    informe = get_informe(informe_id)
    
    # Buscar informes anteriores (RAG)
    embedding = generate_embedding(informe['contenido'])
    informes_anteriores = buscar_informes_similares(
        informe['trabajador_id'],
        embedding,
        limit=3
    )
    
    # Construir contexto hist√≥rico
    contexto = "\n".join([
        f"Fecha: {inf['fecha']}, Riesgo: {inf['nivel']}, "
        f"Observaciones: {inf['obs']}"
        for inf in informes_anteriores
    ])
    
    # Leer prompt con ejemplos (few-shot)
    with open('prompts/classification.txt', 'r') as f:
        prompt_template = f.read()
    
    # Reemplazar placeholders
    prompt = prompt_template.replace('{contexto}', contexto)
    prompt = prompt.replace('{informe}', json.dumps(informe))
    
    # Invocar Bedrock
    response = bedrock_runtime.invoke_model(
        modelId='us.amazon.nova-pro-v1:0',
        body=json.dumps({
            "messages": [{"role": "user", "content": prompt}],
            "inferenceConfig": {
                "temperature": 0.3,  # Baja pero no 0 para variaci√≥n
                "maxTokens": 500
            }
        })
    )
    
    # Parsear y guardar
    result = parse_response(response)
    update_informe(informe_id, result)
    
    return result
```

---

## ‚ùì FAQ con Respuestas T√©cnicas

### Sobre Amazon Bedrock

**P: ¬øPor qu√© usar Bedrock en lugar de llamar directamente a OpenAI?**

R: Varias razones:
1. **Integraci√≥n nativa con AWS**: Permisos IAM, VPC, CloudWatch
2. **M√∫ltiples modelos**: Amazon, Anthropic, Meta, Cohere en un solo lugar
3. **Cumplimiento**: Datos no se usan para entrenar modelos
4. **Soporte empresarial**: SLA, soporte t√©cnico de AWS
5. **Costos**: Competitivos y facturados con AWS

**P: ¬øCu√°nto cuesta usar Bedrock?**

R: Precios aproximados (us-east-1):
- Nova Pro: $0.80 por 1M tokens de entrada, $3.20 por 1M tokens de salida
- Titan Embeddings: $0.10 por 1M tokens
- Para este workshop: ~$2-5 USD por participante

**P: ¬øQu√© modelos est√°n disponibles en Bedrock?**

R: Principales modelos:
- **Amazon**: Nova Pro, Nova Lite, Titan
- **Anthropic**: Claude 3 (Opus, Sonnet, Haiku)
- **Meta**: Llama 3
- **Cohere**: Command, Embed
- **Stability AI**: Stable Diffusion (im√°genes)

**P: ¬øC√≥mo accedo a los modelos de Bedrock?**

R: Los modelos serverless se habilitan autom√°ticamente en la primera invocaci√≥n. Solo necesitas permisos IAM adecuados (`bedrock:InvokeModel`). No requiere activaci√≥n manual.

### Sobre Prompts

**P: ¬øCu√°l es la longitud ideal de un prompt?**

R: Depende de la tarea:
- **Extracci√≥n simple**: 200-500 tokens
- **Clasificaci√≥n con ejemplos**: 500-1000 tokens
- **An√°lisis complejo**: 1000-2000 tokens
- **L√≠mite pr√°ctico**: 4000-8000 tokens (depende del modelo)

**P: ¬øC√≥mo s√© si mi prompt es bueno?**

R: Criterios:
1. **Consistencia**: ¬øDa resultados similares con inputs similares?
2. **Precisi√≥n**: ¬øLos resultados son correctos?
3. **Formato**: ¬øRespeta el formato solicitado?
4. **Completitud**: ¬øIncluye toda la informaci√≥n necesaria?

Prueba con 10-20 casos y mide estos criterios.

**P: ¬øDebo usar JSON mode o parsear la respuesta?**

R: Depende:
- **JSON mode** (si est√° disponible): Garantiza JSON v√°lido
- **Parsear**: M√°s flexible, permite explicaciones adicionales

En este workshop usamos parseo porque queremos ver el proceso.

### Sobre RAG

**P: ¬øCu√°ntos documentos debo recuperar en RAG?**

R: Regla general:
- **3-5 documentos**: Balance entre contexto y ruido
- **Menos de 3**: Puede faltar contexto
- **M√°s de 10**: Puede confundir al modelo

En este workshop usamos 3.

**P: ¬øC√≥mo s√© si RAG est√° mejorando los resultados?**

R: Prueba A/B:
1. Clasificar 20 informes sin RAG
2. Clasificar los mismos 20 con RAG
3. Comparar precisi√≥n con evaluaci√≥n humana

T√≠picamente RAG mejora 10-30% la precisi√≥n.

**P: ¬øPuedo usar RAG con otros tipos de datos?**

R: S√≠, RAG funciona con:
- Documentos (PDFs, Word)
- C√≥digo fuente
- Logs de sistema
- Conversaciones
- Cualquier texto estructurado

### Sobre Embeddings

**P: ¬øPor qu√© 1024 dimensiones?**

R: Balance entre:
- **M√°s dimensiones**: Mayor precisi√≥n, m√°s costo de almacenamiento
- **Menos dimensiones**: Menor precisi√≥n, menos costo

1024 es un buen balance para la mayor√≠a de casos.

**P: ¬øPuedo usar embeddings de OpenAI con pgvector?**

R: S√≠, pgvector es agn√≥stico al modelo:
- OpenAI: 1536 dimensiones
- Titan v2: 1024 dimensiones
- Cohere: 768 dimensiones

Solo ajusta la dimensi√≥n en la tabla.

**P: ¬øC√≥mo actualizo embeddings cuando cambia el contenido?**

R: Estrategias:
1. **Regenerar todo**: Simple pero costoso
2. **Incremental**: Solo nuevos/modificados
3. **Batch nocturno**: Actualizar en horario de baja demanda

En producci√≥n, usa estrategia incremental.

### Sobre Debugging

**P: ¬øC√≥mo debuggeo prompts que no funcionan?**

R: Pasos:
1. **Ver logs en CloudWatch**: Prompt completo y respuesta
2. **Probar en consola de Bedrock**: Playground para iteraci√≥n r√°pida
3. **Simplificar**: Remover complejidad hasta que funcione
4. **Agregar ejemplos**: Few-shot learning ayuda mucho
5. **Ajustar temperature**: Probar valores diferentes

**P: ¬øQu√© hago si Bedrock da errores de throttling?**

R: Soluciones:
1. **Implementar retry con backoff exponencial**
2. **Solicitar aumento de l√≠mites** (Service Quotas)
3. **Usar batch processing** en lugar de tiempo real
4. **Distribuir carga** entre m√∫ltiples regiones

**P: ¬øC√≥mo monitoreo costos de Bedrock?**

R: Herramientas:
1. **Cost Explorer**: Ver costos por servicio
2. **CloudWatch Metrics**: Tokens procesados
3. **Budgets**: Alertas de presupuesto
4. **Tags**: Etiquetar recursos para tracking

---


## ‚è±Ô∏è Tiempos Estimados por M√≥dulo

### D√≠a 1 (1h 15min)

| M√≥dulo | Actividad | Tiempo | Acumulado |
|--------|-----------|--------|-----------|
| 0 | Introducci√≥n y bienvenida | 5 min | 5 min |
| 0.5 | Despliegue AI Stacks + Arquitectura | 8 min | 13 min |
| 1 | Demo en vivo: Subir PDF y ver procesamiento | 10 min | 23 min |
| 1 | Explicar c√≥digo (Textract + Bedrock) | 8 min | 31 min |
| 1 | Ejercicio: Participantes suben su PDF | 7 min | 38 min |
| 2 | Comparar versiones de prompts | 15 min | 53 min |
| 2 | Experimentar con temperature | 10 min | 63 min |
| 2 | Ejercicio participantes | 5 min | 68 min |
| - | Checkpoint y Q&A | 7 min | 75 min |

**Total D√≠a 1:** 1h 15min

**Nota:** El M√≥dulo 0.5 incluye el tiempo de despliegue (5-8 min) mientras se explica la arquitectura y casos de uso.

### D√≠a 2 (2h)

| M√≥dulo | Actividad | Tiempo | Acumulado |
|--------|-----------|--------|-----------|
| 3 | Explicar RAG y embeddings | 10 min | 10 min |
| 3 | Desplegar stack RAG | 5 min | 15 min |
| 3 | Generar embeddings | 5 min | 20 min |
| 3 | Demostrar b√∫squeda similitud | 10 min | 30 min |
| 4 | Explicar few-shot learning | 5 min | 35 min |
| 4 | Desplegar stack clasificaci√≥n | 5 min | 40 min |
| 4 | Revisar prompt clasificaci√≥n | 10 min | 50 min |
| 4 | Clasificar y comparar con/sin RAG | 10 min | 60 min |
| 5 | Desplegar stacks resumen y email | 5 min | 65 min |
| 5 | Generar resumen ejecutivo | 10 min | 75 min |
| 5 | Revisar prompts de email | 5 min | 80 min |
| 5 | Enviar emails y mostrar resultados | 10 min | 90 min |
| - | Experimentaci√≥n libre | 30 min | 120 min |

**Total D√≠a 2:** 2h

**Total Workshop:** 3h 15min

---

## üéØ Checkpoints Funcionales

### Checkpoint D√≠a 1

**Objetivo:** Verificar que el flujo de extracci√≥n funciona end-to-end.

**Verificaciones:**

```bash
# 1. Stacks desplegados
aws cloudformation describe-stacks \
  --stack-name LegacyStack \
  --query 'Stacks[0].StackStatus'
# Esperado: CREATE_COMPLETE

aws cloudformation describe-stacks \
  --stack-name AIExtractionStack \
  --query 'Stacks[0].StackStatus'
# Esperado: CREATE_COMPLETE

# 2. PDF procesado
aws s3 ls s3://<bucket>/external-reports/
# Esperado: Ver al menos 1 PDF

# 3. Datos en Aurora
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM informes_medicos WHERE origen='EXTERNO';"
# Esperado: >= 1

# 4. Logs en CloudWatch
aws logs tail /aws/lambda/extract-pdf --since 10m
# Esperado: Ver logs de procesamiento exitoso
```

**Criterios de √âxito:**
- ‚úÖ Todos los stacks desplegados
- ‚úÖ Al menos 1 PDF procesado
- ‚úÖ Datos guardados en Aurora
- ‚úÖ Logs muestran √©xito

**Si algo falla:**
1. Verificar permisos IAM
2. Verificar modelos habilitados en Bedrock
3. Revisar logs de CloudWatch para errores
4. Verificar conectividad a Aurora

### Checkpoint D√≠a 2

**Objetivo:** Verificar que el flujo completo funciona end-to-end.

**Verificaciones:**

```bash
# 1. Todos los stacks desplegados
aws cloudformation list-stacks \
  --stack-status-filter CREATE_COMPLETE \
  --query 'StackSummaries[?contains(StackName, `Stack`)].StackName'
# Esperado: 6 stacks (Legacy, Extraction, RAG, Classification, Summary, Email)

# 2. Embeddings generados
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM informes_embeddings;"
# Esperado: >= 1

# 3. Informes clasificados
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM informes_medicos WHERE nivel_riesgo IS NOT NULL;"
# Esperado: >= 1

# 4. Res√∫menes generados
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM informes_medicos WHERE resumen_ejecutivo IS NOT NULL;"
# Esperado: >= 1

# 5. Emails enviados
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM historial_emails WHERE estado='ENVIADO';"
# Esperado: >= 1
```

**Criterios de √âxito:**
- ‚úÖ Todos los stacks desplegados
- ‚úÖ Embeddings generados
- ‚úÖ Clasificaci√≥n funcionando
- ‚úÖ Res√∫menes generados
- ‚úÖ Emails enviados

**Si algo falla:**
1. Verificar que D√≠a 1 funcion√≥ correctamente
2. Verificar email verificado en SES
3. Revisar logs de cada Lambda
4. Verificar datos en Aurora

---

## üìä M√©tricas de √âxito del Workshop

### M√©tricas T√©cnicas

- ‚úÖ **100% de participantes** completan despliegue del sistema legacy
- ‚úÖ **90%+ de participantes** procesan al menos 1 PDF exitosamente
- ‚úÖ **80%+ de participantes** completan flujo end-to-end
- ‚úÖ **70%+ de participantes** experimentan con prompts

### M√©tricas de Aprendizaje

Al final del workshop, los participantes deben poder:

- ‚úÖ Explicar diferencia entre Textract y Bedrock
- ‚úÖ Escribir un prompt efectivo
- ‚úÖ Explicar qu√© es RAG y por qu√© es √∫til
- ‚úÖ Describir few-shot learning
- ‚úÖ Ajustar temperature seg√∫n el caso de uso
- ‚úÖ Desplegar infraestructura con CDK

### M√©tricas de Satisfacci√≥n

- ‚úÖ **4.5+/5** en encuesta de satisfacci√≥n
- ‚úÖ **90%+** recomendar√≠an el workshop
- ‚úÖ **80%+** sienten que pueden aplicar lo aprendido

---

## üõ†Ô∏è Troubleshooting para el Instructor

### Problema: Error "Model access denied" en Bedrock

**Causa:** Permisos IAM insuficientes.

**Soluci√≥n:**
1. Verificar que el usuario tiene permisos `bedrock:InvokeModel`
2. Verificar regi√≥n (us-east-2 o us-east-1 recomendadas)
3. Si es cuenta organizacional, verificar SCPs
4. Los modelos se habilitan autom√°ticamente en la primera invocaci√≥n

### Problema: Credenciales AWS expiradas durante el workshop

**Causa:** Sesi√≥n SSO expirada (com√∫n despu√©s de 8-12 horas).

**Soluci√≥n:**
```bash
# Renovar sesi√≥n SSO
aws sso login --profile <nombre-perfil>

# Verificar que funciona
aws sts get-caller-identity --profile <nombre-perfil>

# Reintentar comando que fall√≥
```

### Problema: CDK deploy falla con "bucket already exists"

**Causa:** Prefijo no √∫nico entre participantes.

**Soluci√≥n:**
1. Pedir a participante cambiar prefijo en [`cdk/bin/app.ts`](cdk/bin/app.ts)
2. Sugerir formato: `participant-nombre-numero`
3. Verificar que sea √∫nico antes de re-desplegar

### Problema: Lambda no puede conectar a Aurora

**Causa:** Security group o VPC mal configurado.

**Soluci√≥n:**
1. Verificar que Lambda est√° en la misma VPC que Aurora
2. Verificar security group permite tr√°fico desde Lambda
3. Verificar subnet tiene ruta a internet (para Bedrock)
4. Revisar logs de CloudWatch para error espec√≠fico

### Problema: Textract falla con "InvalidS3ObjectException"

**Causa:** PDF corrupto o formato no soportado.

**Soluci√≥n:**
1. Verificar que el archivo es un PDF v√°lido
2. Probar con PDFs de ejemplo del repositorio
3. Verificar permisos de S3
4. Verificar que el PDF no est√° encriptado

### Problema: Bedrock responde con JSON inv√°lido

**Causa:** Prompt no es suficientemente espec√≠fico.

**Soluci√≥n:**
1. Agregar m√°s ejemplos al prompt
2. Bajar temperature a 0.1
3. Agregar instrucci√≥n expl√≠cita: "Responde SOLO con JSON v√°lido"
4. Implementar retry con validaci√≥n

### Problema: Emails no se env√≠an

**Causa:** Email no verificado en SES o cuenta en sandbox.

**Soluci√≥n:**
1. Verificar email en SES
2. Si est√° en sandbox, solo puede enviar a emails verificados
3. Solicitar salir de sandbox (toma 24h)
4. Como alternativa, usar SNS para notificaciones

### Problema: Costos m√°s altos de lo esperado

**Causa:** Muchas invocaciones o tokens excesivos.

**Soluci√≥n:**
1. Revisar CloudWatch Metrics para uso de Bedrock
2. Optimizar prompts para usar menos tokens
3. Implementar caching de respuestas
4. Configurar alertas de presupuesto

---

## üìö Recursos Adicionales para el Instructor

### Documentaci√≥n Oficial

- [Amazon Bedrock Documentation](https://docs.aws.amazon.com/bedrock/)
- [Amazon Textract Documentation](https://docs.aws.amazon.com/textract/)
- [AWS CDK Documentation](https://docs.aws.amazon.com/cdk/)
- [pgvector Documentation](https://github.com/pgvector/pgvector)

### Gu√≠as de Prompt Engineering

- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [OpenAI Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)
- [Anthropic Prompt Library](https://docs.anthropic.com/claude/prompt-library)

### Papers y Art√≠culos

- [RAG: Retrieval-Augmented Generation](https://arxiv.org/abs/2005.11401)
- [Few-Shot Learning](https://arxiv.org/abs/2005.14165)
- [In-Context Learning](https://arxiv.org/abs/2301.00234)

### Comunidades

- [AWS re:Post - Bedrock](https://repost.aws/tags/TA4IHBWMFxRRKzKzuCJAV_Aw/amazon-bedrock)
- [AWS Samples GitHub](https://github.com/aws-samples)
- [Bedrock Workshop](https://catalog.workshops.aws/building-with-amazon-bedrock)

---

## ‚úÖ Checklist Final

### Antes del Workshop

- [ ] Sistema desplegado en cuenta de demostraci√≥n
- [ ] Email a participantes enviado con prerequisitos

### Durante el Workshop

- [ ] Conectarse 15 minutos antes
- [ ] Tener consola AWS, CloudWatch Logs y terminal listos

### Despu√©s del Workshop

- [ ] Enviar encuesta de satisfacci√≥n
- [ ] Compartir recursos adicionales
- [ ] Responder preguntas pendientes
- [ ] Recopilar feedback para mejoras
- [ ] Limpiar recursos de demostraci√≥n

---

## üéâ Conclusi√≥n

Este workshop proporciona una experiencia pr√°ctica completa de IA Generativa con AWS. Los participantes no solo aprenden conceptos, sino que construyen un sistema real end-to-end.

**Puntos clave para el √©xito:**
1. Mantener el ritmo (3h 15min es ajustado)
2. Enfocarse en conceptos, no solo en c√≥digo
3. Permitir experimentaci√≥n
4. Responder preguntas con ejemplos pr√°cticos
5. Conectar cada m√≥dulo con el caso de uso real

**Recuerda:** El objetivo no es que memoricen comandos, sino que entiendan los conceptos y puedan aplicarlos en sus propios proyectos.

¬°Buena suerte con el workshop! üöÄ


---

## üßπ Limpieza de Recursos Despu√©s del Workshop

**‚ö†Ô∏è IMPORTANTE:** Elimina todos los recursos despu√©s del workshop para evitar costos innecesarios.

### Opci√≥n A: Script Automatizado (Recomendado)

El script elimina todos los recursos en el orden correcto: AI Stacks ‚Üí Legacy Stacks ‚Üí Network Stack

```powershell
# PowerShell - Elimina todos los recursos
.\scripts\instructor-cleanup.ps1

# Con par√°metros personalizados:
.\scripts\instructor-cleanup.ps1 -ConfigFile config/participants.json -Profile <tu-perfil-aws> -Concurrency 5

# Para participantes espec√≠ficos:
.\scripts\instructor-cleanup.ps1 -Participants "participant-juan","participant-maria"

# Sin confirmaci√≥n (para automatizaci√≥n):
.\scripts\instructor-cleanup.ps1 -SkipConfirmation
```

Ver script: [`scripts/instructor-cleanup.ps1`](scripts/instructor-cleanup.ps1)

```bash
# Bash (Linux/Mac)
./scripts/instructor-cleanup.sh

# Con par√°metros:
./scripts/instructor-cleanup.sh config/participants.json <tu-perfil-aws> us-east-2
```

Ver script: [`scripts/instructor-cleanup.sh`](scripts/instructor-cleanup.sh)

**Tiempo estimado:** Variable seg√∫n n√∫mero de participantes (~5-15 minutos)

**El script:**
- ‚úÖ Elimina en el orden correcto (AI ‚Üí Legacy ‚Üí Network)
- ‚úÖ Contin√∫a si un stack falla
- ‚úÖ Genera reporte de errores
- ‚úÖ Verifica recursos hu√©rfanos

### Opci√≥n B: Limpieza Manual

Si prefieres eliminar manualmente o el script falla:

#### 1. Eliminar AI Stacks de Cada Participante

```powershell
# PowerShell - Para cada participante
$env:DEPLOY_MODE = "ai"
$env:PARTICIPANT_PREFIX = "participant-juan"
cd cdk
cdk destroy --all --force --profile <tu-perfil-aws>
```

#### 2. Eliminar LegacyStacks

```powershell
# PowerShell - Para cada participante
$env:DEPLOY_MODE = "legacy"
$env:PARTICIPANT_PREFIX = "participant-juan"
cd cdk
cdk destroy participant-juan-MedicalReportsLegacyStack --force --profile <tu-perfil-aws>
```

#### 3. Eliminar SharedNetworkStack

```powershell
# PowerShell - Una sola vez al final
$env:DEPLOY_MODE = "network"
cd cdk
cdk destroy SharedNetworkStack --force --profile <tu-perfil-aws>
```

### Verificaci√≥n de Limpieza

Verifica que no quedan recursos:

```powershell
# Listar stacks restantes
aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE --profile <tu-perfil-aws>

# Verificar buckets S3 (deben estar vac√≠os)
aws s3 ls --profile <tu-perfil-aws>

# Verificar bases de datos Aurora
aws rds describe-db-clusters --profile <tu-perfil-aws>
```

### Recursos que se Eliminan

Por cada participante:
- ‚úÖ 5 AI Stacks (Lambdas de IA)
- ‚úÖ 1 LegacyStack (Aurora, S3, API Gateway, Lambdas)
- ‚úÖ Security Groups
- ‚úÖ Roles y pol√≠ticas IAM

Infraestructura compartida:
- ‚úÖ SharedNetworkStack (VPC, NAT Gateway, subnets)

### Troubleshooting de Limpieza

**Error: "Stack cannot be deleted while it has dependent stacks"**
- Elimina primero los AI Stacks, luego Legacy, luego Network
- El script automatizado ya maneja este orden

**Error: "Bucket not empty"**
- Los buckets S3 tienen `autoDeleteObjects: true`
- Si falla, vac√≠a manualmente: `aws s3 rm s3://bucket-name --recursive`

**Error: "Resource being used by another resource"**
- Espera unos minutos y reintenta
- Verifica en la consola de CloudFormation qu√© recurso est√° bloqueando

**Stacks en estado DELETE_FAILED**
- Revisa los eventos en CloudFormation para ver qu√© fall√≥
- Elimina manualmente el recurso problem√°tico
- Reintenta la eliminaci√≥n del stack

### Costos Estimados

Si olvidas eliminar los recursos, los costos aproximados son:

| Recurso | Costo por hora | Costo por d√≠a |
|---------|----------------|---------------|
| Aurora Serverless v2 (0.5 ACU) | ~$0.06 | ~$1.44 |
| NAT Gateway | ~$0.045 | ~$1.08 |
| Lambdas (idle) | $0 | $0 |
| S3 (storage) | M√≠nimo | M√≠nimo |
| **Total por participante** | **~$0.06** | **~$1.44** |
| **10 participantes + VPC** | **~$0.65** | **~$15.60** |

**‚ö†Ô∏è Recomendaci√≥n:** Elimina los recursos inmediatamente despu√©s del workshop para evitar costos innecesarios.

---

## üìä Resumen de Comandos R√°pidos

### Preparaci√≥n Antes del Workshop

```powershell
# 1. Configurar participantes
# Editar: config/participants.json

# 2. Verificar emails en SES
aws ses verify-email-identity --email-address EMAIL --profile <tu-perfil-aws>

# 3. Desplegar VPC compartida (~8 min)
.\scripts\instructor-deploy-network.ps1

# 4. Desplegar LegacyStacks (~20 min para 10 participantes)
.\scripts\instructor-deploy-legacy.ps1

# 5. Verificar despliegue
aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE --profile <tu-perfil-aws>
```

### Durante el Workshop (Participantes)

```powershell
# Participantes despliegan AI Stacks (~5-8 min)
.\scripts\participant-deploy-ai.ps1 -ParticipantPrefix "participant-X" -VerifiedEmail "email@example.com"
```

### Despu√©s del Workshop

```powershell
# Limpieza completa
.\scripts\instructor-cleanup.ps1
```

---

## üìö Documentaci√≥n Adicional

- **Modos de despliegue:** Ver [`cdk/DEPLOY_MODES.md`](cdk/DEPLOY_MODES.md)
- **Configuraci√≥n de participantes:** Ver [`config/README.md`](config/README.md)
- **Arquitectura t√©cnica:** Ver [`.kiro/specs/workshop-deployment-optimization/design.md`](.kiro/specs/workshop-deployment-optimization/design.md)
- **Gu√≠a para participantes:** Ver [`PARTICIPANT_GUIDE.md`](PARTICIPANT_GUIDE.md)

---

## üÜò Soporte Durante el Workshop

### Problemas Comunes

**"Mi despliegue est√° tardando mucho"**
- Tiempo normal: 5-8 minutos
- Si tarda >10 minutos, verificar CloudFormation en consola
- Posible causa: L√≠mites de servicio alcanzados

**"Error: LegacyStack no encontrado"**
- El instructor debe haber desplegado el LegacyStack primero
- Verificar: `aws cloudformation describe-stacks --stack-name participant-X-MedicalReportsLegacyStack`

**"Error: Token expirado"**
- Renovar sesi√≥n: `aws sso login --profile <tu-perfil-aws>`
- Los scripts lo hacen autom√°ticamente

**"No puedo enviar emails"**
- Verificar que el email est√° verificado en SES
- Si la cuenta est√° en SES Sandbox, solo se pueden enviar a emails verificados

### Contacto de Emergencia

Durante el workshop, ten a mano:
- Consola de CloudFormation
- CloudWatch Logs
- Documentaci√≥n de Bedrock
- Este INSTRUCTOR_GUIDE.md

---

**¬°√âxito con tu workshop! üöÄ**
