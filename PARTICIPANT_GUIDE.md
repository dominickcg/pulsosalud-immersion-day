# üéì Gu√≠a para Participantes - Medical Reports Automation Workshop

Bienvenido al workshop de **Automatizaci√≥n de Informes M√©dicos con AWS y Amazon Bedrock**. Esta gu√≠a te llevar√° paso a paso a trav√©s de la implementaci√≥n de un sistema completo de IA Generativa.

## üìÖ Estructura del Workshop

**Duraci√≥n Total:** 3 horas 15 minutos (dividido en 2 d√≠as)

### D√≠a 1 (1h 15min)
- ‚è±Ô∏è **5 min** - Setup inicial y despliegue del sistema legacy
- ‚è±Ô∏è **30 min** - M√≥dulo 1: Extracci√≥n de PDFs con Textract y Bedrock
- ‚è±Ô∏è **30 min** - M√≥dulo 2: Prompt Engineering y experimentaci√≥n
- ‚è±Ô∏è **10 min** - Checkpoint D√≠a 1 y Q&A

### D√≠a 2 (2h)
- ‚è±Ô∏è **30 min** - M√≥dulo 3: RAG con embeddings vectoriales
- ‚è±Ô∏è **30 min** - M√≥dulo 4: Clasificaci√≥n de riesgo con few-shot learning
- ‚è±Ô∏è **30 min** - M√≥dulo 5: Generaci√≥n de res√∫menes y emails personalizados
- ‚è±Ô∏è **30 min** - Experimentaci√≥n libre y Q&A

---

## üöÄ Setup Inicial (5-8 minutos)

### Prerequisitos

Solo necesitas:

- ‚úÖ **Acceso a AWS Console** (proporcionado por el instructor)
- ‚úÖ **Navegador web** (Chrome, Firefox, Edge, Safari)

**¬°Eso es todo!** Usaremos **AWS CloudShell**, que ya tiene todo pre-instalado:
- ‚úÖ AWS CLI configurado autom√°ticamente
- ‚úÖ Node.js y npm
- ‚úÖ Python 3
- ‚úÖ Git
- ‚úÖ Editor de texto (nano, vim)

### Informaci√≥n Proporcionada por el Instructor

El instructor te habr√° proporcionado:

1. **Acceso a AWS Console:**
   - Usuario: `workshop-user-X` (donde X es tu n√∫mero asignado)
   - Contrase√±a temporal
   - Link: https://console.aws.amazon.com/

2. **Tu PARTICIPANT_PREFIX:** `participant-X` (ej: `participant-1`, `participant-2`)

3. **Email verificado:** El email del instructor (el mismo para todos los participantes)

4. **Link al repositorio** del workshop

**Ejemplo de informaci√≥n que recibir√°s:**
- Usuario AWS: `workshop-user-1`
- PARTICIPANT_PREFIX: `participant-1`
- Email del instructor: `instructor@example.com` ‚Üê **Este es el email del instructor, NO tu email personal**

**‚ö†Ô∏è IMPORTANTE:** El instructor ya despleg√≥ la infraestructura base (VPC, Aurora, S3) antes del workshop. T√∫ solo desplegar√°s los AI Stacks durante esta sesi√≥n.

### Paso 1: Abrir AWS CloudShell

1. **Inicia sesi√≥n** en AWS Console con las credenciales proporcionadas
2. **Abre CloudShell**: 
   - Haz clic en el √≠cono de terminal (>_) en la barra superior derecha
   - O busca "CloudShell" en la barra de b√∫squeda
   - Se abrir√° una terminal en tu navegador

![CloudShell est√° en la esquina superior derecha de la consola AWS]

**CloudShell ya tiene todo configurado:**
- ‚úÖ AWS CLI con tus credenciales
- ‚úÖ Node.js, npm, Python, Git
- ‚úÖ 1 GB de almacenamiento persistente

### Paso 2: Clonar el Repositorio

En CloudShell, ejecuta:

```bash
# Clonar repositorio
git clone <repository-url>
cd pulsosalud-immersion-day

# Verificar que est√°s autenticado
aws sts get-caller-identity
```

### Paso 3: Instalar AWS CDK

CloudShell no tiene CDK pre-instalado. Inst√°lalo localmente en el proyecto:

```bash
# Instalar CDK localmente en el proyecto
cd cdk
npm install

# Verificar instalaci√≥n (usar npx para ejecutar)
npx cdk --version
```

**Nota:** Usaremos `npx cdk` en lugar de solo `cdk` para ejecutar comandos CDK.

**Tiempo:** ~2-3 minutos

### Paso 4: Desplegar AI Stacks

El instructor ya despleg√≥:
- ‚úÖ VPC compartida
- ‚úÖ Aurora Serverless v2 (tu base de datos)
- ‚úÖ S3 Bucket (tu almacenamiento)
- ‚úÖ API Gateway y Lambdas Legacy

T√∫ solo necesitas desplegar los **AI Stacks** (las Lambdas de procesamiento de IA):

```bash
# Volver al directorio ra√≠z del proyecto
cd ..

# Dar permisos de ejecuci√≥n al script (necesario en CloudShell)
chmod +x ./scripts/participant-deploy-ai.sh

# Ejecutar el script automatizado
./scripts/participant-deploy-ai.sh participant-1 instructor@example.com
```

Ver script: [`scripts/participant-deploy-ai.sh`](scripts/participant-deploy-ai.sh) o [`scripts/participant-deploy-ai.ps1`](scripts/participant-deploy-ai.ps1) (PowerShell)

**Reemplaza:**
- `participant-1` con tu PARTICIPANT_PREFIX asignado
- `instructor@example.com` con el **email del instructor** (proporcionado por el instructor)

**Tiempo estimado:** 10-15 minutos ‚è±Ô∏è

**Recursos que se desplegar√°n:**
1. **AIExtractionStack** - Extracci√≥n de PDFs con Textract + Bedrock
2. **AIRAGStack** - Embeddings vectoriales con Titan
3. **AIClassificationStack** - Clasificaci√≥n de riesgo con Nova Pro
4. **AISummaryStack** - Generaci√≥n de res√∫menes con Nova Pro
5. **AIEmailStack** - Emails personalizados con Nova Pro + SES

### Paso 5: Verificar Despliegue

Mientras se despliega, puedes ver el progreso en:
- **CloudShell:** Ver√°s el progreso de cada stack en la terminal
- **Consola AWS:** Abre otra pesta√±a y ve a CloudFormation para ver el progreso visual

Una vez completado, ver√°s los outputs de cada stack con los ARNs de las Lambdas.

## üìö D√≠a 1: Extracci√≥n y Prompt Engineering

**‚úÖ Tu infraestructura ya est√° lista:** Si completaste el Setup Inicial, todos tus AI Stacks ya est√°n desplegados y listos para usar.

### M√≥dulo 1: Extracci√≥n de PDFs con Textract y Bedrock (25 min)

**Objetivo:** Procesar tu primer PDF junto con el instructor y ver el sistema funcionando en tiempo real.

**Conceptos Clave:**
```
Textract = "Lee" el texto del PDF (como un esc√°ner inteligente)
Bedrock = "Entiende" qu√© significa cada dato (como un experto m√©dico)

Juntos convierten un PDF en datos estructurados.
```

---

### Parte 1: Procesar un PDF (10 min)

El instructor y t√∫ van a subir un PDF al mismo tiempo y ver c√≥mo se procesa.

#### Paso 1: Obtener el nombre de tu bucket (1 min)

```bash
# Reemplaza participant-1 con tu prefijo
# En CloudShell, ejecuta:
aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`BucketName`].OutputValue' \
  --output text
```

**‚úÖ Guarda este nombre**, lo vas a usar en el siguiente paso.

---

#### Paso 2: Subir tu PDF (2 min)

```bash
# Reemplaza [TU-BUCKET] con el nombre que obtuviste
aws s3 cp sample_data/informe_alto_riesgo.pdf \
  s3://[TU-BUCKET]/external-reports/

# Confirmar que se subi√≥
aws s3 ls s3://[TU-BUCKET]/external-reports/
```

---

#### Paso 3: Ver los logs en tiempo real (5 min)

**‚è±Ô∏è Espera 1-2 minutos** despu√©s de subir el PDF para que la Lambda se ejecute autom√°ticamente.

**Opci√≥n A: Desde CloudShell**
```bash
# Reemplaza participant-1 con tu prefijo
aws logs tail /aws/lambda/participant-1-extract-pdf --follow
```

**Opci√≥n B: Desde la Consola AWS**
1. Abre otra pesta√±a ‚Üí CloudWatch
2. Log groups ‚Üí `/aws/lambda/participant-1-extract-pdf`
3. Click en el log stream m√°s reciente

```
"Aqu√≠ vemos que la Lambda se activ√≥..."
‚Üí Busca en tus logs: Lambda invocation started

"Textract est√° extrayendo el texto del PDF..."
‚Üí Busca en tus logs: Textract completed

"Ahora Bedrock est√° estructurando esos datos..."
‚Üí Busca en tus logs: Bedrock response received

"Y finalmente se est√° guardando en Aurora"
‚Üí Busca en tus logs: Data inserted successfully
```

**‚úÖ Si ves estos 4 mensajes: ¬°Tu PDF se proces√≥ correctamente!**

---

#### Paso 4: Verificar resultado en Aurora (2 min)

**üëâ El instructor dir√°: "Verifiquemos que los datos se guardaron"**

El instructor mostrar√° c√≥mo consultar Aurora. T√∫ puedes hacer lo mismo (opcional):

```sql
-- El instructor mostrar√° esta consulta
SELECT 
  trabajador_nombre,
  presion_arterial,
  nivel_riesgo,
  fecha_examen
FROM informes_medicos 
WHERE origen='EXTERNO'
ORDER BY fecha_creacion DESC
LIMIT 1;
```

**üí° Punto clave:** El PDF se convirti√≥ en datos estructurados que podemos consultar.

---

### Parte 2: Entender el C√≥digo (8 min)

**üéØ Ahora que viste c√≥mo funciona, veamos el c√≥digo**

**üëâ El instructor dir√°: "D√©jenme mostrarles el c√≥digo que hace esto posible"**

El instructor va a abrir `lambda/ai/extract_pdf/index.py` y explicar los 3 pasos. T√∫ puedes seguir abriendo el mismo archivo en CloudShell o en tu editor local.

**Paso 1: Textract Extrae Texto (2 min)**

```python
# Textract lee el PDF y extrae TODO el texto
response = textract_client.analyze_document(
    Document={'S3Object': {'Bucket': bucket, 'Name': key}},
    FeatureTypes=['TABLES', 'FORMS']
)
```

**üí° Mientras el instructor explica:**
- Textract lee el PDF y extrae TODO el texto, incluyendo tablas
- Pero solo extrae, no entiende qu√© significa cada cosa

---

**Paso 2: Bedrock Estructura Datos (4 min)**

```python
# Bedrock ENTIENDE el contexto y estructura en JSON
bedrock_response = bedrock_runtime.invoke_model(
    modelId='us.amazon.nova-pro-v1:0',
    body=json.dumps({
        "messages": [{"role": "user", "content": prompt}],
        "inferenceConfig": {
            "temperature": 0.1,  # Baja para precisi√≥n
            "maxTokens": 2000
        }
    })
)
```

**üí° Mientras el instructor explica:**
- Le decimos a Bedrock: "Toma este texto y extrae estos campos en JSON"
- Bedrock ENTIENDE que '140/90' es presi√≥n arterial, no un tel√©fono
- Temperature 0.1 = respuestas m√°s precisas y consistentes

---

**Paso 3: Guardar en Aurora (2 min)**

```python
# Insertar en base de datos
cursor.execute("""
    INSERT INTO informes_medicos 
    (trabajador_nombre, presion_arterial, ...)
    VALUES (%s, %s, ...)
""", (datos['trabajador_nombre'], datos['presion_arterial'], ...))
```

**üí° Mientras el instructor explica:**
- Finalmente guardamos en la base de datos
- Ahora los datos est√°n listos para consultar y analizar

---

### Parte 3: Ejercicio Individual (7 min)

**üéØ Ahora procesa otro PDF por tu cuenta**

**üëâ El instructor dir√°: "Ahora cada uno va a procesar un PDF diferente"**

#### Tu tarea:

1. **Sube otro PDF** (usa `informe_medio_riesgo.pdf` esta vez)
   ```bash
   aws s3 cp sample_data/informe_medio_riesgo.pdf \
     s3://[TU-BUCKET]/external-reports/
   ```

2. **Ve los logs** para confirmar que se proces√≥
   ```bash
   aws logs tail /aws/lambda/participant-1-extract-pdf --follow
   ```

3. **Levanta la mano virtual** o escribe en el chat cuando termines

**‚úÖ Criterio de √©xito:**
- Ves "Data inserted successfully" en los logs
- El instructor confirma que todos completaron

**‚ùå Si algo falla:**
- Verifica que el PDF est√° en `external-reports/`
- Verifica que usaste tu prefijo correcto
- Escribe en el chat o pide ayuda al instructor

---

### üéì Resumen del M√≥dulo 1

**Lo que lograste:**
- ‚úÖ Viste el sistema funcionando en tiempo real
- ‚úÖ Entendiste c√≥mo Textract y Bedrock trabajan juntos
- ‚úÖ Procesaste tu primer PDF autom√°ticamente
- ‚úÖ Verificaste que los datos se guardaron en Aurora

**Concepto clave:** 
> Textract + Bedrock = PDF no estructurado ‚Üí Datos estructurados utilizables

**Pr√≥ximo m√≥dulo:** Vamos a aprender c√≥mo mejorar la calidad de extracci√≥n con Prompt Engineering.

---

### ‚ùì Preguntas Frecuentes del M√≥dulo 1

**P: ¬øPor qu√© no veo logs inmediatamente?**
R: Los logs pueden tardar 1-2 minutos en aparecer. Ten paciencia.

**P: ¬øQu√© pasa si subo el PDF a otra carpeta?**
R: La Lambda solo se activa con PDFs en `external-reports/`. Otros folders no funcionar√°n.

**P: ¬øPuedo subir mis propios PDFs?**
R: S√≠, pero deben ser informes m√©dicos similares a los ejemplos para que el prompt funcione bien.

**P: ¬øCu√°nto cuesta procesar un PDF?**
R: Aproximadamente $0.02-0.05 USD por PDF (Textract + Bedrock + almacenamiento).

---

### M√≥dulo 2: Prompt Engineering y Experimentaci√≥n (30 min)

#### Objetivo
Entender c√≥mo iterar y mejorar prompts para obtener mejores resultados.

#### Ejercicio 1: Comparar Versiones de Prompts

Revisa las 3 versiones del prompt de extracci√≥n:

**Versi√≥n 1** ([`prompts/extraction_v1.txt`](prompts/extraction_v1.txt)):
```
Extrae datos del siguiente informe m√©dico.
```
‚ùå Muy vago, resultados inconsistentes

**Versi√≥n 2** ([`prompts/extraction_v2.txt`](prompts/extraction_v2.txt)):
```
Extrae los siguientes campos del informe m√©dico:
- Nombre del trabajador
- Presi√≥n arterial
...
Devuelve en formato JSON.
```
‚ö†Ô∏è Mejor, pero sin ejemplos

**Versi√≥n 3** ([`prompts/extraction.txt`](prompts/extraction.txt)):
```
Eres un asistente especializado en extraer datos de informes m√©dicos.

Extrae la siguiente informaci√≥n y devu√©lvela en formato JSON:
{
  "trabajador_nombre": "string",
  "presion_arterial": "string",
  ...
}

IMPORTANTE: 
- Si un campo no est√° presente, usa null
- Mant√©n el formato exacto del JSON
- No inventes datos
```
‚úÖ Espec√≠fico, con estructura y reglas claras

**Lecci√≥n:** Los prompts espec√≠ficos con ejemplos y reglas producen mejores resultados.

#### Ejercicio 2: Experimentar con Temperature

La **temperature** controla la aleatoriedad de las respuestas:
- **0.0 - 0.3**: Determin√≠stico, preciso (ideal para extracci√≥n)
- **0.4 - 0.7**: Balanceado (ideal para res√∫menes)
- **0.8 - 1.0**: Creativo, variado (ideal para contenido)

**Pr√°ctica:**

1. Abre [`lambda/ai/extract_pdf/index.py`](lambda/ai/extract_pdf/index.py)
2. Cambia `temperature: 0.1` a `temperature: 0.8`
3. Re-despliega:
   ```bash
   cd cdk
   cdk deploy AIExtractionStack
   ```
4. Sube el mismo PDF otra vez
5. Compara resultados

**Pregunta:** ¬øQu√© diferencias notas?

#### Ejercicio 3: Experimentar con max_tokens

El par√°metro **maxTokens** limita la longitud de la respuesta:

1. Cambia `maxTokens: 2000` a `maxTokens: 500`
2. Re-despliega
3. Observa si la respuesta se corta

**Lecci√≥n:** Ajusta maxTokens seg√∫n la complejidad de la tarea.

---

### üéØ Checkpoint D√≠a 1 (10 min)

Verifica que todo funciona:

```bash
# 1. Sistema legacy desplegado
aws cloudformation describe-stacks --stack-name LegacyStack

# 2. Sistema de extracci√≥n desplegado
aws cloudformation describe-stacks --stack-name AIExtractionStack

# 3. PDF procesado correctamente
psql -h <aurora-endpoint> -U postgres -d medical_reports \
  -c "SELECT COUNT(*) FROM informes_medicos WHERE origen='EXTERNO';"

# Deber√≠a retornar al menos 1
```

**Preguntas para reflexionar:**
- ¬øC√≥mo funciona Textract vs Bedrock?
- ¬øPor qu√© usamos temperature baja para extracci√≥n?
- ¬øQu√© hace que un prompt sea efectivo?

---

## üìö D√≠a 2: RAG, Clasificaci√≥n y Personalizaci√≥n

### M√≥dulo 3: RAG con Embeddings Vectoriales (30 min)

#### Objetivo
Implementar RAG (Retrieval-Augmented Generation) para proporcionar contexto hist√≥rico a las respuestas de IA.

#### ¬øQu√© es RAG?

**RAG** = Retrieval-Augmented Generation

1. **Retrieval**: Buscar informaci√≥n relevante en una base de datos
2. **Augmented**: Agregar esa informaci√≥n al prompt
3. **Generation**: Generar respuesta con contexto

**Beneficios:**
- ‚úÖ Reduce alucinaciones
- ‚úÖ Proporciona contexto espec√≠fico
- ‚úÖ Mejora precisi√≥n de respuestas

#### Paso 1: Desplegar Stack RAG

```bash
cd cdk
cdk deploy AIRAGStack
```

**Recursos creados:**
- Lambda para generar embeddings
- Permisos para Amazon Titan Embeddings

#### Paso 2: Entender Embeddings

Los **embeddings** son representaciones vectoriales de texto:

```python
# Texto original
"Presi√≥n arterial: 140/90 mmHg"

# Embedding (vector de 1024 dimensiones)
[0.123, -0.456, 0.789, ..., 0.234]
```

**Ventaja:** Textos similares tienen embeddings similares.

#### Paso 3: Generar Embeddings

```bash
# Generar embeddings para un informe
aws lambda invoke \
  --function-name generate-embeddings \
  --payload '{"informe_id": 1}' \
  response.json

# Ver resultado
cat response.json
```

#### Paso 4: Revisar C√≥digo de B√∫squeda

Abre [`lambda/shared/similarity_search.py`](lambda/shared/similarity_search.py):

```python
def buscar_informes_similares(trabajador_id, embedding_actual, limit=3):
    """
    Busca informes anteriores del mismo trabajador usando similitud coseno.
    """
    sql = """
        SELECT 
            ie.informe_id,
            ie.contenido,
            1 - (ie.embedding <=> %s::vector) as similarity
        FROM informes_embeddings ie
        WHERE ie.trabajador_id = %s
          AND ie.informe_id != %s
        ORDER BY ie.embedding <=> %s::vector
        LIMIT %s
    """
```

**Conceptos clave:**
- `<=>` es el operador de distancia coseno de pgvector
- Menor distancia = mayor similitud
- Filtramos por trabajador_id para contexto relevante

#### Paso 5: Probar B√∫squeda RAG

```bash
# Crear varios informes para el mismo trabajador
aws lambda invoke \
  --function-name generate-test-data \
  --payload '{"trabajador_id": 1, "cantidad": 3}' \
  response.json

# Generar embeddings para todos
for i in {1..3}; do
  aws lambda invoke \
    --function-name generate-embeddings \
    --payload "{\"informe_id\": $i}" \
    response.json
done

# Ahora la b√∫squeda RAG encontrar√° informes anteriores
```

---

### M√≥dulo 4: Clasificaci√≥n de Riesgo con Few-Shot Learning (30 min)

#### Objetivo
Clasificar informes m√©dicos en niveles de riesgo (BAJO, MEDIO, ALTO) usando few-shot learning.

#### ¬øQu√© es Few-Shot Learning?

**Few-shot learning** = Ense√±ar al modelo con pocos ejemplos en el prompt.

```
Clasifica el siguiente informe m√©dico en: BAJO, MEDIO o ALTO riesgo.

Ejemplos:

BAJO: Presi√≥n 118/75, IMC 23.5, sin antecedentes
MEDIO: Presi√≥n 135/85, IMC 27.2, colesterol elevado
ALTO: Presi√≥n 155/95, IMC 32.1, diabetes tipo 2

Ahora clasifica este informe:
[informe actual]
```

#### Paso 1: Desplegar Stack de Clasificaci√≥n

```bash
cd cdk
cdk deploy AIClassificationStack
```

#### Paso 2: Revisar Prompt de Clasificaci√≥n

Abre [`prompts/classification.txt`](prompts/classification.txt):

```
Eres un m√©dico ocupacional experto en evaluar riesgos laborales.

Clasifica el siguiente informe en uno de estos niveles:
- BAJO: Par√°metros normales, apto sin restricciones
- MEDIO: Par√°metros lim√≠trofes, requiere seguimiento
- ALTO: Par√°metros alterados, requiere atenci√≥n inmediata

EJEMPLOS:

[Ejemplo BAJO con datos espec√≠ficos]
[Ejemplo MEDIO con datos espec√≠ficos]
[Ejemplo ALTO con datos espec√≠ficos]

CONTEXTO HIST√ìRICO:
[Informes anteriores del trabajador - proporcionado por RAG]

INFORME ACTUAL:
[Datos del informe]

Responde en formato JSON:
{
  "nivel_riesgo": "BAJO|MEDIO|ALTO",
  "justificacion": "explicaci√≥n detallada"
}
```

**Nota:** El contexto hist√≥rico viene de RAG.

#### Paso 3: Clasificar un Informe

```bash
# Clasificar informe
aws lambda invoke \
  --function-name classify-risk \
  --payload '{"informe_id": 1}' \
  response.json

# Ver resultado
cat response.json
```

#### Paso 4: Verificar Clasificaci√≥n en Aurora

```bash
psql -h <aurora-endpoint> -U postgres -d medical_reports

SELECT 
  id,
  trabajador_nombre,
  nivel_riesgo,
  justificacion_riesgo
FROM informes_completos
WHERE id = 1;
```

#### Ejercicio: Comparar Versiones de Prompts

Revisa las 3 versiones del prompt de clasificaci√≥n:

**Versi√≥n 1** ([`prompts/classification_v1.txt`](prompts/classification_v1.txt)):
- Sin ejemplos
- Resultados inconsistentes

**Versi√≥n 2** ([`prompts/classification_v2.txt`](prompts/classification_v2.txt)):
- Con ejemplos b√°sicos
- Mejor, pero sin contexto hist√≥rico

**Versi√≥n 3** ([`prompts/classification.txt`](prompts/classification.txt)):
- Con ejemplos detallados
- Con contexto hist√≥rico (RAG)
- Resultados precisos y consistentes

**Lecci√≥n:** Few-shot learning + RAG = Clasificaci√≥n precisa

---

### M√≥dulo 5: Res√∫menes y Emails Personalizados (30 min)

#### Objetivo
Generar res√∫menes ejecutivos y emails personalizados seg√∫n el nivel de riesgo.

#### Paso 1: Desplegar Stacks de Resumen y Email

```bash
cd cdk
cdk deploy AISummaryStack
cdk deploy AIEmailStack
```

#### Paso 2: Generar Resumen Ejecutivo

```bash
# Generar resumen
aws lambda invoke \
  --function-name generate-summary \
  --payload '{"informe_id": 1}' \
  response.json

# Ver resultado
cat response.json
```

**Caracter√≠sticas del resumen:**
- M√°ximo 150 palabras
- Lenguaje claro y no t√©cnico
- Incluye tendencias hist√≥ricas (RAG)
- Enfocado en lo m√°s importante

#### Paso 3: Revisar Prompt de Resumen

Abre [`prompts/summary.txt`](prompts/summary.txt):

```
Genera un resumen ejecutivo del informe m√©dico.

REQUISITOS:
- M√°ximo 150 palabras
- Lenguaje claro, no t√©cnico
- Enf√≥cate en hallazgos principales
- Incluye tendencias si hay informes anteriores

CONTEXTO HIST√ìRICO:
[Informes anteriores - proporcionado por RAG]

INFORME ACTUAL:
[Datos del informe]

FORMATO:
P√°rrafo √∫nico, directo y accionable.
```

**Par√°metros:**
- `temperature: 0.5` (balanceado entre precisi√≥n y fluidez)
- `maxTokens: 300`

#### Paso 4: Enviar Email Personalizado

```bash
# Enviar email
aws lambda invoke \
  --function-name send-email \
  --payload '{"informe_id": 1}' \
  response.json
```

#### Paso 5: Revisar Prompts de Email

Hay 3 prompts diferentes seg√∫n el nivel de riesgo:

**Email Riesgo ALTO** ([`prompts/email_high.txt`](prompts/email_high.txt)):
```
Genera un email URGENTE para el contratista.

TONO: Urgente pero profesional
OBJETIVO: Acci√≥n inmediata

Incluye:
- Hallazgos cr√≠ticos
- Acciones requeridas INMEDIATAMENTE
- Consecuencias de no actuar
```

**Email Riesgo MEDIO** ([`prompts/email_medium.txt`](prompts/email_medium.txt)):
```
Genera un email PROFESIONAL para el contratista.

TONO: Profesional y constructivo
OBJETIVO: Seguimiento programado

Incluye:
- Hallazgos que requieren atenci√≥n
- Recomendaciones de seguimiento
- Plazo sugerido
```

**Email Riesgo BAJO** ([`prompts/email_low.txt`](prompts/email_low.txt)):
```
Genera un email TRANQUILIZADOR para el contratista.

TONO: Positivo y alentador
OBJETIVO: Confirmar estado saludable

Incluye:
- Confirmaci√≥n de par√°metros normales
- Felicitaci√≥n por mantener salud
- Recordatorio de controles peri√≥dicos
```

**Par√°metros:**
- `temperature: 0.7` (m√°s creativo para personalizaci√≥n)
- `maxTokens: 500`

#### Paso 6: Verificar Email Recibido

Revisa tu bandeja de entrada. Deber√≠as recibir un email personalizado seg√∫n el nivel de riesgo del informe.

---

### üé® Experimentaci√≥n Libre (30 min)

Ahora es tu turno de experimentar. Aqu√≠ hay algunas ideas:

#### Experimento 1: Modificar Tono de Emails

1. Abre [`prompts/email_high.txt`](prompts/email_high.txt)
2. Cambia "URGENTE" por "IMPORTANTE"
3. Re-despliega: `cdk deploy AIEmailStack`
4. Env√≠a otro email y compara

#### Experimento 2: Ajustar Longitud de Res√∫menes

1. Abre [`prompts/summary.txt`](prompts/summary.txt)
2. Cambia "M√°ximo 150 palabras" a "M√°ximo 50 palabras"
3. Re-despliega: `cdk deploy AISummaryStack`
4. Genera otro resumen y compara

#### Experimento 3: Agregar M√°s Ejemplos a Clasificaci√≥n

1. Abre [`prompts/classification.txt`](prompts/classification.txt)
2. Agrega un 4to ejemplo con un caso espec√≠fico
3. Re-despliega: `cdk deploy AIClassificationStack`
4. Clasifica varios informes y observa mejoras

#### Experimento 4: Cambiar Temperature

Prueba diferentes valores de temperature:

| Temperature | Uso Ideal | Resultado |
|-------------|-----------|-----------|
| 0.0 - 0.2 | Extracci√≥n, clasificaci√≥n | Determin√≠stico, preciso |
| 0.3 - 0.5 | Res√∫menes, an√°lisis | Balanceado |
| 0.6 - 0.8 | Emails, contenido | Creativo, variado |
| 0.9 - 1.0 | Brainstorming | Muy creativo |

#### Experimento 5: Comparar Con y Sin RAG

1. Modifica [`lambda/ai/classify_risk/index.py`](lambda/ai/classify_risk/index.py)
2. Comenta la secci√≥n que agrega contexto hist√≥rico
3. Re-despliega y compara resultados

**Pregunta:** ¬øC√≥mo mejora RAG la precisi√≥n?

---

## üîß Troubleshooting

### Error: "Model access denied"

**Causa:** Permisos IAM insuficientes.

**Soluci√≥n:**
```bash
# Verifica que tu usuario tiene permisos bedrock:InvokeModel
# Los modelos se habilitan autom√°ticamente en la primera invocaci√≥n
```

### Error: "Database connection failed"

**Causa:** Lambda no puede conectar a Aurora.

**Soluci√≥n:**
```bash
# Verifica que Lambda est√° en la misma VPC que Aurora
# Verifica security groups
```

### Error: "Email not verified"

**Causa:** No verificaste tu email en SES.

**Soluci√≥n:**
```bash
aws ses verify-email-identity --email-address tu-email@ejemplo.com
# Confirma desde el email que recibir√°s
```

### Error: "S3 bucket already exists"

**Causa:** Otro participante usa el mismo prefijo.

**Soluci√≥n:**
```bash
# Cambia tu prefijo √∫nico en cdk/bin/app.ts
# Ejemplo: 'participant-john-2'
```

### Logs no aparecen en CloudWatch

**Soluci√≥n:**
```bash
# Espera 1-2 minutos para que aparezcan
# O usa:
aws logs tail /aws/lambda/<function-name> --follow
```

---

## üßπ Limpieza de Recursos

Al finalizar el workshop, elimina todos los recursos:

```bash
cd cdk

# Eliminar todos los stacks
cdk destroy --all

# Confirmar: y

# Verificar que todo se elimin√≥
aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE
```

**Importante:** Aurora se eliminar√° autom√°ticamente sin crear snapshots (configurado para la demo).

---

## üìä Resumen de Conceptos Aprendidos

### Servicios AWS
- ‚úÖ **Amazon Bedrock** - LLMs como servicio
- ‚úÖ **Amazon Nova Pro** - Modelo de lenguaje avanzado
- ‚úÖ **Amazon Titan Embeddings** - Generaci√≥n de embeddings
- ‚úÖ **Amazon Textract** - OCR para PDFs
- ‚úÖ **Aurora Serverless v2** - Base de datos con pgvector
- ‚úÖ **Lambda** - Funciones serverless
- ‚úÖ **S3** - Almacenamiento de objetos
- ‚úÖ **SES** - Env√≠o de emails
- ‚úÖ **CDK** - Infraestructura como c√≥digo

### T√©cnicas de IA Generativa
- ‚úÖ **Prompt Engineering** - Dise√±o de prompts efectivos
- ‚úÖ **Few-Shot Learning** - Aprendizaje con pocos ejemplos
- ‚úÖ **RAG** - Retrieval-Augmented Generation
- ‚úÖ **Embeddings Vectoriales** - Representaci√≥n de texto
- ‚úÖ **Temperature Control** - Control de aleatoriedad
- ‚úÖ **Token Management** - Gesti√≥n de longitud de respuestas

### Mejores Pr√°cticas
- ‚úÖ Prompts espec√≠ficos con ejemplos
- ‚úÖ Temperature baja para precisi√≥n
- ‚úÖ RAG para reducir alucinaciones
- ‚úÖ Iteraci√≥n de prompts
- ‚úÖ Validaci√≥n de salidas
- ‚úÖ Monitoreo con CloudWatch

---

## üéØ Pr√≥ximos Pasos

Despu√©s del workshop, puedes:

1. **Experimentar m√°s** con diferentes prompts y par√°metros
2. **Agregar nuevos casos de uso** (ej: an√°lisis de tendencias)
3. **Integrar con otros servicios** (ej: Step Functions para orquestaci√≥n)
4. **Optimizar costos** ajustando modelos y par√°metros
5. **Implementar en producci√≥n** con mejores pr√°cticas de seguridad

---

## üìö Recursos Adicionales

- [Amazon Bedrock Documentation](https://docs.aws.amazon.com/bedrock/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [AWS CDK Documentation](https://docs.aws.amazon.com/cdk/)
- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [RAG Best Practices](https://aws.amazon.com/blogs/machine-learning/rag-best-practices/)

---

## ‚ùì Preguntas Frecuentes

**P: ¬øCu√°nto cuesta ejecutar esta demo?**
R: Aproximadamente $5-10 USD por participante (Aurora + Bedrock + otros servicios).

**P: ¬øPuedo usar otros modelos de Bedrock?**
R: S√≠, puedes cambiar el modelId en el c√≥digo. Ejemplos: Claude, Llama, etc.

**P: ¬øFunciona en otras regiones?**
R: S√≠, pero verifica disponibilidad de Bedrock en tu regi√≥n.

**P: ¬øC√≥mo escalo esto a producci√≥n?**
R: Agrega: autenticaci√≥n, rate limiting, monitoreo avanzado, CI/CD, y backups.

**P: ¬øPuedo usar mis propios PDFs?**
R: S√≠, sube cualquier PDF m√©dico a S3 en la carpeta `/external-reports/`.

---

**¬°Felicitaciones!** üéâ Has completado el workshop de Automatizaci√≥n de Informes M√©dicos con AWS y Amazon Bedrock.

¬øPreguntas? Consulta con el instructor o revisa la [Gu√≠a del Instructor](INSTRUCTOR_GUIDE.md).


---

## üèóÔ∏è Arquitectura del Workshop (Informaci√≥n Adicional)

### ¬øPor qu√© el despliegue es tan r√°pido ahora?

El workshop usa una **arquitectura optimizada** que separa la infraestructura en dos capas:

#### Capa 1: Infraestructura Base (Desplegada por el Instructor)
- **SharedNetworkStack:** VPC compartida para todos los participantes
- **LegacyStack:** Tu Aurora, S3, API Gateway y Lambdas Legacy
- **Tiempo:** ~15 minutos por participante (desplegado antes del workshop)

#### Capa 2: AI Stacks (Desplegada por Ti)
- **5 AI Stacks:** Lambdas de procesamiento de IA
- **Tiempo:** ~5-8 minutos (desplegado durante el workshop)

### Beneficios de esta Arquitectura

‚úÖ **M√°s tiempo para aprender:** 70-80% menos tiempo de despliegue en vivo
‚úÖ **Recursos compartidos:** VPC compartida reduce costos
‚úÖ **Aislamiento completo:** Cada participante tiene su propia Aurora y S3
‚úÖ **Despliegue paralelo:** El instructor puede preparar m√∫ltiples participantes simult√°neamente

### Recursos que Tienes

Despu√©s del despliegue, tienes acceso a:

**Base de Datos:**
- Aurora Serverless v2 (PostgreSQL 15.8 con pgvector)
- Credenciales en AWS Secrets Manager
- Tablas: `patients`, `exams`, `exam_embeddings`

**Almacenamiento:**
- S3 Bucket individual: `<tu-prefix>-medical-reports-<account-id>`
- Carpetas: `external-reports/`, `generated-reports/`

**APIs:**
- API Gateway con endpoints:
  - `POST /examenes` - Registrar examen
  - `POST /examenes/generar-prueba` - Generar datos de prueba

**Lambdas de IA:**
- `extract-pdf` - Extracci√≥n con Textract + Bedrock
- `generate-embeddings` - Embeddings con Titan
- `classify-risk` - Clasificaci√≥n con Nova Pro
- `generate-summary` - Res√∫menes con Nova Pro
- `send-email` - Emails con Nova Pro + SES

### Documentaci√≥n Adicional

- **Modos de despliegue:** Ver [`cdk/DEPLOY_MODES.md`](cdk/DEPLOY_MODES.md)
- **Gu√≠a del instructor:** Ver [`INSTRUCTOR_GUIDE.md`](INSTRUCTOR_GUIDE.md)
- **Arquitectura t√©cnica:** Ver [`.kiro/specs/workshop-deployment-optimization/design.md`](.kiro/specs/workshop-deployment-optimization/design.md)

---

## üÜò Soporte

Si tienes problemas durante el workshop:

1. **Revisa la secci√≥n de Troubleshooting** en el Setup Inicial
2. **Verifica CloudFormation** en la consola AWS
3. **Consulta CloudWatch Logs** para errores de Lambda
4. **Contacta al instructor** para ayuda

---

**¬°Disfruta el workshop y aprende mucho! üöÄ**
