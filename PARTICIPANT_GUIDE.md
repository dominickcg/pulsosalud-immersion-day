# üéì Gu√≠a para Participantes - Medical Reports Automation Workshop

Bienvenido al workshop de **Automatizaci√≥n de Informes M√©dicos con AWS y Amazon Bedrock**. Esta gu√≠a te llevar√° paso a paso a trav√©s de la implementaci√≥n de un sistema que optimiza el env√≠o de informes m√©dicos a clientes usando IA Generativa.

## üè• El Problema de Negocio

Una empresa de salud ocupacional realiza ex√°menes m√©dicos a trabajadores de empresas contratistas (mineras, constructoras, etc.). 

**Situaci√≥n Actual:**
- Realizan 500+ ex√°menes m√©dicos por mes
- Deben enviar informes a las empresas clientes
- Cada informe requiere:
  - Revisi√≥n manual por m√©dico
  - Clasificaci√≥n de nivel de riesgo
  - Creaci√≥n de resumen ejecutivo
  - Redacci√≥n de email personalizado

**Objetivo del Workshop:**
Automatizar este proceso usando Amazon Bedrock para:
1. ‚úÖ Clasificar autom√°ticamente el nivel de riesgo (BAJO/MEDIO/ALTO)
2. ‚úÖ Generar res√∫menes ejecutivos personalizados
3. ‚úÖ Crear emails con el tono adecuado seg√∫n la urgencia
4. ‚úÖ Reducir tiempo de procesamiento de 20-30 min a 2 min por informe

## üìÖ Estructura del Workshop

**Duraci√≥n Total:** 3 horas 15 minutos (dividido en 2 d√≠as)

### D√≠a 1: Clasificaci√≥n y Res√∫menes con IA (1h 15min)
- ‚è±Ô∏è **5 min** - Setup inicial: Despliegue de AI Stacks (3-5 min de espera)
- ‚è±Ô∏è **30 min** - M√≥dulo 1: Clasificaci√≥n autom√°tica de riesgo con IA
- ‚è±Ô∏è **30 min** - M√≥dulo 2: Generaci√≥n de res√∫menes ejecutivos
- ‚è±Ô∏è **10 min** - Checkpoint D√≠a 1

### D√≠a 2: Capacidades Avanzadas (2h)
- ‚è±Ô∏è **30 min** - M√≥dulo 3: Emails personalizados por nivel de riesgo
- ‚è±Ô∏è **30 min** - M√≥dulo 4: RAG con embeddings vectoriales (contexto hist√≥rico)
- ‚è±Ô∏è **30 min** - M√≥dulo 5: Integraci√≥n de PDFs externos (cl√≠nicas externas)
- ‚è±Ô∏è **30 min** - Experimentaci√≥n libre y Q&A

---

## üöÄ Setup Inicial (5-8 minutos)

### Prerequisitos

Solo necesitas:

- ‚úÖ **Acceso a AWS Console** (proporcionado por el instructor)
- ‚úÖ **Navegador web** (Chrome, Firefox, Edge, Safari)

**¬°Eso es todo!** Usaremos **AWS CloudShell**, que ya tiene todo pre-instalado:
- ‚úÖ AWS CLI configurado autom√°ticamente
- ‚úÖ Node.js y npm
- ‚úÖ Python 3
- ‚úÖ Git
- ‚úÖ Editor de texto (nano, vim)

### Informaci√≥n Proporcionada por el Instructor

**Ejemplo de informaci√≥n que recibir√°s:**
- Usuario AWS: `workshop-user-1`
- PARTICIPANT_PREFIX: `participant-1`
- Email del instructor: `instructor@example.com` ‚Üê **Este es el email del instructor, NO tu email personal**

**‚ö†Ô∏è IMPORTANTE:** El instructor ya despleg√≥ la infraestructura base (VPC, Aurora, S3, App Web) antes del workshop. T√∫ solo desplegar√°s los AI Stacks (2 stacks, 3-5 minutos) durante esta sesi√≥n.

### Paso 1: Abrir AWS CloudShell

1. **Inicia sesi√≥n** en AWS Console con las credenciales proporcionadas
2. **Abre CloudShell**: 
   - Haz clic en el √≠cono de terminal (>_) en la barra superior derecha
   - O busca "CloudShell" en la barra de b√∫squeda
   - Se abrir√° una terminal en tu navegador

![CloudShell est√° en la esquina superior derecha de la consola AWS]

**CloudShell ya tiene todo configurado:**
- ‚úÖ AWS CLI con tus credenciales
- ‚úÖ Node.js, npm, Python, Git
- ‚úÖ 1 GB de almacenamiento persistente

### Paso 2: Clonar el Repositorio

En CloudShell, ejecuta:

```bash
# Clonar repositorio
git clone https://github.com/tu-organizacion/pulsosalud-immersion-day.git
cd pulsosalud-immersion-day

# Verificar que est√°s autenticado
aws sts get-caller-identity
```

**Deber√≠as ver tu informaci√≥n de cuenta AWS.**

### Paso 3: Instalar Dependencias del Proyecto

```bash
# Instalar dependencias de CDK
cd cdk
npm install

# Verificar instalaci√≥n
npx cdk --version
```

**Output esperado:** `2.x.x (build xxxxx)`

**Nota:** En CloudShell usamos `npx cdk` en lugar de solo `cdk` para ejecutar comandos CDK.

**Tiempo:** ~2-3 minutos

Mientras se instala, el instructor explicar√° la arquitectura del workshop.

### Paso 4: Desplegar AI Stacks del D√≠a 1

El instructor ya despleg√≥:
- ‚úÖ VPC compartida (PulsoSaludNetworkStack)
- ‚úÖ Aurora Serverless v2 con datos de ejemplo (10 informes m√©dicos)
- ‚úÖ S3 Buckets para almacenamiento
- ‚úÖ API Gateway con endpoints
- ‚úÖ App Web para visualizar y ejecutar acciones
- ‚úÖ Lambdas Legacy (registro de ex√°menes, listado)

T√∫ solo necesitas desplegar los **AI Stacks del D√≠a 1** (3 stacks):

```bash
# Aseg√∫rate de estar en el directorio CDK
cd ~/pulsosalud-immersion-day/cdk

# Configurar variables de entorno (IMPORTANTE)
# Reemplaza participant-1 con tu PARTICIPANT_PREFIX
export PARTICIPANT_PREFIX=participant-1
export DEPLOY_MODE=ai

# Desplegar los AI Stacks del D√≠a 1
# Nota: AIRAGStack se despliega autom√°ticamente como dependencia
npx cdk deploy $PARTICIPANT_PREFIX-AIClassificationStack $PARTICIPANT_PREFIX-AISummaryStack --require-approval never
```

**‚ö†Ô∏è IMPORTANTE:** Reemplaza `participant-1` con tu PARTICIPANT_PREFIX asignado por el instructor (ej: `participant-2`, `participant-3`, etc.)

**Tiempo estimado:** 6-8 minutos

**Recursos que se desplegar√°n:**
1. **AIRAGStack** (dependencia) - Lambda generate-embeddings + Layer de similarity search
2. **AIClassificationStack** - Lambda classify-risk con Bedrock Nova Pro
3. **AISummaryStack** - Lambda generate-summary con Bedrock Nova Pro

Mientras esperas, el instructor explicar√° la arquitectura del sistema en pantalla compartida.

**Recursos que se desplegar√°n (D√≠a 1):**
1. **AIClassificationStack** - Lambda classify-risk con Bedrock Nova Pro
2. **AISummaryStack** - Lambda generate-summary con Bedrock Nova Pro

**Recursos del D√≠a 2** (se desplegar√°n en la segunda sesi√≥n):
- AIEmailStack - Emails personalizados
- AIRAGStack - Embeddings vectoriales avanzados
- AIExtractionStack - Integraci√≥n de PDFs externos

### Paso 5: Obtener la URL de tu App Web

Una vez completado el despliegue, obt√©n la URL de tu app web:

```bash
# Obtener la URL de tu app web
aws cloudformation describe-stacks \
  --stack-name $PARTICIPANT_PREFIX-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`AppWebUrl`].OutputValue' \
  --output text
```

**Output esperado:**
```
http://participant-1-app-web-123456789012.s3-website.us-east-2.amazonaws.com
```

**Copia la URL** y √°brela en una nueva pesta√±a de tu navegador.

---

**Tu App Web incluye:**
- **Lista de informes m√©dicos** - 10 informes de ejemplo pre-cargados
- **Vista de detalle** - Presi√≥n arterial, IMC, antecedentes, etc.
- **Bot√≥n "Clasificar con IA"** - Llama a tu Lambda classify-risk
- **Bot√≥n "Generar Resumen"** - Llama a tu Lambda generate-summary
- **Estad√≠sticas en tiempo real** - Contadores y distribuci√≥n de riesgo

**Deber√≠as ver:**
- Una tabla con 10 informes m√©dicos
- Cada informe tiene datos completos (nombre, presi√≥n, IMC, etc.)
- Botones de acci√≥n en cada fila
- Panel de estad√≠sticas en la parte superior

**¬°Listo!** Ya puedes empezar con el M√≥dulo 1.

## üìö D√≠a 1: Optimizaci√≥n del Env√≠o de Informes

**‚úÖ Tu infraestructura ya est√° lista:** Si completaste el Setup Inicial, todos tus AI Stacks ya est√°n desplegados y listos para usar.

### M√≥dulo 1: Clasificaci√≥n Autom√°tica de Riesgo (30 min)

**Objetivo:** Automatizar la clasificaci√≥n de informes m√©dicos en niveles de riesgo usando Amazon Bedrock.

#### üéØ El Problema

**Situaci√≥n Actual:**
- Un m√©dico debe revisar CADA informe manualmente
- Debe decidir si es riesgo BAJO, MEDIO o ALTO
- Esto toma 10-15 minutos por informe
- Con 500 informes/mes = 125 horas de trabajo manual
- Riesgo de inconsistencia en criterios entre m√©dicos

**La Soluci√≥n con IA:**
- Amazon Bedrock clasifica autom√°ticamente usando few-shot learning
- Consistencia 100% en criterios de clasificaci√≥n
- Tiempo reducido a 30 segundos por informe
- M√©dico solo revisa casos cr√≠ticos (ALTO riesgo)

**Conceptos Clave:**
```
Few-Shot Learning = Ense√±ar al modelo con pocos ejemplos
Bedrock Nova Pro = Modelo de lenguaje que "entiende" contexto m√©dico
RAG = Buscar informes anteriores del mismo trabajador para contexto
```

**Flujo de Clasificaci√≥n:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Informe     ‚îÇ
‚îÇ M√©dico      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Buscar Informes Anteriores (RAG)    ‚îÇ
‚îÇ    ‚Ä¢ Query SQL: √∫ltimos 3 informes      ‚îÇ
‚îÇ    ‚Ä¢ Mismo trabajador                   ‚îÇ
‚îÇ    ‚Ä¢ Ordenados por fecha DESC           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Construir Prompt con Few-Shot       ‚îÇ
‚îÇ    ‚Ä¢ Cargar ejemplos (BAJO/MEDIO/ALTO) ‚îÇ
‚îÇ    ‚Ä¢ Agregar contexto hist√≥rico         ‚îÇ
‚îÇ    ‚Ä¢ Agregar datos del informe actual   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Invocar Bedrock Nova Pro            ‚îÇ
‚îÇ    ‚Ä¢ Temperature: 0.1 (precisi√≥n)       ‚îÇ
‚îÇ    ‚Ä¢ MaxTokens: 1000                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Parsear Respuesta JSON              ‚îÇ
‚îÇ    ‚Ä¢ nivel_riesgo: BAJO/MEDIO/ALTO     ‚îÇ
‚îÇ    ‚Ä¢ justificacion: texto explicativo   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. Guardar en Aurora                   ‚îÇ
‚îÇ    ‚Ä¢ UPDATE informes_medicos            ‚îÇ
‚îÇ    ‚Ä¢ SET nivel_riesgo, justificacion    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Parte 1: Ver Datos Existentes en el Sistema Legacy (5 min)

El instructor ya carg√≥ datos de ejemplo en tu base de datos Aurora.

#### Paso 1: Configurar variables de entorno para Aurora (1 min)

**Opci√≥n A: Usar el script de configuraci√≥n autom√°tica (Recomendado)**

```bash
# Navegar al directorio de scripts
cd ~/pulsosalud-immersion-day/scripts/examples

# Ejecutar el script (detecta autom√°ticamente tu prefijo desde tu usuario IAM)
source setup-env-vars-cloudshell.sh
```

El script detectar√° autom√°ticamente tu prefijo de participante extrayendo el n√∫mero de tu usuario IAM (ej: `workshop-user-1` ‚Üí `participant-1`).

**Salida esperada:**
```
üîç Detectando tu prefijo de participante...
üë§ Usuario detectado: workshop-user-1
‚úÖ Prefijo detectado autom√°ticamente: participant-1
ÔøΩ  Configurando variables de entorno para participant-1...
üìä Obteniendo ARN del cluster Aurora...
‚úÖ CLUSTER_ARN: arn:aws:rds:us-east-2:...
‚úÖ SECRET_ARN: arn:aws:secretsmanager:us-east-2:...
‚úÖ DATABASE_NAME: medical_reports
‚úÖ API_GATEWAY_URL: https://...
‚úÖ WEBSITE_URL: http://...
```

**Opci√≥n B: Configurar manualmente (si el script autom√°tico falla)**

```bash
# Configurar variables de entorno usando tu PARTICIPANT_PREFIX
export PARTICIPANT_PREFIX=participant-1  # Reemplaza con tu prefijo

export CLUSTER_ARN=$(aws cloudformation describe-stacks \
  --stack-name $PARTICIPANT_PREFIX-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`DatabaseClusterArn`].OutputValue' \
  --output text)

export SECRET_ARN=$(aws cloudformation describe-stacks \
  --stack-name $PARTICIPANT_PREFIX-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`DatabaseSecretArn`].OutputValue' \
  --output text)

export DATABASE_NAME="medical_reports"

# Verificar que se configuraron correctamente
echo "Participant: $PARTICIPANT_PREFIX"
echo "Cluster ARN: $CLUSTER_ARN"
echo "Secret ARN: $SECRET_ARN"
echo "Database: $DATABASE_NAME"
```

**‚úÖ Estas variables las usar√°s para consultas a la base de datos.**

---

#### Paso 2: Ver informes existentes (2 min)

```bash
# Ver informes en la base de datos usando las variables configuradas en el Paso 1
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database medical_reports \
  --sql "SELECT id, trabajador_id, tipo_examen, presion_arterial, peso FROM informes_medicos LIMIT 5"
```

Observa que estos son informes reales que necesitan ser clasificados y enviados a clientes.

---

### Parte 2: Clasificar un Informe Autom√°ticamente (10 min)

Ahora vamos a usar Bedrock para clasificar autom√°ticamente el nivel de riesgo.

#### Paso 1: Invocar Lambda de Clasificaci√≥n (2 min)

```bash
# Clasificar el informe ID 1
aws lambda invoke \
  --function-name $PARTICIPANT_PREFIX-classify-risk \
  --cli-binary-format raw-in-base64-out \
  --payload '{"informe_id": 1}' \
  response.json

# Ver resultado
cat response.json | python3 -m json.tool
```

**Tip:** Usamos `python3 -m json.tool` para formatear el JSON y hacerlo m√°s legible.

**‚úÖ Deber√≠as ver:**
```json
{
  "informe_id": 1,
  "nivel_riesgo": "ALTO",
  "justificacion": "Presi√≥n arterial 165/102 mmHg indica hipertensi√≥n severa...",
  "tiempo_procesamiento": "2.3s"
}
```

---

#### Paso 2: Ver logs en tiempo real (3 min)

```bash
# Ver logs de la Lambda (√∫ltimos 5 minutos)
aws logs tail /aws/lambda/$PARTICIPANT_PREFIX-classify-risk --since 5m --follow
```

Busca en los logs:
- `Invoking Bedrock with inference profile` ‚Üí Llamada a Bedrock
- `Few-shot examples loaded` ‚Üí Ejemplos de entrenamiento
- `RAG context retrieved` ‚Üí Informes anteriores del trabajador
- `Classification result` ‚Üí Resultado final

**Presiona Ctrl+C para salir del modo follow**

---

#### Paso 3: Verificar resultado en Aurora (2 min)

```bash
# Ver el informe clasificado
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database $DATABASE_NAME \
  --sql "SELECT id, nivel_riesgo, justificacion_riesgo FROM informes_medicos WHERE id = 1" \
  | python3 -m json.tool
```

**‚úÖ El informe ahora tiene:**
- `nivel_riesgo`: BAJO, MEDIO o ALTO
- `justificacion_riesgo`: Explicaci√≥n detallada

**Nota:** El output de RDS Data API es JSON con formato especial. Busca los valores en `stringValue` dentro de `records`.

---

### Parte 3: Entender C√≥mo Funciona (10 min)

#### Paso 1: Ver el Prompt de Clasificaci√≥n (3 min)

```bash
# Abrir el prompt en CloudShell
cat prompts/classification.txt
```

**Observa la estructura:**

```
Eres un m√©dico ocupacional experto...

Clasifica en uno de estos niveles:
- BAJO: Par√°metros normales, apto sin restricciones
- MEDIO: Par√°metros lim√≠trofes, requiere seguimiento  
- ALTO: Par√°metros alterados, requiere atenci√≥n inmediata

EJEMPLOS (Few-Shot Learning):

[Ejemplo BAJO con datos espec√≠ficos]
Presi√≥n: 118/75, IMC: 23.5, sin antecedentes
‚Üí BAJO

[Ejemplo MEDIO con datos espec√≠ficos]
Presi√≥n: 135/85, IMC: 27.2, colesterol elevado
‚Üí MEDIO

[Ejemplo ALTO con datos espec√≠ficos]
Presi√≥n: 155/95, IMC: 32.1, diabetes tipo 2
‚Üí ALTO

CONTEXTO HIST√ìRICO (RAG):
[Informes anteriores del trabajador]

INFORME ACTUAL:
[Datos del informe a clasificar]
```

**Lecci√≥n clave:** Few-shot learning + contexto hist√≥rico = clasificaci√≥n precisa

---

#### Paso 2: Ver el C√≥digo de la Lambda (4 min)

```bash
# Ver c√≥digo de clasificaci√≥n
cat lambda/ai/classify_risk/index.py
```

Busca estas secciones:

**1. Buscar contexto hist√≥rico (RAG):**
```python
# Buscar informes anteriores del mismo trabajador
informes_anteriores = buscar_informes_similares(trabajador_id)
```

**2. Construir prompt con ejemplos:**
```python
# Cargar ejemplos de few-shot learning
prompt = load_classification_prompt()
prompt += f"\nCONTEXTO HIST√ìRICO:\n{informes_anteriores}"
prompt += f"\nINFORME ACTUAL:\n{datos_informe}"
```

**3. Invocar Bedrock:**
```python
response = bedrock_runtime.invoke_model(
    modelId='us.amazon.nova-pro-v1:0',
    body=json.dumps({
        "messages": [{"role": "user", "content": prompt}],
        "inferenceConfig": {
            "temperature": 0.1,  # Baja para precisi√≥n
            "maxTokens": 1000
        }
    })
)
```

**Lecci√≥n clave:** Temperature baja (0.1) = respuestas consistentes y precisas

---

### Parte 4: Usar la App Web (5 min)

Ahora vamos a usar la interfaz visual.

#### Paso 1: Abrir tu App Web (1 min)

El instructor te proporcion√≥ la URL de tu app web. √Åbrela en tu navegador.

**Deber√≠as ver:**
- Lista de 10 informes m√©dicos
- Detalles de cada informe (presi√≥n arterial, IMC, etc.)
- Bot√≥n "Clasificar con IA" en cada informe
- Bot√≥n "Generar Resumen" (deshabilitado hasta clasificar)

---

#### Paso 2: Clasificar desde la App Web (2 min)

1. **Selecciona un informe** que NO est√© clasificado (sin badge de riesgo)
2. **Haz clic en "Clasificar con IA"**
3. **Observa:**
   - El bot√≥n muestra "Clasificando..."
   - Despu√©s de 2-3 segundos, aparece el badge de riesgo (BAJO/MEDIO/ALTO)
   - Se muestra la justificaci√≥n detallada

Detr√°s de escena, la app web est√° llamando a tu Lambda classify-risk a trav√©s de API Gateway.

---

#### Paso 3: Comparar CLI vs App Web (2 min)

**Ventajas de la App Web:**
- ‚úÖ Visual e intuitiva
- ‚úÖ No necesitas recordar comandos
- ‚úÖ Ves todos los informes de un vistazo
- ‚úÖ Feedback inmediato con badges de color

**Ventajas del CLI:**
- ‚úÖ Automatizaci√≥n y scripting
- ‚úÖ Integraci√≥n con otros sistemas
- ‚úÖ Acceso a logs detallados

**Lecci√≥n:** Ambas interfaces son √∫tiles seg√∫n el caso de uso.

---

### Parte 5: Ejercicio Individual (5 min)

**Tu tarea:** Clasificar 2-3 informes m√°s usando la app web

1. **Clasifica al menos 2 informes** usando el bot√≥n "Clasificar con IA"
2. **Observa los diferentes niveles de riesgo** (BAJO/MEDIO/ALTO)
3. **Lee las justificaciones** para entender por qu√© se clasific√≥ as√≠

**‚úÖ Criterio de √©xito:**
- Tienes al menos 3 informes clasificados
- Entiendes la diferencia entre BAJO, MEDIO y ALTO
- Los resultados tienen sentido m√©dicamente

**‚ùå Si algo falla:**
- Refresca la p√°gina
- Verifica que el despliegue se complet√≥ correctamente
- Revisa los logs en CloudShell: `aws logs tail /aws/lambda/participant-1-classify-risk`
- Pide ayuda al instructor

---

### üéì Resumen del M√≥dulo 1

**Lo que lograste:**
- ‚úÖ Viste datos reales del sistema legacy
- ‚úÖ Clasificaste informes autom√°ticamente con Bedrock
- ‚úÖ Entendiste few-shot learning y RAG
- ‚úÖ Verificaste resultados en la base de datos

**Valor de negocio:**
- Tiempo: De 10-15 min ‚Üí 30 segundos por informe
- Ahorro: 120+ horas/mes de trabajo m√©dico
- Consistencia: 100% en criterios de clasificaci√≥n
- Priorizaci√≥n: Identificaci√≥n inmediata de casos cr√≠ticos

**Concepto clave:** 
> Few-shot learning + RAG = Clasificaci√≥n precisa sin entrenar un modelo custom

**Pr√≥ximo m√≥dulo:** Generar res√∫menes ejecutivos autom√°ticamente

---

### M√≥dulo 2: Generaci√≥n de Res√∫menes Ejecutivos (30 min)

**Objetivo:** Automatizar la creaci√≥n de res√∫menes ejecutivos para gerentes de empresas clientes.

#### üéØ El Problema

**Situaci√≥n Actual:**
- Los gerentes de empresas clientes NO leen informes m√©dicos completos (5-10 p√°ginas)
- Necesitan res√∫menes ejecutivos de 2-3 p√°rrafos que destaquen:
  - Hallazgos principales
  - Nivel de riesgo
  - Acciones recomendadas
  - Tendencias vs. ex√°menes anteriores
- Crear estos res√∫menes manualmente toma 5-10 minutos por informe
- Con 500 informes/mes = 50+ horas de trabajo

**La Soluci√≥n con IA:**
- Amazon Bedrock genera res√∫menes autom√°ticamente
- Incluye contexto hist√≥rico usando RAG
- Lenguaje claro y no t√©cnico
- Tiempo reducido a 15 segundos por resumen

**Conceptos Clave:**
```
Temperature Media (0.5) = Balance entre precisi√≥n y fluidez
maxTokens = Controla la longitud del resumen
RAG = Agrega tendencias de ex√°menes anteriores
```

**Flujo de Generaci√≥n de Resumen:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Informe     ‚îÇ
‚îÇ Clasificado ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Verificar Clasificaci√≥n             ‚îÇ
‚îÇ    ‚Ä¢ Debe tener nivel_riesgo            ‚îÇ
‚îÇ    ‚Ä¢ Si no, retornar error              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Buscar Informes Anteriores (RAG)    ‚îÇ
‚îÇ    ‚Ä¢ Query SQL: √∫ltimos 2 informes      ‚îÇ
‚îÇ    ‚Ä¢ Mismo trabajador                   ‚îÇ
‚îÇ    ‚Ä¢ Para detectar tendencias           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Construir Prompt para Resumen       ‚îÇ
‚îÇ    ‚Ä¢ Cargar template summary.txt        ‚îÇ
‚îÇ    ‚Ä¢ Agregar contexto hist√≥rico         ‚îÇ
‚îÇ    ‚Ä¢ Agregar datos + nivel de riesgo    ‚îÇ
‚îÇ    ‚Ä¢ Especificar audiencia (gerente)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Invocar Bedrock Nova Pro            ‚îÇ
‚îÇ    ‚Ä¢ Temperature: 0.5 (balance)         ‚îÇ
‚îÇ    ‚Ä¢ MaxTokens: 300 (~150 palabras)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. Contar Palabras y Validar           ‚îÇ
‚îÇ    ‚Ä¢ Verificar longitud (80-180 palabras)‚îÇ
‚îÇ    ‚Ä¢ Formatear respuesta                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. Guardar en Aurora                   ‚îÇ
‚îÇ    ‚Ä¢ UPDATE informes_medicos            ‚îÇ
‚îÇ    ‚Ä¢ SET resumen_ejecutivo              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Parte 1: Generar un Resumen Autom√°ticamente (10 min)

Vamos a generar un resumen ejecutivo del informe que clasificamos en el M√≥dulo 1.

#### Paso 1: Invocar Lambda de Resumen (2 min)

```bash
# Generar resumen del informe ID 1
aws lambda invoke \
  --function-name participant-1-generate-summary \
  --cli-binary-format raw-in-base64-out \
  --payload '{"informe_id": 1}' \
  summary_response.json

# Ver resultado
cat summary_response.json
```

**‚úÖ Deber√≠as ver:**
```json
{
  "informe_id": 1,
  "resumen": "El trabajador Carlos Rodr√≠guez presenta m√∫ltiples factores de riesgo que requieren atenci√≥n m√©dica inmediata. Se detecta hipertensi√≥n arterial severa (165/102 mmHg) y obesidad grado I (IMC: 32.9). Los ex√°menes de laboratorio revelan diabetes mellitus descompensada. Comparado con su examen anterior hace 6 meses, se observa deterioro significativo en todos los par√°metros. Se recomienda restricci√≥n inmediata de actividades de alto riesgo y evaluaci√≥n m√©dica urgente.",
  "palabras": 87,
  "tiempo_procesamiento": "1.8s"
}
```

---

#### Paso 2: Ver logs en tiempo real (3 min)

```bash
# Ver logs de la Lambda
aws logs tail /aws/lambda/participant-1-generate-summary --follow
```

Busca en los logs:
- `Loading summary prompt` ‚Üí Carga del prompt
- `RAG: Retrieved 2 previous reports` ‚Üí Informes anteriores encontrados
- `Invoking Bedrock with temperature 0.5` ‚Üí Llamada a Bedrock
- `Summary generated: 87 words` ‚Üí Resumen creado

**Presiona Ctrl+C para salir**

---

#### Paso 3: Verificar resultado en Aurora (2 min)

```bash
# Ver el resumen guardado
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database medical_reports \
  --sql "SELECT id, resumen_ejecutivo FROM informes_medicos WHERE id = 1"
```

**‚úÖ El informe ahora tiene un resumen ejecutivo listo para enviar al cliente**

---

### Parte 2: Entender el Prompt de Resumen (8 min)

**El instructor explicar√° mientras t√∫ sigues en tu pantalla**

#### Paso 1: Ver el Prompt (3 min)

```bash
# Abrir el prompt de resumen
cat prompts/summary.txt
```

**Observa la estructura:**

```
Genera un resumen ejecutivo del informe m√©dico.

AUDIENCIA: Gerente de empresa (no m√©dico)

REQUISITOS:
- M√°ximo 150 palabras
- Lenguaje claro, NO t√©cnico
- Enf√≥cate en hallazgos principales y acciones
- Incluye tendencias si hay informes anteriores

CONTEXTO HIST√ìRICO (RAG):
[Informes anteriores del trabajador - si existen]

INFORME ACTUAL:
[Datos del informe]
[Nivel de riesgo: ALTO]

FORMATO:
2-3 p√°rrafos, directo y accionable.
```

**Lecci√≥n clave:** El prompt especifica la audiencia (gerente, no m√©dico) para ajustar el lenguaje

---

#### Paso 2: Comparar con Clasificaci√≥n (2 min)

**Diferencias clave entre Clasificaci√≥n y Resumen:**

| Aspecto | Clasificaci√≥n | Resumen |
|---------|---------------|---------|
| **Temperature** | 0.1 (preciso) | 0.5 (balanceado) |
| **maxTokens** | 1000 | 300 |
| **Objetivo** | Decisi√≥n binaria | Comunicaci√≥n fluida |
| **Audiencia** | Sistema | Humano (gerente) |

**Lecci√≥n:** Ajustamos par√°metros seg√∫n el caso de uso

---

#### Paso 3: Ver el C√≥digo (3 min)

```bash
# Ver c√≥digo de generaci√≥n de resumen
cat lambda/ai/generate_summary/index.py
```

**Busca estas secciones:**

**1. Buscar contexto hist√≥rico:**
```python
# Buscar informes anteriores para tendencias
informes_anteriores = buscar_informes_similares(trabajador_id, limit=2)
```

**2. Construir prompt con contexto:**
```python
prompt = load_summary_prompt()
if informes_anteriores:
    prompt += f"\nCONTEXTO HIST√ìRICO:\n{format_historical_context(informes_anteriores)}"
prompt += f"\nINFORME ACTUAL:\n{datos_informe}"
prompt += f"\nNivel de riesgo: {nivel_riesgo}"
```

**3. Invocar Bedrock con temperature media:**
```python
response = bedrock_runtime.invoke_model(
    modelId='us.amazon.nova-pro-v1:0',
    body=json.dumps({
        "messages": [{"role": "user", "content": prompt}],
        "inferenceConfig": {
            "temperature": 0.5,  # Balance entre precisi√≥n y fluidez
            "maxTokens": 300     # Limita longitud del resumen
        }
    })
)
```

---

### Parte 3: Entender los Par√°metros de Bedrock (7 min)

El instructor explicar√° los par√°metros clave de Bedrock.

#### Par√°metro 1: Temperature (3 min)

**¬øQu√© es temperature?**
- Controla la "creatividad" o "aleatoriedad" del modelo
- Rango: 0.0 (determin√≠stico) a 1.0 (muy creativo)

**Ejemplos de uso:**

| Temperature | Caso de Uso | Resultado |
|-------------|-------------|-----------|
| **0.1** | Clasificaci√≥n de riesgo | Preciso, consistente, mismo input ‚Üí mismo output |
| **0.5** | Res√∫menes ejecutivos | Balanceado: preciso pero con fluidez natural |
| **0.7** | Emails personalizados | M√°s variado, tono m√°s natural |
| **0.9** | Brainstorming | Muy creativo, respuestas diversas |

**Lecci√≥n:** Usamos temperature 0.1 para clasificaci√≥n (precisi√≥n) y 0.5 para res√∫menes (balance).

---

#### Par√°metro 2: maxTokens (2 min)

**¬øQu√© es maxTokens?**
- Limita la longitud m√°xima de la respuesta
- 1 token ‚âà 0.75 palabras en espa√±ol
- 300 tokens ‚âà 225 palabras

**Ejemplos de uso:**

| maxTokens | Caso de Uso | Resultado |
|-----------|-------------|-----------|
| **1000** | Clasificaci√≥n con justificaci√≥n | Permite explicaci√≥n detallada |
| **300** | Resumen ejecutivo | Fuerza concisi√≥n (~150 palabras) |
| **500** | Email personalizado | Suficiente para email completo |

**Lecci√≥n:** maxTokens no solo limita, tambi√©n gu√≠a al modelo a ser m√°s conciso.

---

#### Par√°metro 3: Prompt Engineering (2 min)

**¬øQu√© hace un buen prompt?**
- ‚úÖ **Contexto claro:** "Eres un m√©dico ocupacional experto..."
- ‚úÖ **Ejemplos (few-shot):** Muestra 2-3 ejemplos del resultado esperado
- ‚úÖ **Formato espec√≠fico:** "Responde en formato JSON: {...}"
- **Restricciones:** "M√°ximo 150 palabras", "Lenguaje no t√©cnico"

**Lecci√≥n:** Un prompt bien dise√±ado es m√°s importante que ajustar par√°metros.

---

### Parte 3.5: Experimentar con Par√°metros (Opcional - 5 min)

Si tienes tiempo, experimenta con diferentes par√°metros.

#### Experimento 1: Temperature Baja (0.2)

```bash
# Generar resumen con temperature baja (m√°s determin√≠stico)
aws lambda invoke \
  --function-name participant-1-generate-summary \
  --cli-binary-format raw-in-base64-out \
  --payload '{"informe_id": 1, "temperature": 0.2}' \
  summary_temp_low.json

# Ver resultado
cat summary_temp_low.json
```

Observa si el resumen es m√°s t√©cnico o m√°s formal.

---

#### Experimento 2: Temperature Alta (0.8)

```bash
# Generar resumen con temperature alta (m√°s creativo)
aws lambda invoke \
  --function-name participant-1-generate-summary \
  --cli-binary-format raw-in-base64-out \
  --payload '{"informe_id": 1, "temperature": 0.8}' \
  summary_temp_high.json

# Ver resultado
cat summary_temp_high.json
```

Observa si el resumen es m√°s variado o usa lenguaje m√°s natural.

---

#### Experimento 3: maxTokens Reducido (150)

```bash
# Generar resumen m√°s corto
aws lambda invoke \
  --function-name participant-1-generate-summary \
  --cli-binary-format raw-in-base64-out \
  --payload '{"informe_id": 1, "maxTokens": 150}' \
  summary_short.json

# Ver resultado
cat summary_short.json
```

Observa si el resumen mantiene la informaci√≥n clave o pierde detalles.

---

**Lecci√≥n:** Los par√°metros por defecto (temperature: 0.5, maxTokens: 300) est√°n optimizados para este caso de uso. Experimentar ayuda a entender su impacto.

---

### Parte 4: Usar la App Web para Res√∫menes (5 min)

Ahora vamos a generar res√∫menes desde la interfaz visual.

#### Paso 1: Generar Resumen desde la App Web (2 min)

1. **Abre tu App Web** (si la cerraste)
2. **Selecciona un informe clasificado** (con badge de riesgo)
3. **Haz clic en "Generar Resumen"**
4. **Observa:**
   - El bot√≥n muestra "Generando..."
   - Despu√©s de 1-2 segundos, aparece el resumen ejecutivo
   - Se muestra el conteo de palabras

**Nota:** Solo puedes generar res√∫menes de informes ya clasificados.

---

#### Paso 2: Analizar el Resumen (2 min)

**Lee el resumen generado y verifica:**
- ‚úÖ Lenguaje claro y no t√©cnico (para gerentes, no m√©dicos)
- ‚úÖ Menciona el nivel de riesgo
- ‚úÖ Incluye hallazgos principales
- ‚úÖ Sugiere acciones recomendadas
- ‚úÖ Longitud: ~100-150 palabras

Si hay informes anteriores del mismo trabajador, el resumen incluir√° tendencias hist√≥ricas (ej: "Comparado con su examen anterior hace 6 meses...").

---

#### Paso 3: Ejercicio Individual (1 min)

**Tu tarea:** Generar res√∫menes de 2-3 informes m√°s

1. **Genera res√∫menes** de los informes que clasificaste
2. **Compara res√∫menes** de diferentes niveles de riesgo
3. **Observa el tono:** ¬øEs m√°s urgente para ALTO riesgo?

**‚úÖ Criterio de √©xito:**
- Tienes al menos 3 res√∫menes generados
- Los res√∫menes son claros y accionables
- Entiendes c√≥mo el nivel de riesgo afecta el contenido

---

### üéì Resumen del M√≥dulo 2

**Lo que lograste:**
- ‚úÖ Generaste res√∫menes ejecutivos autom√°ticamente
- ‚úÖ Entendiste c√≥mo ajustar temperature y maxTokens
- ‚úÖ Viste c√≥mo RAG agrega contexto hist√≥rico
- ‚úÖ Experimentaste con diferentes par√°metros

**Valor de negocio:**
- Tiempo: De 5-10 min ‚Üí 15 segundos por resumen
- Ahorro: 50+ horas/mes
- Calidad: Consistente y profesional
- Tendencias: Incluye comparaci√≥n con ex√°menes anteriores

**Concepto clave:** 
> Temperature media + maxTokens limitado = Res√∫menes concisos y fluidos

**Pr√≥ximo:** Checkpoint del D√≠a 1 y c√°lculo de ROI

---

### üéâ ¬°Felicitaciones!

Has completado el D√≠a 1 del workshop. Ahora sabes c√≥mo:
- ‚úÖ Clasificar informes autom√°ticamente con few-shot learning
- ‚úÖ Generar res√∫menes ejecutivos con IA
- ‚úÖ Ajustar par√°metros (temperature, maxTokens) seg√∫n el caso de uso
- ‚úÖ Usar RAG para agregar contexto hist√≥rico
- ‚úÖ Calcular el ROI de automatizaci√≥n con IA

**Ma√±ana (D√≠a 2):** Aprender√°s a personalizar emails seg√∫n el nivel de riesgo, profundizar en RAG, e integrar PDFs externos.

---

## üìñ Conceptos Clave del D√≠a 1

Esta secci√≥n resume los conceptos t√©cnicos m√°s importantes que aprendiste hoy, con ejemplos concretos del workshop.

### 1. Few-Shot Learning

**¬øQu√© es?**
Few-shot learning es una t√©cnica donde ense√±as al modelo de IA con solo unos pocos ejemplos (t√≠picamente 2-5) en lugar de entrenar un modelo completo con miles de datos.

**C√≥mo lo usamos en el workshop:**
En el prompt de clasificaci√≥n, incluimos 3 ejemplos:
- 1 ejemplo de riesgo BAJO (presi√≥n 118/75, IMC 23.5)
- 1 ejemplo de riesgo MEDIO (presi√≥n 135/85, IMC 27.2)
- 1 ejemplo de riesgo ALTO (presi√≥n 155/95, IMC 32.1)

**Ventajas:**
- ‚úÖ No requiere entrenar un modelo custom (ahorra tiempo y dinero)
- ‚úÖ F√°cil de actualizar (solo editas el prompt)
- ‚úÖ Resultados inmediatos sin necesidad de datos hist√≥ricos masivos

**Ejemplo del workshop:**
```
EJEMPLOS:

Ejemplo BAJO:
Presi√≥n: 118/75, IMC: 23.5, sin antecedentes
‚Üí BAJO

Ejemplo MEDIO:
Presi√≥n: 135/85, IMC: 27.2, colesterol elevado
‚Üí MEDIO

Ejemplo ALTO:
Presi√≥n: 155/95, IMC: 32.1, diabetes tipo 2
‚Üí ALTO

Ahora clasifica este informe:
[datos del informe actual]
```

---

### 2. RAG (Retrieval-Augmented Generation)

**¬øQu√© es?**
RAG es una t√©cnica que combina b√∫squeda de informaci√≥n (Retrieval) con generaci√≥n de texto (Generation). Primero busca informaci√≥n relevante, luego la agrega al prompt para que el modelo genere una respuesta m√°s precisa.

**C√≥mo lo usamos en el workshop:**
Antes de clasificar o generar un resumen, buscamos los √∫ltimos 2-3 informes del mismo trabajador usando SQL:

```sql
SELECT * FROM informes_medicos 
WHERE trabajador_id = :id 
ORDER BY fecha_examen DESC 
LIMIT 3
```

Luego agregamos esa informaci√≥n al prompt como "contexto hist√≥rico".

**Ventajas:**
- ‚úÖ Reduce alucinaciones (el modelo no inventa datos)
- ‚úÖ Proporciona contexto espec√≠fico del trabajador
- ‚úÖ Permite detectar tendencias (ej: "deterioro en los √∫ltimos 6 meses")

**Ejemplo del workshop:**
```
CONTEXTO HIST√ìRICO:
- 2024-06-15: Presi√≥n 140/88, IMC 28.5, Riesgo: MEDIO
- 2024-03-10: Presi√≥n 135/85, IMC 27.2, Riesgo: MEDIO

INFORME ACTUAL:
- 2024-12-02: Presi√≥n 165/102, IMC 32.9
‚Üí Se observa deterioro progresivo ‚Üí ALTO
```

**Diferencia con b√∫squeda vectorial (D√≠a 2):**
- D√≠a 1: RAG simple con SQL (busca por `trabajador_id`)
- D√≠a 2: RAG avanzado con embeddings (busca por similitud sem√°ntica)

---

### 3. Temperature

**¬øQu√© es?**
Temperature controla la "creatividad" o "aleatoriedad" del modelo. Es un n√∫mero entre 0.0 y 1.0.

**Escala de Temperature:**
```
0.0 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0.5 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1.0
Determin√≠stico  Balanceado    Muy creativo
Preciso         Natural       Variado
```

**C√≥mo lo usamos en el workshop:**

| Caso de Uso | Temperature | Por qu√© |
|-------------|-------------|---------|
| **Clasificaci√≥n** | 0.1 | Necesitamos precisi√≥n y consistencia. Mismo informe ‚Üí mismo resultado |
| **Res√∫menes** | 0.5 | Balance entre precisi√≥n y fluidez natural del lenguaje |
| **Emails (D√≠a 2)** | 0.7 | M√°s variedad y tono natural para comunicaci√≥n humana |

**Ejemplo pr√°ctico:**

**Temperature 0.1 (Clasificaci√≥n):**
- Input: "Presi√≥n 165/102, IMC 32.9, diabetes"
- Output 1: "ALTO - Hipertensi√≥n severa requiere atenci√≥n inmediata"
- Output 2: "ALTO - Hipertensi√≥n severa requiere atenci√≥n inmediata"
- Output 3: "ALTO - Hipertensi√≥n severa requiere atenci√≥n inmediata"
- ‚úÖ Siempre el mismo resultado (consistencia)

**Temperature 0.5 (Resumen):**
- Input: Mismo informe
- Output 1: "El trabajador presenta hipertensi√≥n severa y obesidad..."
- Output 2: "Se detecta presi√≥n arterial elevada y sobrepeso significativo..."
- Output 3: "Los par√°metros indican hipertensi√≥n grado 2 y obesidad..."
- ‚úÖ Variaciones naturales pero mantiene el mensaje

**Temperature 0.9 (Muy creativo - NO recomendado para este caso):**
- Output: "¬°Alerta! Este trabajador necesita cambios urgentes en su estilo de vida..."
- ‚ùå Demasiado variado, puede perder precisi√≥n m√©dica

---

### 4. maxTokens

**¬øQu√© es?**
maxTokens limita la longitud m√°xima de la respuesta del modelo. Un token es aproximadamente 0.75 palabras en espa√±ol.

**Conversi√≥n aproximada:**
```
100 tokens  ‚âà  75 palabras  ‚âà  1 p√°rrafo corto
300 tokens  ‚âà 225 palabras  ‚âà  2-3 p√°rrafos
1000 tokens ‚âà 750 palabras  ‚âà  1 p√°gina
```

**C√≥mo lo usamos en el workshop:**

| Caso de Uso | maxTokens | Resultado Esperado |
|-------------|-----------|-------------------|
| **Clasificaci√≥n** | 1000 | Permite justificaci√≥n detallada (~500 palabras) |
| **Res√∫menes** | 300 | Fuerza concisi√≥n (~150 palabras) |
| **Emails (D√≠a 2)** | 500 | Email completo pero no excesivo (~350 palabras) |

**Funci√≥n dual de maxTokens:**
1. **Limitar:** Evita respuestas demasiado largas
2. **Guiar:** El modelo ajusta su estilo para cumplir el l√≠mite

**Ejemplo pr√°ctico:**

**maxTokens 1000 (Clasificaci√≥n):**
```
Resultado: "ALTO - El trabajador presenta hipertensi√≥n arterial severa 
(165/102 mmHg) que supera significativamente los valores normales 
(120/80 mmHg). Adem√°s, se observa obesidad grado I (IMC 32.9) y 
diabetes mellitus descompensada. Estos factores combinados representan 
un riesgo cardiovascular elevado que requiere intervenci√≥n m√©dica 
inmediata. Se recomienda restricci√≥n de actividades de alto riesgo 
f√≠sico y evaluaci√≥n cardiol√≥gica urgente..."
```
‚úÖ Justificaci√≥n completa y detallada

**maxTokens 300 (Resumen):**
```
Resultado: "El trabajador presenta m√∫ltiples factores de riesgo que 
requieren atenci√≥n inmediata. Se detecta hipertensi√≥n severa y obesidad. 
Comparado con su examen anterior, se observa deterioro significativo. 
Se recomienda restricci√≥n de actividades de riesgo y evaluaci√≥n m√©dica 
urgente."
```
‚úÖ Conciso pero completo (~80 palabras)

**maxTokens 50 (Demasiado corto - NO recomendado):**
```
Resultado: "Hipertensi√≥n severa y obesidad. Requiere atenci√≥n m√©dica."
```
‚ùå Pierde informaci√≥n importante

---

### 5. Prompt Engineering

**¬øQu√© es?**
Prompt engineering es el arte de dise√±ar instrucciones efectivas para modelos de IA. Un buen prompt es claro, espec√≠fico y proporciona contexto.

**Anatom√≠a de un buen prompt (del workshop):**

```
1. CONTEXTO/ROL
   "Eres un m√©dico ocupacional experto en evaluar riesgos laborales."
   ‚Üí Define qui√©n es el modelo

2. TAREA
   "Clasifica el siguiente informe en uno de estos niveles: BAJO, MEDIO, ALTO"
   ‚Üí Define qu√© debe hacer

3. CRITERIOS
   "- BAJO: Par√°metros normales, apto sin restricciones
    - MEDIO: Par√°metros lim√≠trofes, requiere seguimiento
    - ALTO: Par√°metros alterados, requiere atenci√≥n inmediata"
   ‚Üí Define c√≥mo evaluar

4. EJEMPLOS (Few-Shot)
   [3 ejemplos concretos con datos y resultados]
   ‚Üí Muestra el formato esperado

5. CONTEXTO ADICIONAL (RAG)
   "CONTEXTO HIST√ìRICO: [informes anteriores]"
   ‚Üí Proporciona informaci√≥n relevante

6. INPUT
   "INFORME ACTUAL: [datos del informe]"
   ‚Üí Los datos a procesar

7. FORMATO DE SALIDA
   "Responde en formato JSON: {nivel_riesgo: ..., justificacion: ...}"
   ‚Üí Define el formato de respuesta
```

**Mejores pr√°cticas del workshop:**
- ‚úÖ Especifica la audiencia ("para gerentes, no m√©dicos")
- ‚úÖ Usa restricciones claras ("m√°ximo 150 palabras")
- ‚úÖ Proporciona ejemplos concretos (few-shot learning)
- ‚úÖ Incluye contexto relevante (RAG)
- ‚úÖ Define el formato de salida (JSON, p√°rrafos, etc.)

---

### 6. Comparaci√≥n: Clasificaci√≥n vs Resumen

**Tabla comparativa de configuraciones:**

| Aspecto | Clasificaci√≥n | Resumen |
|---------|---------------|---------|
| **Objetivo** | Decisi√≥n categ√≥rica (BAJO/MEDIO/ALTO) | Comunicaci√≥n fluida |
| **Audiencia** | Sistema/M√©dico | Gerente (no m√©dico) |
| **Temperature** | 0.1 (precisi√≥n) | 0.5 (balance) |
| **maxTokens** | 1000 (justificaci√≥n detallada) | 300 (concisi√≥n) |
| **Prompt** | Criterios t√©cnicos + ejemplos | Lenguaje claro + restricciones |
| **RAG** | √öltimos 3 informes | √öltimos 2 informes |
| **Salida** | JSON estructurado | Texto en p√°rrafos |
| **Tiempo** | ~30 segundos | ~15 segundos |

**Lecci√≥n clave:** No hay una configuraci√≥n "correcta" universal. Los par√°metros se ajustan seg√∫n el caso de uso espec√≠fico.

---

### üéØ Aplicando estos conceptos

**Pregunta de reflexi√≥n:** Si tuvieras que crear un sistema para generar emails de seguimiento, ¬øqu√© par√°metros usar√≠as?

**Respuesta sugerida:**
- Temperature: 0.6-0.7 (m√°s natural que resumen, menos que brainstorming)
- maxTokens: 400-500 (email completo pero no excesivo)
- Few-shot: 2-3 ejemplos de emails por nivel de riesgo
- RAG: Incluir historial de comunicaciones previas
- Prompt: Especificar tono (urgente/profesional/tranquilizador)

**Ver√°s esto en acci√≥n en el D√≠a 2 del workshop!** üöÄ

---

## üìö D√≠a 2: Capacidades Avanzadas

Bienvenido al D√≠a 2 del workshop. Hoy exploraremos capacidades avanzadas de IA que llevan el sistema al siguiente nivel:

**Objetivos del D√≠a 2:**
- üîç Entender b√∫squeda sem√°ntica con embeddings vectoriales (RAG avanzado)
- üìß Generar emails personalizados seg√∫n nivel de riesgo
- üîí Comprender consideraciones de privacidad m√©dica
- üé® Experimentar con prompts y modelos de IA

**Estructura:**
- ‚è±Ô∏è **10 min** - Setup: Despliegue de AI Stacks del D√≠a 2
- ‚è±Ô∏è **40 min** - M√≥dulo 3: RAG Avanzado con Embeddings Vectoriales
- ‚è±Ô∏è **40 min** - M√≥dulo 4: Emails Personalizados
- ‚è±Ô∏è **20 min** - Integraci√≥n y Discusi√≥n
- ‚è±Ô∏è **10 min** - Experimentaci√≥n Libre

---

## üöÄ Setup del D√≠a 2 (10 minutos)

### Paso 1: Desplegar AI Stacks del D√≠a 2

```bash
# Aseg√∫rate de estar en el directorio CDK
cd ~/pulsosalud-immersion-day/cdk

# Configurar email verificado (reemplaza con tu email)
export VERIFIED_EMAIL="tu-email@example.com"

# Desplegar AI Stacks del D√≠a 2
# Nota: AIRAGStack ya fue desplegado en el D√≠a 1 como dependencia
npx cdk deploy $PARTICIPANT_PREFIX-AIEmailStack --require-approval never --context verifiedEmail=$VERIFIED_EMAIL
```

**‚ö†Ô∏è IMPORTANTE:** Reemplaza `tu-email@example.com` con un email que puedas verificar.

**Recursos que se desplegar√°n:**
- **AIEmailStack**: Lambda para generar y enviar emails personalizados

**Tiempo estimado:** 3-5 minutos

**Nota:** El AIRAGStack (embeddings) ya fue desplegado en el D√≠a 1 como dependencia de los otros stacks.

### Paso 2: Verificar Despliegue

El despliegue mostrar√° los outputs al finalizar:

```
‚úÖ participant-X-AIEmailStack

Outputs:
participant-X-AIEmailStack.SendEmailLambdaName = participant-X-send-email
participant-X-AIEmailStack.VerifiedEmail = tu@email.com
```

### Paso 3: Verificar Email en SES

Antes de poder enviar emails, debes verificar tu email en Amazon SES:

```bash
# Verificar tu email en SES
aws ses verify-email-identity --email-address $VERIFIED_EMAIL

# Verificar estado
aws ses list-identities
```

---

## üîç M√≥dulo 3: RAG Avanzado con Embeddings Vectoriales (40 min)

### Objetivo

Entender por qu√© necesitamos embeddings vectoriales para b√∫squeda sem√°ntica y c√≥mo implementarlos.

### Parte 1: ¬øPor qu√© SQL no es suficiente? (10 min)

#### El Problema con SQL

En el D√≠a 1, usamos SQL para buscar informes del MISMO trabajador:

```sql
SELECT * FROM informes_medicos 
WHERE trabajador_id = 123
```

**Limitaciones:**
- ‚ùå Solo busca coincidencias EXACTAS
- ‚ùå No entiende sin√≥nimos ("dolor lumbar" ‚â† "molestias en espalda")
- ‚ùå Trabajadores nuevos = Sin contexto hist√≥rico
- ‚ùå No puede encontrar casos SIMILARES de otros trabajadores

#### Demostraci√≥n: SQL vs Embeddings

**Opci√≥n 1: Usar el script de demostraci√≥n (recomendado)**

```bash
# 1. Navegar al directorio de scripts de ejemplo
cd ~/pulsosalud-immersion-day/scripts/examples

# 2. Configurar variables de entorno (si no lo hiciste antes)
# El script detecta autom√°ticamente tu prefijo de participante
source setup-env-vars-cloudshell.sh

# 3. Hacer el script ejecutable
chmod +x demo-rag-comparison.sh

# 4. Ejecutar demo de comparaci√≥n
./demo-rag-comparison.sh
```

**üí° Tip:** El script `setup-env-vars-cloudshell.sh` detecta autom√°ticamente tu prefijo extrayendo el n√∫mero de tu usuario IAM (ej: `workshop-user-5` ‚Üí `participant-5`).

Este script muestra:
1. **B√∫squeda SQL**: Solo encuentra informes del mismo trabajador
2. **B√∫squeda con Embeddings**: Encuentra casos similares de CUALQUIER trabajador
3. **Tabla comparativa**: SQL vs Embeddings
4. **Ejemplo concreto**: Por qu√© SQL no puede entender similitud sem√°ntica

**Opci√≥n 2: Comandos manuales (si el script no funciona)**

```bash
# 1. Buscar informes del mismo trabajador (SQL - D√≠a 1)
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database $DATABASE_NAME \
  --sql "SELECT * FROM informes_medicos WHERE trabajador_id = 1 ORDER BY fecha_examen DESC"

# 2. Verificar embeddings disponibles
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database $DATABASE_NAME \
  --sql "SELECT COUNT(*) FROM informes_embeddings"

# 3. Buscar casos similares (Embeddings - D√≠a 2)
# Nota: Requiere que hayas generado embeddings primero
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database $DATABASE_NAME \
  --sql "SELECT im.id, im.trabajador_nombre, 1 - (ie1.embedding <=> ie2.embedding) as similarity FROM informes_medicos im JOIN informes_embeddings ie1 ON im.id = ie1.informe_id CROSS JOIN informes_embeddings ie2 WHERE ie2.informe_id = 1 AND im.id != 1 ORDER BY similarity DESC LIMIT 5"
```

**Pregunta clave**: ¬øC√≥mo buscar√≠as con SQL casos similares a "dolor lumbar por postura prolongada"?

**Respuesta**: No puedes. SQL no entiende que:
- "dolor lumbar" ‚âà "molestias en espalda baja"
- "postura prolongada" ‚âà "largas jornadas sentado"

### Parte 2: ¬øQu√© son los Embeddings? (10 min)

**Embeddings** son representaciones vectoriales de texto que capturan el significado sem√°ntico.

```python
# Texto original
"Dolor lumbar ocasional por postura prolongada en cabina"

# Embedding (vector de 1024 dimensiones)
[0.123, -0.456, 0.789, ..., 0.234]
```

**Ventaja clave**: Textos con significado similar tienen vectores cercanos en el espacio vectorial.

**Ejemplo**:
- "Dolor lumbar por postura prolongada" ‚Üí Vector A
- "Molestias en espalda baja por jornadas sentado" ‚Üí Vector B
- Similitud de coseno (A, B) = 0.89 (muy similar!)

**Modelo usado**: Amazon Titan Embeddings v2
- Dimensiones: 1024
- Optimizado para espa√±ol e ingl√©s
- Captura contexto y sin√≥nimos

### Parte 3: Generar Embeddings (10 min)

#### Paso 1: Generar Embedding para un Informe

```bash
# Invocar Lambda para generar embedding
aws lambda invoke \
  --function-name $PARTICIPANT_PREFIX-generate-embeddings \
  --cli-binary-format raw-in-base64-out \
  --payload '{"informe_id": 1}' \
  embeddings_response.json

# Ver resultado
cat embeddings_response.json | python3 -m json.tool
```

**Output esperado**:
```
========================================
  Resultado de Generaci√≥n de Embeddings
========================================

Estado: √âXITO
Informe ID: 1
Dimensiones del vector: 1024
‚úì Vector tiene las dimensiones correctas (1024)

Tiempo de procesamiento: 1.8s

Preview del contenido usado:
Trabajador: Juan P√©rez
Tipo de examen: Ocupacional Anual
Observaciones: Dolor lumbar ocasional...

‚úì Embedding almacenado correctamente en la base de datos
```

#### Paso 2: Verificar en Base de Datos

```bash
# Ver embeddings generados
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database $DATABASE_NAME \
  --sql "SELECT ie.informe_id, im.trabajador_nombre, im.tipo_examen, LENGTH(ie.embedding::text) as embedding_size FROM informes_embeddings ie JOIN informes_medicos im ON ie.informe_id = im.id LIMIT 5" \
  | python3 -m json.tool
```

**Qu√© verificar:**
- ‚úÖ `informe_id` del informe que procesaste
- ‚úÖ `embedding_size` deber√≠a ser grande (el vector tiene 1024 dimensiones)

### Parte 4: Buscar Casos Similares (10 min)

#### Paso 1: Ejecutar B√∫squeda de Similitud

```bash
# Buscar los 5 informes m√°s similares al informe ID 1
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database $DATABASE_NAME \
  --sql "SELECT im.id, im.trabajador_nombre, im.tipo_examen, im.nivel_riesgo, ROUND((1 - (ie1.embedding <=> ie2.embedding))::numeric, 4) as similarity FROM informes_medicos im JOIN informes_embeddings ie1 ON im.id = ie1.informe_id CROSS JOIN informes_embeddings ie2 WHERE ie2.informe_id = 1 AND im.id != 1 ORDER BY similarity DESC LIMIT 5" \
  | python3 -m json.tool
```

**Output esperado**:
```
========================================
  Resultados de B√∫squeda de Similitud
========================================

Encontrados 5 informes similares
Tiempo de b√∫squeda: 45.23 ms

[1] Trabajador: Pedro Garc√≠a (Informe #3)
    Similitud: 0.8934
    Tipo examen: Ocupacional Anual
    Nivel riesgo: MEDIO
    Observaciones: Molestias en espalda baja por jornadas...

[2] Trabajador: Carlos L√≥pez (Informe #7)
    Similitud: 0.8521
    Tipo examen: Ocupacional Peri√≥dico
    Nivel riesgo: MEDIO
    Observaciones: Dolor lumbar por vibraci√≥n constante...

[...]

--- Estad√≠sticas ---
Similitud promedio: 0.8234
Similitud m√°xima: 0.8934
Similitud m√≠nima: 0.7456
```

#### Paso 2: Entender la Query

La query usa el operador `<=>` de pgvector:

```sql
SELECT 
    im.id,
    t.nombre as trabajador,
    im.tipo_examen,
    1 - (ie1.embedding <=> ie2.embedding) as similarity_score
FROM informes_medicos im
JOIN informes_embeddings ie1 ON im.id = ie1.informe_id
CROSS JOIN informes_embeddings ie2
WHERE ie2.informe_id = 1  -- Informe de referencia
  AND im.id != 1          -- Excluir el mismo informe
ORDER BY similarity_score DESC
LIMIT 5;
```

**Conceptos clave**:
- `<=>`: Operador de distancia de coseno (0 = id√©nticos, 2 = opuestos)
- `1 - distancia`: Convertir distancia en similitud (1 = id√©nticos, 0 = no relacionados)
- `CROSS JOIN`: Comparar con todos los embeddings

### Parte 5: Consideraciones de Privacidad (10 min)

#### IMPORTANTE: RAG es Herramienta INTERNA del M√©dico

**‚úÖ Para el M√âDICO (Uso Interno)**:
- S√ç puede ver casos similares anonimizados
- S√ç puede usar patrones hist√≥ricos para decisiones
- S√ç puede anticipar riesgos basado en casos similares

**‚ùå Para el EMPLEADO (Email/Comunicaci√≥n)**:
- NO puede recibir informaci√≥n de otros empleados
- NO puede saber que existen casos similares
- S√ç puede recibir mejores recomendaciones (sin mencionar origen)

**Ejemplo - Vista del M√©dico (Correcto)**:
```
Informe: Juan P√©rez
Casos similares encontrados (5):
1. Trabajador #145 (similarity: 0.89)
   - Perfil similar, mejor√≥ con pausas ergon√≥micas
2. Trabajador #203 (similarity: 0.85)
   - Perfil similar, requiri√≥ seguimiento cardiol√≥gico
```

**Ejemplo - Email al Empleado (Correcto)**:
```
Estimado Juan,
Tu examen muestra presi√≥n arterial elevada.

Recomendaciones:
1. Consulta con cardi√≥logo en 2 semanas
2. Pausas ergon√≥micas cada 2 horas

[NO se menciona que hay casos similares]
[NO se comparte informaci√≥n de otros empleados]
```

**Documentaci√≥n completa**: Ver `docs/RAG_PRIVACY.md`

---

## üìß M√≥dulo 4: Emails Personalizados (40 min)

### Objetivo

Generar emails personalizados seg√∫n el nivel de riesgo del trabajador, respetando la privacidad m√©dica.

### Parte 1: Personalizaci√≥n por Nivel de Riesgo (10 min)

#### ¬øPor qu√© Personalizar Emails?

Cada nivel de riesgo requiere un tono y contenido diferente:

| Nivel | Tono | Objetivo | Urgencia |
|-------|------|----------|----------|
| **ALTO** | Serio pero tranquilizador | Acci√≥n inmediata | 48-72 horas |
| **MEDIO** | Informativo y preventivo | Seguimiento programado | 1-2 semanas |
| **BAJO** | Positivo y motivacional | Mantener buenos h√°bitos | Pr√≥ximo examen anual |

#### Prompts Espec√≠ficos por Nivel

Tenemos 3 prompts diferentes:

**1. Email Riesgo ALTO** (`prompts/email-alto-riesgo.txt`):
```
Eres un asistente m√©dico especializado en comunicaci√≥n urgente.

CONTEXTO: El empleado tiene resultados que requieren atenci√≥n inmediata.
TONO: Serio pero tranquilizador, sin generar p√°nico.

ESTRUCTURA:
- Asunto: "Importante: Resultados de tu examen - Seguimiento requerido"
- Explicaci√≥n clara de hallazgos
- Importancia del seguimiento INMEDIATO
- Recomendaciones urgentes con plazos espec√≠ficos
- Informaci√≥n de contacto

IMPORTANTE - PRIVACIDAD:
- NUNCA menciones casos de otros empleados
- NUNCA digas "encontramos casos similares"
- Solo usa datos del trabajador actual
```

**2. Email Riesgo MEDIO** (`prompts/email-medio-riesgo.txt`):
```
Eres un asistente m√©dico especializado en comunicaci√≥n preventiva.

CONTEXTO: El empleado tiene resultados que requieren monitoreo preventivo.
TONO: Informativo, preventivo y motivacional.

ESTRUCTURA:
- Asunto: "Resultados de tu examen - Recomendaciones preventivas"
- Resumen positivo con √°reas de atenci√≥n
- Importancia de la prevenci√≥n
- Recomendaciones de estilo de vida
- Plan de seguimiento en 1-2 semanas
```

**3. Email Riesgo BAJO** (`prompts/email-bajo-riesgo.txt`):
```
Eres un asistente m√©dico especializado en comunicaci√≥n positiva.

CONTEXTO: El empleado tiene resultados excelentes.
TONO: Positivo, felicitatorio y motivacional.

ESTRUCTURA:
- Asunto: "¬°Excelentes resultados en tu examen!"
- Felicitaci√≥n por buenos resultados
- Reconocimiento de buenos h√°bitos
- Tips para mantener la salud
- Recordatorio de pr√≥ximo examen
```

### Parte 2: Generar y Enviar Email (15 min)

#### Paso 1: Generar Email para un Informe

```bash
# Generar y enviar email para el informe ID 1
aws lambda invoke \
  --function-name $PARTICIPANT_PREFIX-send-email \
  --cli-binary-format raw-in-base64-out \
  --payload '{"informe_id": 1}' \
  email_response.json

# Ver resultado
cat email_response.json | python3 -m json.tool
```

**Output esperado**:
```
========================================
  Resultado de Env√≠o de Email
========================================

Estado: √âXITO
Informe ID: 1
Destinatario: trabajador@empresa.com
Nivel de riesgo: ALTO
Message ID (SES): <mensaje-id-ses>

Tiempo de procesamiento: 2.1s

========================================
  Preview del Email Generado
========================================

Asunto: Importante: Resultados de tu examen m√©dico - Seguimiento requerido

Cuerpo (primeros 500 caracteres):
Estimado Juan P√©rez,

Te escribo en relaci√≥n a tu examen m√©dico ocupacional realizado 
el 15 de noviembre de 2024.

RESULTADOS:
‚Ä¢ Presi√≥n arterial: 165/105 mmHg (significativamente elevada)
‚Ä¢ IMC: 31.2 (obesidad grado I)
...

‚úì Base de datos actualizada correctamente
  Fecha env√≠o: 2024-12-04 10:30:00
  Message ID: <mensaje-id-ses>
```

#### Paso 2: Verificar Email Recibido

1. Revisa tu bandeja de entrada
2. Busca el email con el asunto correspondiente
3. Verifica que el tono es apropiado para el nivel de riesgo
4. Confirma que NO menciona informaci√≥n de otros empleados

#### Paso 3: Verificar en Base de Datos

```bash
# Ver informes con emails enviados
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database $DATABASE_NAME \
  --sql "SELECT im.id, im.trabajador_nombre, im.nivel_riesgo, im.email_enviado, im.fecha_email_enviado, im.email_message_id FROM informes_medicos WHERE im.email_enviado = TRUE" \
  | python3 -m json.tool
```

**Qu√© verificar:**
- ‚úÖ `email_enviado` = true
- ‚úÖ `fecha_email_enviado` tiene timestamp
- ‚úÖ `email_message_id` tiene el ID de SES

### Parte 3: Privacidad M√©dica en Emails (10 min)

#### CR√çTICO: Emails NO Deben Violar Privacidad

**Regla de Oro**: Los empleados NUNCA deben recibir informaci√≥n de otros empleados.

#### ‚úÖ Email CORRECTO (Riesgo ALTO)

```
Estimado Juan P√©rez,

Tu examen m√©dico ocupacional del 15 de noviembre muestra:

RESULTADOS:
‚Ä¢ Presi√≥n arterial: 165/105 mmHg (significativamente elevada)
‚Ä¢ IMC: 31.2 (obesidad grado I)

RECOMENDACIONES URGENTES:
1. Consulta con cardi√≥logo en las pr√≥ximas 48-72 horas
2. Ex√°menes adicionales requeridos
3. Cambios inmediatos en estilo de vida

Estas recomendaciones est√°n basadas en las mejores pr√°cticas 
m√©dicas para tu perfil de salud y tipo de trabajo.

[‚úì Solo datos del empleado actual]
[‚úì NO menciona casos similares]
[‚úì Recomendaciones sin revelar origen]
```

#### ‚ùå Email INCORRECTO (Viola privacidad)

```
Estimado Juan,

Tu presi√≥n arterial (165/105) es similar a la de otros 4 empleados.

Hemos encontrado casos similares:
‚Ä¢ Pedro Garc√≠a tuvo presi√≥n similar y mejor√≥ con...
‚Ä¢ Carlos L√≥pez tambi√©n requiri√≥ seguimiento...

[‚ùå NUNCA mencionar otros empleados]
[‚ùå NUNCA compartir informaci√≥n de terceros]
[‚ùå NUNCA revelar que se us√≥ RAG]
```

#### Frases Prohibidas

NUNCA usar en emails:
- "Encontramos casos similares al tuyo..."
- "Otros empleados con tu perfil..."
- "Bas√°ndonos en casos previos de..."
- "Comparado con tus compa√±eros..."
- "El promedio de los empleados..."

#### Frases Correctas

S√ç usar en emails:
- "Bas√°ndonos en las mejores pr√°cticas m√©dicas..."
- "Estas recomendaciones est√°n dise√±adas para tu perfil..."
- "Seg√∫n las gu√≠as cl√≠nicas actuales..."
- "Para tu tipo de trabajo y perfil de salud..."

**Documentaci√≥n completa**: Ver `docs/EMAIL_EXAMPLES.md`

### Parte 4: Verificar Emails en Amazon SES (5 min)

#### Paso 1: Acceder a SES Console

1. Abre AWS Console
2. Navega a Amazon SES
3. Ve a "Email sending" ‚Üí "Sending statistics"

#### Paso 2: Verificar Estad√≠sticas

Ver√°s:
- Emails enviados
- Emails entregados
- Bounces (rebotes)
- Complaints (quejas)

#### Paso 3: Ver Detalles de un Email

```bash
# Ver estad√≠sticas de env√≠o de SES
aws ses get-send-statistics
```

---

## üîó Integraci√≥n y Discusi√≥n (20 min)

### C√≥mo los M√≥dulos Trabajan Juntos

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FLUJO COMPLETO D√çA 2                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. CLASIFICACI√ìN (D√≠a 1)
   ‚îî‚îÄ> Informe clasificado como ALTO/MEDIO/BAJO

2. GENERACI√ìN DE EMBEDDINGS (D√≠a 2 - M√≥dulo 3)
   ‚îî‚îÄ> Vector de 1024 dimensiones almacenado en BD

3. B√öSQUEDA DE SIMILITUD (D√≠a 2 - M√≥dulo 3)
   ‚îî‚îÄ> M√©dico ve 5 casos similares (USO INTERNO)
   ‚îî‚îÄ> Contexto para mejores decisiones

4. GENERACI√ìN DE EMAIL (D√≠a 2 - M√≥dulo 4)
   ‚îî‚îÄ> Email personalizado seg√∫n nivel de riesgo
   ‚îî‚îÄ> SIN mencionar casos similares (PRIVACIDAD)
   ‚îî‚îÄ> Empleado recibe mejores recomendaciones

5. ENV√çO VIA SES (D√≠a 2 - M√≥dulo 4)
   ‚îî‚îÄ> Email entregado al empleado
   ‚îî‚îÄ> Tracking con Message ID
```

### Casos de Uso Reales

#### Caso 1: Trabajador Nuevo con Riesgo Alto

**Sin RAG**:
- M√©dico no tiene contexto hist√≥rico
- Recomendaciones gen√©ricas
- Seguimiento est√°ndar

**Con RAG**:
- Sistema encuentra 5 casos similares
- M√©dico ve que 4/5 mejoraron con pausas ergon√≥micas
- M√©dico ve que 1/5 requiri√≥ seguimiento cardiol√≥gico
- **Recomendaci√≥n mejorada**: Pausas ergon√≥micas + seguimiento preventivo
- **Email al empleado**: Solo recomendaciones, sin mencionar casos similares

#### Caso 2: Trabajador con Historial

**Sin RAG**:
- M√©dico revisa manualmente informes anteriores
- Proceso lento y propenso a errores

**Con RAG**:
- Sistema autom√°ticamente encuentra informes anteriores
- M√©dico ve tendencias (mejorando/empeorando)
- Recomendaciones basadas en evoluci√≥n
- **Email al empleado**: Menciona su propia evoluci√≥n, no otros casos

### Mejoras Futuras

Ideas para explorar despu√©s del workshop:

1. **RAG en Emails**: Usar casos similares para generar recomendaciones (sin violarlas privacidad)
2. **An√°lisis de Tendencias**: Identificar patrones ocupacionales por tipo de trabajo
3. **Alertas Proactivas**: Notificar cuando un trabajador se acerca a umbrales de riesgo
4. **Dashboard para M√©dicos**: Visualizar casos similares y tendencias
5. **Feedback Loop**: Aprender de qu√© recomendaciones funcionan mejor

---

## üé® Experimentaci√≥n Libre (10 min)

### Ideas para Experimentar

#### 1. Modificar Prompts de Emails

```bash
# Editar prompt (usa nano en CloudShell)
nano prompts/email-alto-riesgo.txt

# Cambiar tono (m√°s emp√°tico, m√°s t√©cnico, m√°s simple)
# Guardar cambios: Ctrl+X, Y, Enter

# Re-desplegar el stack para aplicar cambios
cd ~/pulsosalud-immersion-day/cdk
npx cdk deploy $PARTICIPANT_PREFIX-AIEmailStack --require-approval never

# Probar nuevo email
cd ~/pulsosalud-immersion-day/scripts/examples
aws lambda invoke \
  --function-name $PARTICIPANT_PREFIX-send-email \
  --cli-binary-format raw-in-base64-out \
  --payload '{"informe_id": 1}' \
  email_test.json

cat email_test.json | python3 -m json.tool
```

#### 2. Comparar Similarity Scores

```bash
# Generar embeddings para varios informes
for i in {1..5}; do
  echo "=== Generando embedding para Informe $i ==="
  aws lambda invoke \
    --function-name $PARTICIPANT_PREFIX-generate-embeddings \
    --cli-binary-format raw-in-base64-out \
    --payload "{\"informe_id\": $i}" \
    embedding_$i.json
  cat embedding_$i.json | python3 -m json.tool
  echo ""
done

# Buscar similares para cada uno
for i in {1..5}; do
  echo "=== Similares para Informe $i ==="
  aws lambda invoke \
    --function-name $PARTICIPANT_PREFIX-generate-embeddings \
    --cli-binary-format raw-in-base64-out \
    --payload "{\"informe_id\": $i, \"action\": \"similarity_search\", \"top_k\": 5}" \
    similarity_$i.json
  cat similarity_$i.json | python3 -m json.tool
  echo ""
done

# Analizar: ¬øQu√© hace que dos casos sean similares?
```

#### 3. Validar Privacidad

```bash
# Generar varios emails y validar privacidad
for i in {1..5}; do
    echo ""
    echo "=== Email para Informe $i ==="
    aws lambda invoke \
      --function-name $PARTICIPANT_PREFIX-send-email \
      --cli-binary-format raw-in-base64-out \
      --payload "{\"informe_id\": $i}" \
      email_$i.json
    
    # Revisar manualmente el contenido:
    echo "Revisando email_$i.json:"
    cat email_$i.json | python3 -m json.tool | grep -A 20 "body"
    
    # Verificar:
    # - ¬øMenciona otros empleados? ‚ùå
    # - ¬øDice "casos similares"? ‚ùå
    # - ¬øSolo datos del empleado actual? ‚úÖ
    echo "---"
done
```

### Recursos para Experimentaci√≥n

- **Gu√≠a de Experimentaci√≥n**: `docs/EXPERIMENTATION_GUIDE.md`
- **Ejemplos de Prompts**: `docs/PROMPT_EXAMPLES.md`
- **Ejemplos de Emails**: `docs/EMAIL_EXAMPLES.md`
- **Privacidad RAG**: `docs/RAG_PRIVACY.md`

---

## üìã Resumen del D√≠a 2

### Lo que Aprendiste

‚úÖ **RAG Avanzado con Embeddings**:
- Por qu√© SQL no es suficiente para b√∫squeda sem√°ntica
- C√≥mo funcionan los embeddings vectoriales
- B√∫squeda de similitud con pgvector
- Consideraciones de privacidad m√©dica

‚úÖ **Emails Personalizados**:
- Personalizaci√≥n por nivel de riesgo
- Prompts espec√≠ficos para cada nivel
- Generaci√≥n y env√≠o con Amazon SES
- Validaci√≥n de privacidad en emails

‚úÖ **Integraci√≥n**:
- C√≥mo los m√≥dulos trabajan juntos
- Flujo completo del sistema
- Casos de uso reales
- Mejoras futuras

### Pr√≥ximos Pasos

1. **Experimenta** con los scripts y prompts
2. **Revisa** la documentaci√≥n adicional en `docs/`
3. **Comparte** tus descubrimientos con otros participantes
4. **Considera** c√≥mo aplicar esto en tu organizaci√≥n

### Recursos Adicionales

- [Amazon Bedrock Documentation](https://docs.aws.amazon.com/bedrock/)
- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [Amazon SES Documentation](https://docs.aws.amazon.com/ses/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)

---
- Resultados inconsistentes

**Versi√≥n 2** ([`prompts/classification_v2.txt`](prompts/classification_v2.txt)):
- Con ejemplos b√°sicos
- Mejor, pero sin contexto hist√≥rico

**Versi√≥n 3** ([`prompts/classification.txt`](prompts/classification.txt)):
- Con ejemplos detallados
- Con contexto hist√≥rico (RAG)
- Resultados precisos y consistentes

**Lecci√≥n:** Few-shot learning + RAG = Clasificaci√≥n precisa

---

### M√≥dulo 5: Res√∫menes y Emails Personalizados (30 min)

#### Objetivo
Generar res√∫menes ejecutivos y emails personalizados seg√∫n el nivel de riesgo.

#### Paso 1: Desplegar Stacks de Resumen y Email

```bash
cd cdk
cdk deploy AISummaryStack
cdk deploy AIEmailStack
```

#### Paso 2: Generar Resumen Ejecutivo

```bash
# Generar resumen
aws lambda invoke \
  --function-name generate-summary \
  --payload '{"informe_id": 1}' \
  response.json

# Ver resultado
cat response.json
```

**Caracter√≠sticas del resumen:**
- M√°ximo 150 palabras
- Lenguaje claro y no t√©cnico
- Incluye tendencias hist√≥ricas (RAG)
- Enfocado en lo m√°s importante

#### Paso 3: Revisar Prompt de Resumen

Abre [`prompts/summary.txt`](prompts/summary.txt):

```
Genera un resumen ejecutivo del informe m√©dico.

REQUISITOS:
- M√°ximo 150 palabras
- Lenguaje claro, no t√©cnico
- Enf√≥cate en hallazgos principales
- Incluye tendencias si hay informes anteriores

CONTEXTO HIST√ìRICO:
[Informes anteriores - proporcionado por RAG]

INFORME ACTUAL:
[Datos del informe]

FORMATO:
P√°rrafo √∫nico, directo y accionable.
```

**Par√°metros:**
- `temperature: 0.5` (balanceado entre precisi√≥n y fluidez)
- `maxTokens: 300`

#### Paso 4: Enviar Email Personalizado

```bash
# Enviar email
aws lambda invoke \
  --function-name send-email \
  --payload '{"informe_id": 1}' \
  response.json
```

#### Paso 5: Revisar Prompts de Email

Hay 3 prompts diferentes seg√∫n el nivel de riesgo:

**Email Riesgo ALTO** ([`prompts/email_high.txt`](prompts/email_high.txt)):
```
Genera un email URGENTE para el contratista.

TONO: Urgente pero profesional
OBJETIVO: Acci√≥n inmediata

Incluye:
- Hallazgos cr√≠ticos
- Acciones requeridas INMEDIATAMENTE
- Consecuencias de no actuar
```

**Email Riesgo MEDIO** ([`prompts/email_medium.txt`](prompts/email_medium.txt)):
```
Genera un email PROFESIONAL para el contratista.

TONO: Profesional y constructivo
OBJETIVO: Seguimiento programado

Incluye:
- Hallazgos que requieren atenci√≥n
- Recomendaciones de seguimiento
- Plazo sugerido
```

**Email Riesgo BAJO** ([`prompts/email_low.txt`](prompts/email_low.txt)):
```
Genera un email TRANQUILIZADOR para el contratista.

TONO: Positivo y alentador
OBJETIVO: Confirmar estado saludable

Incluye:
- Confirmaci√≥n de par√°metros normales
- Felicitaci√≥n por mantener salud
- Recordatorio de controles peri√≥dicos
```

**Par√°metros:**
- `temperature: 0.7` (m√°s creativo para personalizaci√≥n)
- `maxTokens: 500`

#### Paso 6: Verificar Email Recibido

Revisa tu bandeja de entrada. Deber√≠as recibir un email personalizado seg√∫n el nivel de riesgo del informe.

---

### üé® Experimentaci√≥n Libre (30 min)

Ahora es tu turno de experimentar. Aqu√≠ hay algunas ideas:

#### Experimento 1: Modificar Tono de Emails

1. Abre [`prompts/email_high.txt`](prompts/email_high.txt)
2. Cambia "URGENTE" por "IMPORTANTE"
3. Re-despliega: `cdk deploy AIEmailStack`
4. Env√≠a otro email y compara

#### Experimento 2: Ajustar Longitud de Res√∫menes

1. Abre [`prompts/summary.txt`](prompts/summary.txt)
2. Cambia "M√°ximo 150 palabras" a "M√°ximo 50 palabras"
3. Re-despliega: `cdk deploy AISummaryStack`
4. Genera otro resumen y compara

#### Experimento 3: Agregar M√°s Ejemplos a Clasificaci√≥n

1. Abre [`prompts/classification.txt`](prompts/classification.txt)
2. Agrega un 4to ejemplo con un caso espec√≠fico
3. Re-despliega: `cdk deploy AIClassificationStack`
4. Clasifica varios informes y observa mejoras

#### Experimento 4: Cambiar Temperature

Prueba diferentes valores de temperature:

| Temperature | Uso Ideal | Resultado |
|-------------|-----------|-----------|
| 0.0 - 0.2 | Extracci√≥n, clasificaci√≥n | Determin√≠stico, preciso |
| 0.3 - 0.5 | Res√∫menes, an√°lisis | Balanceado |
| 0.6 - 0.8 | Emails, contenido | Creativo, variado |
| 0.9 - 1.0 | Brainstorming | Muy creativo |

#### Experimento 5: Comparar Con y Sin RAG

1. Modifica [`lambda/ai/classify_risk/index.py`](lambda/ai/classify_risk/index.py)
2. Comenta la secci√≥n que agrega contexto hist√≥rico
3. Re-despliega y compara resultados

**Pregunta:** ¬øC√≥mo mejora RAG la precisi√≥n?

---

## üîß Troubleshooting

### Problema 1: "Lambda not found" o "Function not found"

**Causa:** La Lambda no se despleg√≥ correctamente o est√°s usando el prefijo incorrecto.

**Soluci√≥n:**
```bash
# 1. Verifica que usaste tu prefijo correcto
# Ejemplo: participant-1, participant-2, etc.

# 2. Verifica que las Lambdas existen
aws lambda list-functions --query 'Functions[?contains(FunctionName, `participant-1`)].FunctionName'

# 3. Si no aparecen, re-despliega los AI Stacks
cd cdk
npx cdk deploy participant-1-AIClassificationStack participant-1-AISummaryStack --require-approval never
```

**Checklist:**
- ‚úÖ ¬øUsaste el prefijo correcto en todos los comandos?
- ‚úÖ ¬øCompletaste el despliegue del Paso 4 del Setup?
- ‚úÖ ¬øEst√°s en la regi√≥n correcta (us-east-2)?

---

### Problema 2: "Access denied to Aurora" o "Database connection failed"

**Causa:** La Lambda no tiene permisos para acceder a Aurora o hay un problema de red.

**Soluci√≥n:**
```bash
# 1. Verifica que el LegacyStack se despleg√≥ correctamente
aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].StackStatus'

# Debe retornar: "CREATE_COMPLETE" o "UPDATE_COMPLETE"

# 2. Verifica que las variables de entorno est√°n configuradas
echo $CLUSTER_ARN
echo $SECRET_ARN

# 3. Si est√°n vac√≠as, config√∫ralas nuevamente (ver M√≥dulo 1, Parte 1, Paso 1)

# 4. Si el problema persiste, contacta al instructor
```

**Nota:** El instructor despleg√≥ tu LegacyStack antes del workshop. Si hay problemas, es probable que necesite re-desplegarlo.

---

### Problema 3: "Bedrock access denied" o "Model access denied"

**Causa:** Tu cuenta no tiene acceso al modelo Nova Pro o la regi√≥n es incorrecta.

**Soluci√≥n:**
```bash
# 1. Verifica que est√°s en us-east-2
aws configure get region

# 2. Verifica acceso a Bedrock
aws bedrock list-foundation-models --region us-east-2 \
  --query 'modelSummaries[?contains(modelId, `nova-pro`)].modelId'

# 3. Si no aparece, contacta al instructor
# El instructor debe habilitar el modelo en la cuenta
```

**Nota:** El acceso a Bedrock debe estar configurado por el instructor antes del workshop.

---

### Problema 4: Los logs no aparecen en CloudWatch

**Causa:** Los logs pueden tardar 1-2 minutos en aparecer despu√©s de invocar la Lambda.

**Soluci√≥n:**
```bash
# 1. Espera 1-2 minutos despu√©s de invocar la Lambda

# 2. Verifica que la Lambda se ejecut√≥
aws lambda invoke \
  --function-name participant-1-classify-risk \
  --cli-binary-format raw-in-base64-out \
  --payload '{"informe_id": 1}' \
  response.json

# 3. Intenta ver los logs nuevamente
aws logs tail /aws/lambda/participant-1-classify-risk --follow

# 4. Si a√∫n no aparecen, verifica el nombre del log group
aws logs describe-log-groups \
  --log-group-name-prefix /aws/lambda/participant-1
```

**Tip:** Presiona Ctrl+C para salir del comando `--follow`.

---

### Problema 5: La App Web no carga o muestra error

**Causa:** La URL es incorrecta o el bucket S3 no est√° configurado correctamente.

**Soluci√≥n:**
```bash
# 1. Obt√©n la URL correcta de tu app web
aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`WebsiteURL`].OutputValue' \
  --output text

# 2. Copia y pega la URL en tu navegador

# 3. Si muestra error 403 o 404, contacta al instructor
```

---

### Problema 6: "Informe not classified" al generar resumen

**Causa:** Est√°s intentando generar un resumen de un informe que no ha sido clasificado.

**Soluci√≥n:**
```bash
# 1. Primero clasifica el informe
aws lambda invoke \
  --function-name participant-1-classify-risk \
  --cli-binary-format raw-in-base64-out \
  --payload '{"informe_id": 1}' \
  response.json

# 2. Verifica que se clasific√≥ correctamente
cat response.json

# 3. Ahora genera el resumen
aws lambda invoke \
  --function-name participant-1-generate-summary \
  --cli-binary-format raw-in-base64-out \
  --payload '{"informe_id": 1}' \
  summary.json
```

**Regla:** Siempre debes clasificar un informe antes de generar su resumen.

---

### Problema 7: Comandos de CloudShell no funcionan

**Causa:** Sintaxis incorrecta o variables no definidas.

**Soluci√≥n:**
```bash
# 1. Verifica que definiste las variables de entorno
echo $CLUSTER_ARN
echo $SECRET_ARN

# 2. Si est√°n vac√≠as, def√≠nelas nuevamente
export CLUSTER_ARN=$(aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`DatabaseClusterArn`].OutputValue' \
  --output text)

export SECRET_ARN=$(aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`DatabaseSecretArn`].OutputValue' \
  --output text)

# 3. Verifica que ahora tienen valores
echo $CLUSTER_ARN
echo $SECRET_ARN
```

---

### Checklist General de Verificaci√≥n

Si tienes problemas, verifica estos puntos en orden:

1. **‚úÖ Prefijo correcto:** ¬øEst√°s usando `participant-1`, `participant-2`, etc. seg√∫n tu asignaci√≥n?
2. **‚úÖ Regi√≥n correcta:** ¬øEst√°s en `us-east-2`?
3. **‚úÖ Sesi√≥n AWS activa:** ¬øPuedes ejecutar `aws sts get-caller-identity` sin errores?
4. **‚úÖ Stacks desplegados:** ¬øCompletaste el Paso 4 del Setup (despliegue de AI Stacks)?
5. **‚úÖ Logs recientes:** ¬øEsperaste 1-2 minutos para que aparezcan los logs?

---

### Comandos √ötiles para Debugging

```bash
# Ver todos tus stacks
aws cloudformation list-stacks \
  --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE \
  --query 'StackSummaries[?contains(StackName, `participant-1`)].StackName'

# Ver todas tus Lambdas
aws lambda list-functions \
  --query 'Functions[?contains(FunctionName, `participant-1`)].FunctionName'

# Ver outputs de un stack
aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs'

# Ver √∫ltimos logs de una Lambda (sin follow)
aws logs tail /aws/lambda/participant-1-classify-risk --since 5m
```

---

### ¬øCu√°ndo pedir ayuda al instructor?

Pide ayuda si:
- ‚ùå Los comandos de verificaci√≥n muestran que faltan recursos
- ‚ùå Ves errores de permisos IAM o Bedrock
- ‚ùå La App Web no carga despu√©s de verificar la URL
- ‚ùå Los problemas persisten despu√©s de seguir las soluciones

**No te preocupes:** Estos workshops tienen muchas partes m√≥viles. El instructor est√° para ayudarte! üôÇ

---

## üìã Ejemplos de Output Esperado

Esta secci√≥n muestra ejemplos de outputs correctos para que puedas verificar que todo funciona bien.

### Output 1: Clasificaci√≥n Exitosa

**Comando:**
```bash
aws lambda invoke \
  --function-name participant-1-classify-risk \
  --cli-binary-format raw-in-base64-out \
  --payload '{"informe_id": 1}' \
  response.json && cat response.json
```

**Output esperado:**
```json
{
  "statusCode": 200,
  "body": {
    "informe_id": 1,
    "nivel_riesgo": "ALTO",
    "justificacion": "El trabajador presenta hipertensi√≥n arterial severa (165/102 mmHg) que supera significativamente los valores normales. Adem√°s, se observa obesidad grado I (IMC 32.9) y diabetes mellitus descompensada. Estos factores combinados representan un riesgo cardiovascular elevado que requiere intervenci√≥n m√©dica inmediata.",
    "tiempo_procesamiento": "2.3s",
    "informes_anteriores_encontrados": 2
  }
}
```

**Qu√© verificar:**
- ‚úÖ `statusCode: 200` (√©xito)
- ‚úÖ `nivel_riesgo` es uno de: BAJO, MEDIO, ALTO
- ‚úÖ `justificacion` tiene sentido m√©dicamente
- ‚úÖ `tiempo_procesamiento` es razonable (1-5 segundos)

---

### Output 2: Generaci√≥n de Resumen Exitosa

**Comando:**
```bash
aws lambda invoke \
  --function-name participant-1-generate-summary \
  --cli-binary-format raw-in-base64-out \
  --payload '{"informe_id": 1}' \
  summary.json && cat summary.json
```

**Output esperado:**
```json
{
  "statusCode": 200,
  "body": {
    "informe_id": 1,
    "resumen": "El trabajador Carlos Rodr√≠guez presenta m√∫ltiples factores de riesgo que requieren atenci√≥n m√©dica inmediata. Se detecta hipertensi√≥n arterial severa (165/102 mmHg) y obesidad grado I (IMC: 32.9). Los ex√°menes de laboratorio revelan diabetes mellitus descompensada. Comparado con su examen anterior hace 6 meses, se observa deterioro significativo en todos los par√°metros. Se recomienda restricci√≥n inmediata de actividades de alto riesgo y evaluaci√≥n m√©dica urgente.",
    "palabras": 87,
    "tiempo_procesamiento": "1.8s",
    "incluye_contexto_historico": true
  }
}
```

**Qu√© verificar:**
- ‚úÖ `statusCode: 200` (√©xito)
- ‚úÖ `resumen` es claro y no t√©cnico
- ‚úÖ `palabras` est√° entre 80-180
- ‚úÖ Menciona el nivel de riesgo y acciones recomendadas

---

### Output 3: Logs de Clasificaci√≥n

**Comando:**
```bash
aws logs tail /aws/lambda/participant-1-classify-risk --since 5m
```

**Output esperado (fragmentos clave):**
```
2024-12-02T10:15:23.456Z [INFO] Lambda invocation started
2024-12-02T10:15:23.567Z [INFO] Loading informe ID: 1
2024-12-02T10:15:23.678Z [INFO] Worker ID: 3, searching for historical reports
2024-12-02T10:15:23.789Z [INFO] RAG: Retrieved 2 previous reports
2024-12-02T10:15:23.890Z [INFO] Loading classification prompt from S3
2024-12-02T10:15:23.991Z [INFO] Few-shot examples loaded: 3 examples
2024-12-02T10:15:24.102Z [INFO] Invoking Bedrock with inference profile: us.amazon.nova-pro-v1:0
2024-12-02T10:15:25.234Z [INFO] Bedrock response received
2024-12-02T10:15:25.345Z [INFO] Classification result: ALTO
2024-12-02T10:15:25.456Z [INFO] Saving to Aurora database
2024-12-02T10:15:25.567Z [INFO] Lambda execution completed successfully
```

**Qu√© buscar:**
- ‚úÖ `RAG: Retrieved X previous reports` (contexto hist√≥rico)
- ‚úÖ `Few-shot examples loaded` (prompt con ejemplos)
- ‚úÖ `Invoking Bedrock` (llamada a IA)
- ‚úÖ `Classification result: BAJO/MEDIO/ALTO` (resultado)
- ‚úÖ `Lambda execution completed successfully` (√©xito)

---

### Output 4: Query a Aurora

**Comando:**
```bash
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database medical_reports \
  --sql "SELECT id, nivel_riesgo, LENGTH(resumen_ejecutivo) as resumen_length FROM informes_medicos WHERE id = 1"
```

**Output esperado:**
```json
{
  "records": [
    [
      {"longValue": 1},
      {"stringValue": "ALTO"},
      {"longValue": 523}
    ]
  ],
  "columnMetadata": [
    {"name": "id", "type": 4},
    {"name": "nivel_riesgo", "type": 12},
    {"name": "resumen_length", "type": 4}
  ]
}
```

**Qu√© verificar:**
- ‚úÖ `nivel_riesgo` tiene un valor (BAJO/MEDIO/ALTO)
- ‚úÖ `resumen_length` es mayor a 0 (si ya generaste el resumen)

---

### Output 5: Lista de Informes (App Web)

**Endpoint:** `GET /informes`

**Output esperado:**
```json
{
  "informes": [
    {
      "id": 1,
      "trabajador_nombre": "Juan P√©rez G√≥mez",
      "tipo_examen": "Examen Ocupacional Peri√≥dico",
      "presion_arterial": "165/102",
      "nivel_riesgo": "ALTO",
      "fecha_examen": "2024-12-01T10:00:00Z"
    },
    {
      "id": 2,
      "trabajador_nombre": "Mar√≠a Gonz√°lez L√≥pez",
      "tipo_examen": "Examen Pre-Ocupacional",
      "presion_arterial": "135/85",
      "nivel_riesgo": "MEDIO",
      "fecha_examen": "2024-12-01T11:00:00Z"
    },
    ...
  ]
}
```

**Qu√© verificar:**
- ‚úÖ Array con 10 informes
- ‚úÖ Cada informe tiene datos completos
- ‚úÖ Algunos tienen `nivel_riesgo` null (no clasificados a√∫n)

---

### Errores Comunes y Sus Outputs

#### Error 1: Lambda no encontrada
```json
{
  "errorMessage": "Function not found: arn:aws:lambda:us-east-2:123456789012:function:participant-1-classify-risk",
  "errorType": "ResourceNotFoundException"
}
```
**Soluci√≥n:** Verifica el prefijo y que desplegaste los AI Stacks.

#### Error 2: Informe no clasificado
```json
{
  "statusCode": 400,
  "body": {
    "error": "InformeNotClassifiedError",
    "message": "El informe debe ser clasificado antes de generar resumen",
    "informe_id": 1
  }
}
```
**Soluci√≥n:** Clasifica el informe primero con `classify-risk`.

#### Error 3: Bedrock access denied
```json
{
  "statusCode": 502,
  "body": {
    "error": "BedrockInvocationError",
    "message": "Access denied to Bedrock model",
    "model_id": "us.amazon.nova-pro-v1:0"
  }
}
```
**Soluci√≥n:** Contacta al instructor para habilitar acceso a Bedrock.

---

## üßπ Limpieza de Recursos

Al finalizar el workshop, elimina todos los recursos:

```bash
cd cdk

# Eliminar todos los stacks
cdk destroy --all

# Confirmar: y

# Verificar que todo se elimin√≥
aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE
```

**Importante:** Aurora se eliminar√° autom√°ticamente sin crear snapshots (configurado para la demo).

---

## üìä Resumen de Conceptos Aprendidos

### Servicios AWS
- ‚úÖ **Amazon Bedrock** - LLMs como servicio
- ‚úÖ **Amazon Nova Pro** - Modelo de lenguaje avanzado
- ‚úÖ **Amazon Titan Embeddings** - Generaci√≥n de embeddings
- ‚úÖ **Amazon Textract** - OCR para PDFs
- ‚úÖ **Aurora Serverless v2** - Base de datos con pgvector
- ‚úÖ **Lambda** - Funciones serverless
- ‚úÖ **S3** - Almacenamiento de objetos
- ‚úÖ **SES** - Env√≠o de emails
- ‚úÖ **CDK** - Infraestructura como c√≥digo

### T√©cnicas de IA Generativa
- ‚úÖ **Prompt Engineering** - Dise√±o de prompts efectivos
- ‚úÖ **Few-Shot Learning** - Aprendizaje con pocos ejemplos
- ‚úÖ **RAG** - Retrieval-Augmented Generation
- ‚úÖ **Embeddings Vectoriales** - Representaci√≥n de texto
- ‚úÖ **Temperature Control** - Control de aleatoriedad
- ‚úÖ **Token Management** - Gesti√≥n de longitud de respuestas

### Mejores Pr√°cticas
- ‚úÖ Prompts espec√≠ficos con ejemplos
- ‚úÖ Temperature baja para precisi√≥n
- ‚úÖ RAG para reducir alucinaciones
- ‚úÖ Iteraci√≥n de prompts
- ‚úÖ Validaci√≥n de salidas
- ‚úÖ Monitoreo con CloudWatch

---

## üéØ Pr√≥ximos Pasos

Despu√©s del workshop, puedes:

1. **Experimentar m√°s** con diferentes prompts y par√°metros
2. **Agregar nuevos casos de uso** (ej: an√°lisis de tendencias)
3. **Integrar con otros servicios** (ej: Step Functions para orquestaci√≥n)
4. **Optimizar costos** ajustando modelos y par√°metros
5. **Implementar en producci√≥n** con mejores pr√°cticas de seguridad

---

## üìö Recursos Adicionales

- [Amazon Bedrock Documentation](https://docs.aws.amazon.com/bedrock/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [AWS CDK Documentation](https://docs.aws.amazon.com/cdk/)
- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [RAG Best Practices](https://aws.amazon.com/blogs/machine-learning/rag-best-practices/)

---

## ‚ùì Preguntas Frecuentes

**P: ¬øCu√°nto cuesta ejecutar esta demo?**
R: Aproximadamente $5-10 USD por participante (Aurora + Bedrock + otros servicios).

**P: ¬øPuedo usar otros modelos de Bedrock?**
R: S√≠, puedes cambiar el modelId en el c√≥digo. Ejemplos: Claude, Llama, etc.

**P: ¬øFunciona en otras regiones?**
R: S√≠, pero verifica disponibilidad de Bedrock en tu regi√≥n.

**P: ¬øC√≥mo escalo esto a producci√≥n?**
R: Agrega: autenticaci√≥n, rate limiting, monitoreo avanzado, CI/CD, y backups.

**P: ¬øPuedo usar mis propios PDFs?**
R: S√≠, sube cualquier PDF m√©dico a S3 en la carpeta `/external-reports/`.

---

**¬°Felicitaciones!** üéâ Has completado el workshop de Automatizaci√≥n de Informes M√©dicos con AWS y Amazon Bedrock.

¬øPreguntas? Consulta con el instructor o revisa la [Gu√≠a del Instructor](INSTRUCTOR_GUIDE.md).


---

## üèóÔ∏è Arquitectura del Workshop (Informaci√≥n Adicional)

### ¬øPor qu√© el despliegue es tan r√°pido ahora?

El workshop usa una **arquitectura optimizada** que separa la infraestructura en dos capas:

#### Capa 1: Infraestructura Base (Desplegada por el Instructor)
- **SharedNetworkStack:** VPC compartida para todos los participantes
- **LegacyStack:** Tu Aurora, S3, API Gateway y Lambdas Legacy
- **Tiempo:** ~15 minutos por participante (desplegado antes del workshop)

#### Capa 2: AI Stacks (Desplegada por Ti)
- **5 AI Stacks:** Lambdas de procesamiento de IA
- **Tiempo:** ~5-8 minutos (desplegado durante el workshop)

### Beneficios de esta Arquitectura

‚úÖ **M√°s tiempo para aprender:** 70-80% menos tiempo de despliegue en vivo
‚úÖ **Recursos compartidos:** VPC compartida reduce costos
‚úÖ **Aislamiento completo:** Cada participante tiene su propia Aurora y S3
‚úÖ **Despliegue paralelo:** El instructor puede preparar m√∫ltiples participantes simult√°neamente

### Recursos que Tienes

Despu√©s del despliegue, tienes acceso a:

**Base de Datos:**
- Aurora Serverless v2 (PostgreSQL 15.8 con pgvector)
- Credenciales en AWS Secrets Manager
- Tablas: `patients`, `exams`, `exam_embeddings`

**Almacenamiento:**
- S3 Bucket individual: `<tu-prefix>-medical-reports-<account-id>`
- Carpetas: `external-reports/`, `generated-reports/`

**APIs:**
- API Gateway con endpoints:
  - `POST /examenes` - Registrar examen
  - `POST /examenes/generar-prueba` - Generar datos de prueba

**Lambdas de IA:**
- `extract-pdf` - Extracci√≥n con Textract + Bedrock
- `generate-embeddings` - Embeddings con Titan
- `classify-risk` - Clasificaci√≥n con Nova Pro
- `generate-summary` - Res√∫menes con Nova Pro
- `send-email` - Emails con Nova Pro + SES

### Documentaci√≥n Adicional

- **Modos de despliegue:** Ver [`cdk/DEPLOY_MODES.md`](cdk/DEPLOY_MODES.md)
- **Gu√≠a del instructor:** Ver [`INSTRUCTOR_GUIDE.md`](INSTRUCTOR_GUIDE.md)
- **Arquitectura t√©cnica:** Ver [`.kiro/specs/workshop-deployment-optimization/design.md`](.kiro/specs/workshop-deployment-optimization/design.md)

---

## üÜò Soporte

Si tienes problemas durante el workshop:

1. **Revisa la secci√≥n de Troubleshooting** en el Setup Inicial
2. **Verifica CloudFormation** en la consola AWS
3. **Consulta CloudWatch Logs** para errores de Lambda
4. **Contacta al instructor** para ayuda

---

**¬°Disfruta el workshop y aprende mucho! üöÄ**
