# üéì Gu√≠a para Participantes - Medical Reports Automation Workshop

Bienvenido al workshop de **Automatizaci√≥n de Informes M√©dicos con AWS y Amazon Bedrock**. Esta gu√≠a te llevar√° paso a paso a trav√©s de la implementaci√≥n de un sistema que optimiza el env√≠o de informes m√©dicos a clientes usando IA Generativa.

## üè• El Problema de Negocio

Una empresa de salud ocupacional realiza ex√°menes m√©dicos a trabajadores de empresas contratistas (mineras, constructoras, etc.). 

**Situaci√≥n Actual:**
- Realizan 500+ ex√°menes m√©dicos por mes
- Deben enviar informes a las empresas clientes
- Cada informe requiere:
  - Revisi√≥n manual por m√©dico
  - Clasificaci√≥n de nivel de riesgo
  - Creaci√≥n de resumen ejecutivo
  - Redacci√≥n de email personalizado

**Objetivo del Workshop:**
Automatizar este proceso usando Amazon Bedrock para:
1. ‚úÖ Clasificar autom√°ticamente el nivel de riesgo (BAJO/MEDIO/ALTO)
2. ‚úÖ Generar res√∫menes ejecutivos personalizados
3. ‚úÖ Crear emails con el tono adecuado seg√∫n la urgencia
4. ‚úÖ Reducir tiempo de procesamiento de 20-30 min a 2 min por informe

## üìÖ Estructura del Workshop

**Duraci√≥n Total:** 3 horas 15 minutos (dividido en 2 d√≠as)

### D√≠a 1: Clasificaci√≥n y Res√∫menes con IA (1h 15min)
- ‚è±Ô∏è **5 min** - Setup inicial: Despliegue de AI Stacks (3-5 min de espera)
- ‚è±Ô∏è **30 min** - M√≥dulo 1: Clasificaci√≥n autom√°tica de riesgo con IA
- ‚è±Ô∏è **30 min** - M√≥dulo 2: Generaci√≥n de res√∫menes ejecutivos
- ‚è±Ô∏è **10 min** - Checkpoint D√≠a 1

### D√≠a 2: Capacidades Avanzadas (2h)
- ‚è±Ô∏è **30 min** - M√≥dulo 3: Emails personalizados por nivel de riesgo
- ‚è±Ô∏è **30 min** - M√≥dulo 4: RAG con embeddings vectoriales (contexto hist√≥rico)
- ‚è±Ô∏è **30 min** - M√≥dulo 5: Integraci√≥n de PDFs externos (cl√≠nicas externas)
- ‚è±Ô∏è **30 min** - Experimentaci√≥n libre y Q&A

---

## üöÄ Setup Inicial (5-8 minutos)

### Prerequisitos

Solo necesitas:

- ‚úÖ **Acceso a AWS Console** (proporcionado por el instructor)
- ‚úÖ **Navegador web** (Chrome, Firefox, Edge, Safari)

**¬°Eso es todo!** Usaremos **AWS CloudShell**, que ya tiene todo pre-instalado:
- ‚úÖ AWS CLI configurado autom√°ticamente
- ‚úÖ Node.js y npm
- ‚úÖ Python 3
- ‚úÖ Git
- ‚úÖ Editor de texto (nano, vim)

### Informaci√≥n Proporcionada por el Instructor

**Ejemplo de informaci√≥n que recibir√°s:**
- Usuario AWS: `workshop-user-1`
- PARTICIPANT_PREFIX: `participant-1`
- Email del instructor: `instructor@example.com` ‚Üê **Este es el email del instructor, NO tu email personal**

**‚ö†Ô∏è IMPORTANTE:** El instructor ya despleg√≥ la infraestructura base (VPC, Aurora, S3, App Web) antes del workshop. T√∫ solo desplegar√°s los AI Stacks (2 stacks, 3-5 minutos) durante esta sesi√≥n.

### Paso 1: Abrir AWS CloudShell

1. **Inicia sesi√≥n** en AWS Console con las credenciales proporcionadas
2. **Abre CloudShell**: 
   - Haz clic en el √≠cono de terminal (>_) en la barra superior derecha
   - O busca "CloudShell" en la barra de b√∫squeda
   - Se abrir√° una terminal en tu navegador

![CloudShell est√° en la esquina superior derecha de la consola AWS]

**CloudShell ya tiene todo configurado:**
- ‚úÖ AWS CLI con tus credenciales
- ‚úÖ Node.js, npm, Python, Git
- ‚úÖ 1 GB de almacenamiento persistente

### Paso 2: Clonar el Repositorio

En CloudShell, ejecuta:

```bash
# Clonar repositorio
git clone <repository-url>
cd pulsosalud-immersion-day

# Verificar que est√°s autenticado
aws sts get-caller-identity
```

### Paso 3: Instalar Dependencias del Proyecto

```bash
# Instalar dependencias de CDK
cd cdk
npm install

# Verificar instalaci√≥n (usar npx para ejecutar CDK)
npx cdk --version
```

**Nota:** Usaremos `npx cdk` en lugar de solo `cdk` para ejecutar comandos CDK desde CloudShell.

**Tiempo:** ~2-3 minutos

Mientras se instala, el instructor explicar√° la arquitectura del workshop.

### Paso 4: Desplegar AI Stacks del D√≠a 1

El instructor ya despleg√≥:
- ‚úÖ VPC compartida
- ‚úÖ Aurora Serverless v2 con datos de ejemplo (10 informes m√©dicos)
- ‚úÖ S3 Bucket para almacenamiento
- ‚úÖ API Gateway con endpoints
- ‚úÖ App Web para visualizar y ejecutar acciones
- ‚úÖ Lambdas Legacy (registro de ex√°menes, listado)

T√∫ solo necesitas desplegar los **AI Stacks del D√≠a 1** (2 stacks):

```bash
# Navegar al directorio CDK
cd pulsosalud-immersion-day/cdk

# Desplegar los 2 AI Stacks del D√≠a 1
# Reemplaza participant-1 con tu PARTICIPANT_PREFIX
npx cdk deploy participant-1-AIClassificationStack participant-1-AISummaryStack --require-approval never
```

**Reemplaza:**
- `participant-1` con tu PARTICIPANT_PREFIX asignado (ej: `participant-2`, `participant-3`, etc.)

**Tiempo estimado:** 3-5 minutos

Mientras esperas, el instructor explicar√° la arquitectura del sistema en pantalla compartida.

**Recursos que se desplegar√°n (D√≠a 1):**
1. **AIClassificationStack** - Lambda classify-risk con Bedrock Nova Pro
2. **AISummaryStack** - Lambda generate-summary con Bedrock Nova Pro

**Recursos del D√≠a 2** (se desplegar√°n en la segunda sesi√≥n):
- AIEmailStack - Emails personalizados
- AIRAGStack - Embeddings vectoriales avanzados
- AIExtractionStack - Integraci√≥n de PDFs externos

### Paso 5: Obtener la URL de tu App Web

Una vez completado el despliegue, obt√©n la URL de tu app web:

```bash
# Obtener la URL de tu app web
aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`WebsiteURL`].OutputValue' \
  --output text
```

**Reemplaza `participant-1` con tu prefijo.**

**Copia la URL** y √°brela en tu navegador.

---

**Tu App Web incluye:**
- **Lista de informes m√©dicos** - 10 informes de ejemplo pre-cargados
- **Vista de detalle** - Presi√≥n arterial, IMC, antecedentes, etc.
- **Bot√≥n "Clasificar con IA"** - Llama a tu Lambda classify-risk
- **Bot√≥n "Generar Resumen"** - Llama a tu Lambda generate-summary
- **Estad√≠sticas en tiempo real** - Contadores y distribuci√≥n de riesgo

**Deber√≠as ver:**
- Una tabla con 10 informes m√©dicos
- Cada informe tiene datos completos (nombre, presi√≥n, IMC, etc.)
- Botones de acci√≥n en cada fila
- Panel de estad√≠sticas en la parte superior

**¬°Listo!** Ya puedes empezar con el M√≥dulo 1.

## üìö D√≠a 1: Optimizaci√≥n del Env√≠o de Informes

**‚úÖ Tu infraestructura ya est√° lista:** Si completaste el Setup Inicial, todos tus AI Stacks ya est√°n desplegados y listos para usar.

### M√≥dulo 1: Clasificaci√≥n Autom√°tica de Riesgo (30 min)

**Objetivo:** Automatizar la clasificaci√≥n de informes m√©dicos en niveles de riesgo usando Amazon Bedrock.

#### üéØ El Problema

**Situaci√≥n Actual:**
- Un m√©dico debe revisar CADA informe manualmente
- Debe decidir si es riesgo BAJO, MEDIO o ALTO
- Esto toma 10-15 minutos por informe
- Con 500 informes/mes = 125 horas de trabajo manual
- Riesgo de inconsistencia en criterios entre m√©dicos

**La Soluci√≥n con IA:**
- Amazon Bedrock clasifica autom√°ticamente usando few-shot learning
- Consistencia 100% en criterios de clasificaci√≥n
- Tiempo reducido a 30 segundos por informe
- M√©dico solo revisa casos cr√≠ticos (ALTO riesgo)

**Conceptos Clave:**
```
Few-Shot Learning = Ense√±ar al modelo con pocos ejemplos
Bedrock Nova Pro = Modelo de lenguaje que "entiende" contexto m√©dico
RAG = Buscar informes anteriores del mismo trabajador para contexto
```

**Flujo de Clasificaci√≥n:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Informe     ‚îÇ
‚îÇ M√©dico      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Buscar Informes Anteriores (RAG)    ‚îÇ
‚îÇ    ‚Ä¢ Query SQL: √∫ltimos 3 informes      ‚îÇ
‚îÇ    ‚Ä¢ Mismo trabajador                   ‚îÇ
‚îÇ    ‚Ä¢ Ordenados por fecha DESC           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Construir Prompt con Few-Shot       ‚îÇ
‚îÇ    ‚Ä¢ Cargar ejemplos (BAJO/MEDIO/ALTO) ‚îÇ
‚îÇ    ‚Ä¢ Agregar contexto hist√≥rico         ‚îÇ
‚îÇ    ‚Ä¢ Agregar datos del informe actual   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Invocar Bedrock Nova Pro            ‚îÇ
‚îÇ    ‚Ä¢ Temperature: 0.1 (precisi√≥n)       ‚îÇ
‚îÇ    ‚Ä¢ MaxTokens: 1000                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Parsear Respuesta JSON              ‚îÇ
‚îÇ    ‚Ä¢ nivel_riesgo: BAJO/MEDIO/ALTO     ‚îÇ
‚îÇ    ‚Ä¢ justificacion: texto explicativo   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. Guardar en Aurora                   ‚îÇ
‚îÇ    ‚Ä¢ UPDATE informes_medicos            ‚îÇ
‚îÇ    ‚Ä¢ SET nivel_riesgo, justificacion    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Parte 1: Ver Datos Existentes en el Sistema Legacy (5 min)

El instructor ya carg√≥ datos de ejemplo en tu base de datos Aurora.

#### Paso 1: Obtener endpoint de Aurora (1 min)

```bash
# Reemplaza participant-1 con tu prefijo
aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`AuroraEndpoint`].OutputValue' \
  --output text
```

**‚úÖ Guarda este endpoint**, lo usar√°s para consultas.

---

#### Paso 2: Ver informes existentes (2 min)

```bash
# Obtener ARN del cluster y secret
CLUSTER_ARN=$(aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`ClusterArn`].OutputValue' \
  --output text)

SECRET_ARN=$(aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`SecretArn`].OutputValue' \
  --output text)

# Ver informes en la base de datos
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database medical_reports \
  --sql "SELECT id, trabajador_id, tipo_examen, presion_arterial, peso FROM informes_medicos LIMIT 5"
```

Observa que estos son informes reales que necesitan ser clasificados y enviados a clientes.

---

### Parte 2: Clasificar un Informe Autom√°ticamente (10 min)

Ahora vamos a usar Bedrock para clasificar autom√°ticamente el nivel de riesgo.

#### Paso 1: Invocar Lambda de Clasificaci√≥n (2 min)

```bash
# Clasificar el informe ID 1
aws lambda invoke \
  --function-name participant-1-classify-risk \
  --payload '{"informe_id": 1}' \
  response.json

# Ver resultado
cat response.json
```

**‚úÖ Deber√≠as ver:**
```json
{
  "informe_id": 1,
  "nivel_riesgo": "ALTO",
  "justificacion": "Presi√≥n arterial 165/102 mmHg indica hipertensi√≥n severa...",
  "tiempo_procesamiento": "2.3s"
}
```

---

#### Paso 2: Ver logs en tiempo real (3 min)

```bash
# Ver logs de la Lambda
aws logs tail /aws/lambda/participant-1-classify-risk --follow
```

Busca en los logs:
- `Invoking Bedrock with inference profile` ‚Üí Llamada a Bedrock
- `Few-shot examples loaded` ‚Üí Ejemplos de entrenamiento
- `RAG context retrieved` ‚Üí Informes anteriores del trabajador
- `Classification result` ‚Üí Resultado final

**Presiona Ctrl+C para salir**

---

#### Paso 3: Verificar resultado en Aurora (2 min)

```bash
# Ver el informe clasificado
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database medical_reports \
  --sql "SELECT id, nivel_riesgo, justificacion_riesgo FROM informes_medicos WHERE id = 1"
```

**‚úÖ El informe ahora tiene:**
- `nivel_riesgo`: BAJO, MEDIO o ALTO
- `justificacion_riesgo`: Explicaci√≥n detallada

---

### Parte 3: Entender C√≥mo Funciona (10 min)

El instructor explicar√° el c√≥digo mientras t√∫ sigues en tu pantalla.

#### Paso 1: Ver el Prompt de Clasificaci√≥n (3 min)

```bash
# Abrir el prompt en CloudShell
cat prompts/classification.txt
```

**Observa la estructura:**

```
Eres un m√©dico ocupacional experto...

Clasifica en uno de estos niveles:
- BAJO: Par√°metros normales, apto sin restricciones
- MEDIO: Par√°metros lim√≠trofes, requiere seguimiento  
- ALTO: Par√°metros alterados, requiere atenci√≥n inmediata

EJEMPLOS (Few-Shot Learning):

[Ejemplo BAJO con datos espec√≠ficos]
Presi√≥n: 118/75, IMC: 23.5, sin antecedentes
‚Üí BAJO

[Ejemplo MEDIO con datos espec√≠ficos]
Presi√≥n: 135/85, IMC: 27.2, colesterol elevado
‚Üí MEDIO

[Ejemplo ALTO con datos espec√≠ficos]
Presi√≥n: 155/95, IMC: 32.1, diabetes tipo 2
‚Üí ALTO

CONTEXTO HIST√ìRICO (RAG):
[Informes anteriores del trabajador]

INFORME ACTUAL:
[Datos del informe a clasificar]
```

**Lecci√≥n clave:** Few-shot learning + contexto hist√≥rico = clasificaci√≥n precisa

---

#### Paso 2: Ver el C√≥digo de la Lambda (4 min)

```bash
# Ver c√≥digo de clasificaci√≥n
cat lambda/ai/classify_risk/index.py
```

Busca estas secciones:

**1. Buscar contexto hist√≥rico (RAG):**
```python
# Buscar informes anteriores del mismo trabajador
informes_anteriores = buscar_informes_similares(trabajador_id)
```

**2. Construir prompt con ejemplos:**
```python
# Cargar ejemplos de few-shot learning
prompt = load_classification_prompt()
prompt += f"\nCONTEXTO HIST√ìRICO:\n{informes_anteriores}"
prompt += f"\nINFORME ACTUAL:\n{datos_informe}"
```

**3. Invocar Bedrock:**
```python
response = bedrock_runtime.invoke_model(
    modelId='us.amazon.nova-pro-v1:0',
    body=json.dumps({
        "messages": [{"role": "user", "content": prompt}],
        "inferenceConfig": {
            "temperature": 0.1,  # Baja para precisi√≥n
            "maxTokens": 1000
        }
    })
)
```

**Lecci√≥n clave:** Temperature baja (0.1) = respuestas consistentes y precisas

---

### Parte 4: Usar la App Web (5 min)

Ahora vamos a usar la interfaz visual.

#### Paso 1: Abrir tu App Web (1 min)

El instructor te proporcion√≥ la URL de tu app web. √Åbrela en tu navegador.

**Deber√≠as ver:**
- Lista de 10 informes m√©dicos
- Detalles de cada informe (presi√≥n arterial, IMC, etc.)
- Bot√≥n "Clasificar con IA" en cada informe
- Bot√≥n "Generar Resumen" (deshabilitado hasta clasificar)

---

#### Paso 2: Clasificar desde la App Web (2 min)

1. **Selecciona un informe** que NO est√© clasificado (sin badge de riesgo)
2. **Haz clic en "Clasificar con IA"**
3. **Observa:**
   - El bot√≥n muestra "Clasificando..."
   - Despu√©s de 2-3 segundos, aparece el badge de riesgo (BAJO/MEDIO/ALTO)
   - Se muestra la justificaci√≥n detallada

Detr√°s de escena, la app web est√° llamando a tu Lambda classify-risk a trav√©s de API Gateway.

---

#### Paso 3: Comparar CLI vs App Web (2 min)

**Ventajas de la App Web:**
- ‚úÖ Visual e intuitiva
- ‚úÖ No necesitas recordar comandos
- ‚úÖ Ves todos los informes de un vistazo
- ‚úÖ Feedback inmediato con badges de color

**Ventajas del CLI:**
- ‚úÖ Automatizaci√≥n y scripting
- ‚úÖ Integraci√≥n con otros sistemas
- ‚úÖ Acceso a logs detallados

**Lecci√≥n:** Ambas interfaces son √∫tiles seg√∫n el caso de uso.

---

### Parte 5: Ejercicio Individual (5 min)

**Tu tarea:** Clasificar 2-3 informes m√°s usando la app web

1. **Clasifica al menos 2 informes** usando el bot√≥n "Clasificar con IA"
2. **Observa los diferentes niveles de riesgo** (BAJO/MEDIO/ALTO)
3. **Lee las justificaciones** para entender por qu√© se clasific√≥ as√≠

**‚úÖ Criterio de √©xito:**
- Tienes al menos 3 informes clasificados
- Entiendes la diferencia entre BAJO, MEDIO y ALTO
- Los resultados tienen sentido m√©dicamente

**‚ùå Si algo falla:**
- Refresca la p√°gina
- Verifica que el despliegue se complet√≥ correctamente
- Revisa los logs en CloudShell: `aws logs tail /aws/lambda/participant-1-classify-risk`
- Pide ayuda al instructor

---

### üéì Resumen del M√≥dulo 1

**Lo que lograste:**
- ‚úÖ Viste datos reales del sistema legacy
- ‚úÖ Clasificaste informes autom√°ticamente con Bedrock
- ‚úÖ Entendiste few-shot learning y RAG
- ‚úÖ Verificaste resultados en la base de datos

**Valor de negocio:**
- Tiempo: De 10-15 min ‚Üí 30 segundos por informe
- Ahorro: 120+ horas/mes de trabajo m√©dico
- Consistencia: 100% en criterios de clasificaci√≥n
- Priorizaci√≥n: Identificaci√≥n inmediata de casos cr√≠ticos

**Concepto clave:** 
> Few-shot learning + RAG = Clasificaci√≥n precisa sin entrenar un modelo custom

**Pr√≥ximo m√≥dulo:** Generar res√∫menes ejecutivos autom√°ticamente

---

### M√≥dulo 2: Generaci√≥n de Res√∫menes Ejecutivos (30 min)

**Objetivo:** Automatizar la creaci√≥n de res√∫menes ejecutivos para gerentes de empresas clientes.

#### üéØ El Problema

**Situaci√≥n Actual:**
- Los gerentes de empresas clientes NO leen informes m√©dicos completos (5-10 p√°ginas)
- Necesitan res√∫menes ejecutivos de 2-3 p√°rrafos que destaquen:
  - Hallazgos principales
  - Nivel de riesgo
  - Acciones recomendadas
  - Tendencias vs. ex√°menes anteriores
- Crear estos res√∫menes manualmente toma 5-10 minutos por informe
- Con 500 informes/mes = 50+ horas de trabajo

**La Soluci√≥n con IA:**
- Amazon Bedrock genera res√∫menes autom√°ticamente
- Incluye contexto hist√≥rico usando RAG
- Lenguaje claro y no t√©cnico
- Tiempo reducido a 15 segundos por resumen

**Conceptos Clave:**
```
Temperature Media (0.5) = Balance entre precisi√≥n y fluidez
maxTokens = Controla la longitud del resumen
RAG = Agrega tendencias de ex√°menes anteriores
```

**Flujo de Generaci√≥n de Resumen:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Informe     ‚îÇ
‚îÇ Clasificado ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Verificar Clasificaci√≥n             ‚îÇ
‚îÇ    ‚Ä¢ Debe tener nivel_riesgo            ‚îÇ
‚îÇ    ‚Ä¢ Si no, retornar error              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Buscar Informes Anteriores (RAG)    ‚îÇ
‚îÇ    ‚Ä¢ Query SQL: √∫ltimos 2 informes      ‚îÇ
‚îÇ    ‚Ä¢ Mismo trabajador                   ‚îÇ
‚îÇ    ‚Ä¢ Para detectar tendencias           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Construir Prompt para Resumen       ‚îÇ
‚îÇ    ‚Ä¢ Cargar template summary.txt        ‚îÇ
‚îÇ    ‚Ä¢ Agregar contexto hist√≥rico         ‚îÇ
‚îÇ    ‚Ä¢ Agregar datos + nivel de riesgo    ‚îÇ
‚îÇ    ‚Ä¢ Especificar audiencia (gerente)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Invocar Bedrock Nova Pro            ‚îÇ
‚îÇ    ‚Ä¢ Temperature: 0.5 (balance)         ‚îÇ
‚îÇ    ‚Ä¢ MaxTokens: 300 (~150 palabras)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. Contar Palabras y Validar           ‚îÇ
‚îÇ    ‚Ä¢ Verificar longitud (80-180 palabras)‚îÇ
‚îÇ    ‚Ä¢ Formatear respuesta                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. Guardar en Aurora                   ‚îÇ
‚îÇ    ‚Ä¢ UPDATE informes_medicos            ‚îÇ
‚îÇ    ‚Ä¢ SET resumen_ejecutivo              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Parte 1: Generar un Resumen Autom√°ticamente (10 min)

Vamos a generar un resumen ejecutivo del informe que clasificamos en el M√≥dulo 1.

#### Paso 1: Invocar Lambda de Resumen (2 min)

```bash
# Generar resumen del informe ID 1
aws lambda invoke \
  --function-name participant-1-generate-summary \
  --payload '{"informe_id": 1}' \
  summary_response.json

# Ver resultado
cat summary_response.json
```

**‚úÖ Deber√≠as ver:**
```json
{
  "informe_id": 1,
  "resumen": "El trabajador Carlos Rodr√≠guez presenta m√∫ltiples factores de riesgo que requieren atenci√≥n m√©dica inmediata. Se detecta hipertensi√≥n arterial severa (165/102 mmHg) y obesidad grado I (IMC: 32.9). Los ex√°menes de laboratorio revelan diabetes mellitus descompensada. Comparado con su examen anterior hace 6 meses, se observa deterioro significativo en todos los par√°metros. Se recomienda restricci√≥n inmediata de actividades de alto riesgo y evaluaci√≥n m√©dica urgente.",
  "palabras": 87,
  "tiempo_procesamiento": "1.8s"
}
```

---

#### Paso 2: Ver logs en tiempo real (3 min)

```bash
# Ver logs de la Lambda
aws logs tail /aws/lambda/participant-1-generate-summary --follow
```

Busca en los logs:
- `Loading summary prompt` ‚Üí Carga del prompt
- `RAG: Retrieved 2 previous reports` ‚Üí Informes anteriores encontrados
- `Invoking Bedrock with temperature 0.5` ‚Üí Llamada a Bedrock
- `Summary generated: 87 words` ‚Üí Resumen creado

**Presiona Ctrl+C para salir**

---

#### Paso 3: Verificar resultado en Aurora (2 min)

```bash
# Ver el resumen guardado
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database medical_reports \
  --sql "SELECT id, resumen_ejecutivo FROM informes_medicos WHERE id = 1"
```

**‚úÖ El informe ahora tiene un resumen ejecutivo listo para enviar al cliente**

---

### Parte 2: Entender el Prompt de Resumen (8 min)

**El instructor explicar√° mientras t√∫ sigues en tu pantalla**

#### Paso 1: Ver el Prompt (3 min)

```bash
# Abrir el prompt de resumen
cat prompts/summary.txt
```

**Observa la estructura:**

```
Genera un resumen ejecutivo del informe m√©dico.

AUDIENCIA: Gerente de empresa (no m√©dico)

REQUISITOS:
- M√°ximo 150 palabras
- Lenguaje claro, NO t√©cnico
- Enf√≥cate en hallazgos principales y acciones
- Incluye tendencias si hay informes anteriores

CONTEXTO HIST√ìRICO (RAG):
[Informes anteriores del trabajador - si existen]

INFORME ACTUAL:
[Datos del informe]
[Nivel de riesgo: ALTO]

FORMATO:
2-3 p√°rrafos, directo y accionable.
```

**Lecci√≥n clave:** El prompt especifica la audiencia (gerente, no m√©dico) para ajustar el lenguaje

---

#### Paso 2: Comparar con Clasificaci√≥n (2 min)

**Diferencias clave entre Clasificaci√≥n y Resumen:**

| Aspecto | Clasificaci√≥n | Resumen |
|---------|---------------|---------|
| **Temperature** | 0.1 (preciso) | 0.5 (balanceado) |
| **maxTokens** | 1000 | 300 |
| **Objetivo** | Decisi√≥n binaria | Comunicaci√≥n fluida |
| **Audiencia** | Sistema | Humano (gerente) |

**Lecci√≥n:** Ajustamos par√°metros seg√∫n el caso de uso

---

#### Paso 3: Ver el C√≥digo (3 min)

```bash
# Ver c√≥digo de generaci√≥n de resumen
cat lambda/ai/generate_summary/index.py
```

**Busca estas secciones:**

**1. Buscar contexto hist√≥rico:**
```python
# Buscar informes anteriores para tendencias
informes_anteriores = buscar_informes_similares(trabajador_id, limit=2)
```

**2. Construir prompt con contexto:**
```python
prompt = load_summary_prompt()
if informes_anteriores:
    prompt += f"\nCONTEXTO HIST√ìRICO:\n{format_historical_context(informes_anteriores)}"
prompt += f"\nINFORME ACTUAL:\n{datos_informe}"
prompt += f"\nNivel de riesgo: {nivel_riesgo}"
```

**3. Invocar Bedrock con temperature media:**
```python
response = bedrock_runtime.invoke_model(
    modelId='us.amazon.nova-pro-v1:0',
    body=json.dumps({
        "messages": [{"role": "user", "content": prompt}],
        "inferenceConfig": {
            "temperature": 0.5,  # Balance entre precisi√≥n y fluidez
            "maxTokens": 300     # Limita longitud del resumen
        }
    })
)
```

---

### Parte 3: Entender los Par√°metros de Bedrock (7 min)

El instructor explicar√° los par√°metros clave de Bedrock.

#### Par√°metro 1: Temperature (3 min)

**¬øQu√© es temperature?**
- Controla la "creatividad" o "aleatoriedad" del modelo
- Rango: 0.0 (determin√≠stico) a 1.0 (muy creativo)

**Ejemplos de uso:**

| Temperature | Caso de Uso | Resultado |
|-------------|-------------|-----------|
| **0.1** | Clasificaci√≥n de riesgo | Preciso, consistente, mismo input ‚Üí mismo output |
| **0.5** | Res√∫menes ejecutivos | Balanceado: preciso pero con fluidez natural |
| **0.7** | Emails personalizados | M√°s variado, tono m√°s natural |
| **0.9** | Brainstorming | Muy creativo, respuestas diversas |

**Lecci√≥n:** Usamos temperature 0.1 para clasificaci√≥n (precisi√≥n) y 0.5 para res√∫menes (balance).

---

#### Par√°metro 2: maxTokens (2 min)

**¬øQu√© es maxTokens?**
- Limita la longitud m√°xima de la respuesta
- 1 token ‚âà 0.75 palabras en espa√±ol
- 300 tokens ‚âà 225 palabras

**Ejemplos de uso:**

| maxTokens | Caso de Uso | Resultado |
|-----------|-------------|-----------|
| **1000** | Clasificaci√≥n con justificaci√≥n | Permite explicaci√≥n detallada |
| **300** | Resumen ejecutivo | Fuerza concisi√≥n (~150 palabras) |
| **500** | Email personalizado | Suficiente para email completo |

**Lecci√≥n:** maxTokens no solo limita, tambi√©n gu√≠a al modelo a ser m√°s conciso.

---

#### Par√°metro 3: Prompt Engineering (2 min)

**¬øQu√© hace un buen prompt?**
- ‚úÖ **Contexto claro:** "Eres un m√©dico ocupacional experto..."
- ‚úÖ **Ejemplos (few-shot):** Muestra 2-3 ejemplos del resultado esperado
- ‚úÖ **Formato espec√≠fico:** "Responde en formato JSON: {...}"
- **Restricciones:** "M√°ximo 150 palabras", "Lenguaje no t√©cnico"

**Lecci√≥n:** Un prompt bien dise√±ado es m√°s importante que ajustar par√°metros.

---

### Parte 3.5: Experimentar con Par√°metros (Opcional - 5 min)

Si tienes tiempo, experimenta con diferentes par√°metros.

#### Experimento 1: Temperature Baja (0.2)

```bash
# Generar resumen con temperature baja (m√°s determin√≠stico)
aws lambda invoke \
  --function-name participant-1-generate-summary \
  --payload '{"informe_id": 1, "temperature": 0.2}' \
  summary_temp_low.json

# Ver resultado
cat summary_temp_low.json
```

Observa si el resumen es m√°s t√©cnico o m√°s formal.

---

#### Experimento 2: Temperature Alta (0.8)

```bash
# Generar resumen con temperature alta (m√°s creativo)
aws lambda invoke \
  --function-name participant-1-generate-summary \
  --payload '{"informe_id": 1, "temperature": 0.8}' \
  summary_temp_high.json

# Ver resultado
cat summary_temp_high.json
```

Observa si el resumen es m√°s variado o usa lenguaje m√°s natural.

---

#### Experimento 3: maxTokens Reducido (150)

```bash
# Generar resumen m√°s corto
aws lambda invoke \
  --function-name participant-1-generate-summary \
  --payload '{"informe_id": 1, "maxTokens": 150}' \
  summary_short.json

# Ver resultado
cat summary_short.json
```

Observa si el resumen mantiene la informaci√≥n clave o pierde detalles.

---

**Lecci√≥n:** Los par√°metros por defecto (temperature: 0.5, maxTokens: 300) est√°n optimizados para este caso de uso. Experimentar ayuda a entender su impacto.

---

### Parte 4: Usar la App Web para Res√∫menes (5 min)

Ahora vamos a generar res√∫menes desde la interfaz visual.

#### Paso 1: Generar Resumen desde la App Web (2 min)

1. **Abre tu App Web** (si la cerraste)
2. **Selecciona un informe clasificado** (con badge de riesgo)
3. **Haz clic en "Generar Resumen"**
4. **Observa:**
   - El bot√≥n muestra "Generando..."
   - Despu√©s de 1-2 segundos, aparece el resumen ejecutivo
   - Se muestra el conteo de palabras

**Nota:** Solo puedes generar res√∫menes de informes ya clasificados.

---

#### Paso 2: Analizar el Resumen (2 min)

**Lee el resumen generado y verifica:**
- ‚úÖ Lenguaje claro y no t√©cnico (para gerentes, no m√©dicos)
- ‚úÖ Menciona el nivel de riesgo
- ‚úÖ Incluye hallazgos principales
- ‚úÖ Sugiere acciones recomendadas
- ‚úÖ Longitud: ~100-150 palabras

Si hay informes anteriores del mismo trabajador, el resumen incluir√° tendencias hist√≥ricas (ej: "Comparado con su examen anterior hace 6 meses...").

---

#### Paso 3: Ejercicio Individual (1 min)

**Tu tarea:** Generar res√∫menes de 2-3 informes m√°s

1. **Genera res√∫menes** de los informes que clasificaste
2. **Compara res√∫menes** de diferentes niveles de riesgo
3. **Observa el tono:** ¬øEs m√°s urgente para ALTO riesgo?

**‚úÖ Criterio de √©xito:**
- Tienes al menos 3 res√∫menes generados
- Los res√∫menes son claros y accionables
- Entiendes c√≥mo el nivel de riesgo afecta el contenido

---

### üéì Resumen del M√≥dulo 2

**Lo que lograste:**
- ‚úÖ Generaste res√∫menes ejecutivos autom√°ticamente
- ‚úÖ Entendiste c√≥mo ajustar temperature y maxTokens
- ‚úÖ Viste c√≥mo RAG agrega contexto hist√≥rico
- ‚úÖ Experimentaste con diferentes par√°metros

**Valor de negocio:**
- Tiempo: De 5-10 min ‚Üí 15 segundos por resumen
- Ahorro: 50+ horas/mes
- Calidad: Consistente y profesional
- Tendencias: Incluye comparaci√≥n con ex√°menes anteriores

**Concepto clave:** 
> Temperature media + maxTokens limitado = Res√∫menes concisos y fluidos

**Pr√≥ximo:** Checkpoint del D√≠a 1 y c√°lculo de ROI

---

### üéØ Checkpoint D√≠a 1 y C√°lculo de ROI (10 min)

#### Verificar que Todo Funciona (3 min)

**Abre tu App Web y verifica:**

1. **Informes clasificados:**
   - ‚úÖ Al menos 3 informes con badges de riesgo (BAJO/MEDIO/ALTO)
   - ‚úÖ Cada uno tiene justificaci√≥n detallada

2. **Res√∫menes generados:**
   - ‚úÖ Al menos 3 informes con res√∫menes ejecutivos
   - ‚úÖ Res√∫menes de ~100-150 palabras
   - ‚úÖ Lenguaje claro y no t√©cnico

3. **Estad√≠sticas en la app:**
   - ‚úÖ Contador de informes clasificados
   - ‚úÖ Distribuci√≥n de niveles de riesgo
   - ‚úÖ Tiempo promedio de procesamiento

**üí° Si algo falta:** Clasifica y genera res√∫menes de m√°s informes hasta tener al menos 3 completos.

---

#### Calcular el ROI (5 min)

**üëâ El instructor mostrar√° estos c√°lculos en pantalla compartida**

**Proceso Manual (ANTES):**
```
Por cada informe:
- Revisi√≥n m√©dica y clasificaci√≥n: 10-15 min
- Creaci√≥n de resumen ejecutivo: 5-10 min
- Total: 15-25 min por informe

Con 500 informes/mes:
- Tiempo total: 125-208 horas/mes
- Costo (asumiendo $50/hora m√©dico): $6,250-10,400/mes
```

**Proceso Automatizado (AHORA):**
```
Por cada informe:
- Clasificaci√≥n autom√°tica: 30 segundos
- Generaci√≥n de resumen: 15 segundos
- Revisi√≥n m√©dica (solo casos ALTO): 5 min
- Total: ~1 min por informe (+ 5 min para casos cr√≠ticos)

Con 500 informes/mes (asumiendo 20% ALTO riesgo):
- Tiempo total: 8 horas clasificaci√≥n + 8 horas revisi√≥n = 16 horas/mes
- Costo: $800/mes
- Ahorro: $5,450-9,600/mes (87-92% reducci√≥n)
```

**Beneficios Adicionales:**
- ‚úÖ Identificaci√≥n inmediata de casos cr√≠ticos
- ‚úÖ Consistencia 100% en criterios
- ‚úÖ Res√∫menes profesionales y estandarizados
- ‚úÖ Tendencias hist√≥ricas autom√°ticas

---

#### Preguntas para Reflexionar (2 min)

**T√©cnicas:**
- ¬øPor qu√© usamos temperature 0.1 para clasificaci√≥n y 0.5 para res√∫menes?
- ¬øC√≥mo ayuda RAG a mejorar la precisi√≥n?
- ¬øQu√© hace que un prompt sea efectivo?

**De Negocio:**
- ¬øQu√© otros procesos en tu organizaci√≥n podr√≠an automatizarse con este patr√≥n?
- ¬øC√≥mo medir√≠as el √©xito de esta automatizaci√≥n?
- ¬øQu√© riesgos ves en automatizar decisiones m√©dicas?

---

### üéâ ¬°Felicitaciones!

Has completado el D√≠a 1 del workshop. Ahora sabes c√≥mo:
- ‚úÖ Clasificar informes autom√°ticamente con few-shot learning
- ‚úÖ Generar res√∫menes ejecutivos con IA
- ‚úÖ Ajustar par√°metros (temperature, maxTokens) seg√∫n el caso de uso
- ‚úÖ Usar RAG para agregar contexto hist√≥rico
- ‚úÖ Calcular el ROI de automatizaci√≥n con IA

**Ma√±ana (D√≠a 2):** Aprender√°s a personalizar emails seg√∫n el nivel de riesgo, profundizar en RAG, e integrar PDFs externos.

---

## üìñ Conceptos Clave del D√≠a 1

Esta secci√≥n resume los conceptos t√©cnicos m√°s importantes que aprendiste hoy, con ejemplos concretos del workshop.

### 1. Few-Shot Learning

**¬øQu√© es?**
Few-shot learning es una t√©cnica donde ense√±as al modelo de IA con solo unos pocos ejemplos (t√≠picamente 2-5) en lugar de entrenar un modelo completo con miles de datos.

**C√≥mo lo usamos en el workshop:**
En el prompt de clasificaci√≥n, incluimos 3 ejemplos:
- 1 ejemplo de riesgo BAJO (presi√≥n 118/75, IMC 23.5)
- 1 ejemplo de riesgo MEDIO (presi√≥n 135/85, IMC 27.2)
- 1 ejemplo de riesgo ALTO (presi√≥n 155/95, IMC 32.1)

**Ventajas:**
- ‚úÖ No requiere entrenar un modelo custom (ahorra tiempo y dinero)
- ‚úÖ F√°cil de actualizar (solo editas el prompt)
- ‚úÖ Resultados inmediatos sin necesidad de datos hist√≥ricos masivos

**Ejemplo del workshop:**
```
EJEMPLOS:

Ejemplo BAJO:
Presi√≥n: 118/75, IMC: 23.5, sin antecedentes
‚Üí BAJO

Ejemplo MEDIO:
Presi√≥n: 135/85, IMC: 27.2, colesterol elevado
‚Üí MEDIO

Ejemplo ALTO:
Presi√≥n: 155/95, IMC: 32.1, diabetes tipo 2
‚Üí ALTO

Ahora clasifica este informe:
[datos del informe actual]
```

---

### 2. RAG (Retrieval-Augmented Generation)

**¬øQu√© es?**
RAG es una t√©cnica que combina b√∫squeda de informaci√≥n (Retrieval) con generaci√≥n de texto (Generation). Primero busca informaci√≥n relevante, luego la agrega al prompt para que el modelo genere una respuesta m√°s precisa.

**C√≥mo lo usamos en el workshop:**
Antes de clasificar o generar un resumen, buscamos los √∫ltimos 2-3 informes del mismo trabajador usando SQL:

```sql
SELECT * FROM informes_medicos 
WHERE trabajador_id = :id 
ORDER BY fecha_examen DESC 
LIMIT 3
```

Luego agregamos esa informaci√≥n al prompt como "contexto hist√≥rico".

**Ventajas:**
- ‚úÖ Reduce alucinaciones (el modelo no inventa datos)
- ‚úÖ Proporciona contexto espec√≠fico del trabajador
- ‚úÖ Permite detectar tendencias (ej: "deterioro en los √∫ltimos 6 meses")

**Ejemplo del workshop:**
```
CONTEXTO HIST√ìRICO:
- 2024-06-15: Presi√≥n 140/88, IMC 28.5, Riesgo: MEDIO
- 2024-03-10: Presi√≥n 135/85, IMC 27.2, Riesgo: MEDIO

INFORME ACTUAL:
- 2024-12-02: Presi√≥n 165/102, IMC 32.9
‚Üí Se observa deterioro progresivo ‚Üí ALTO
```

**Diferencia con b√∫squeda vectorial (D√≠a 2):**
- D√≠a 1: RAG simple con SQL (busca por `trabajador_id`)
- D√≠a 2: RAG avanzado con embeddings (busca por similitud sem√°ntica)

---

### 3. Temperature

**¬øQu√© es?**
Temperature controla la "creatividad" o "aleatoriedad" del modelo. Es un n√∫mero entre 0.0 y 1.0.

**Escala de Temperature:**
```
0.0 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0.5 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1.0
Determin√≠stico  Balanceado    Muy creativo
Preciso         Natural       Variado
```

**C√≥mo lo usamos en el workshop:**

| Caso de Uso | Temperature | Por qu√© |
|-------------|-------------|---------|
| **Clasificaci√≥n** | 0.1 | Necesitamos precisi√≥n y consistencia. Mismo informe ‚Üí mismo resultado |
| **Res√∫menes** | 0.5 | Balance entre precisi√≥n y fluidez natural del lenguaje |
| **Emails (D√≠a 2)** | 0.7 | M√°s variedad y tono natural para comunicaci√≥n humana |

**Ejemplo pr√°ctico:**

**Temperature 0.1 (Clasificaci√≥n):**
- Input: "Presi√≥n 165/102, IMC 32.9, diabetes"
- Output 1: "ALTO - Hipertensi√≥n severa requiere atenci√≥n inmediata"
- Output 2: "ALTO - Hipertensi√≥n severa requiere atenci√≥n inmediata"
- Output 3: "ALTO - Hipertensi√≥n severa requiere atenci√≥n inmediata"
- ‚úÖ Siempre el mismo resultado (consistencia)

**Temperature 0.5 (Resumen):**
- Input: Mismo informe
- Output 1: "El trabajador presenta hipertensi√≥n severa y obesidad..."
- Output 2: "Se detecta presi√≥n arterial elevada y sobrepeso significativo..."
- Output 3: "Los par√°metros indican hipertensi√≥n grado 2 y obesidad..."
- ‚úÖ Variaciones naturales pero mantiene el mensaje

**Temperature 0.9 (Muy creativo - NO recomendado para este caso):**
- Output: "¬°Alerta! Este trabajador necesita cambios urgentes en su estilo de vida..."
- ‚ùå Demasiado variado, puede perder precisi√≥n m√©dica

---

### 4. maxTokens

**¬øQu√© es?**
maxTokens limita la longitud m√°xima de la respuesta del modelo. Un token es aproximadamente 0.75 palabras en espa√±ol.

**Conversi√≥n aproximada:**
```
100 tokens  ‚âà  75 palabras  ‚âà  1 p√°rrafo corto
300 tokens  ‚âà 225 palabras  ‚âà  2-3 p√°rrafos
1000 tokens ‚âà 750 palabras  ‚âà  1 p√°gina
```

**C√≥mo lo usamos en el workshop:**

| Caso de Uso | maxTokens | Resultado Esperado |
|-------------|-----------|-------------------|
| **Clasificaci√≥n** | 1000 | Permite justificaci√≥n detallada (~500 palabras) |
| **Res√∫menes** | 300 | Fuerza concisi√≥n (~150 palabras) |
| **Emails (D√≠a 2)** | 500 | Email completo pero no excesivo (~350 palabras) |

**Funci√≥n dual de maxTokens:**
1. **Limitar:** Evita respuestas demasiado largas
2. **Guiar:** El modelo ajusta su estilo para cumplir el l√≠mite

**Ejemplo pr√°ctico:**

**maxTokens 1000 (Clasificaci√≥n):**
```
Resultado: "ALTO - El trabajador presenta hipertensi√≥n arterial severa 
(165/102 mmHg) que supera significativamente los valores normales 
(120/80 mmHg). Adem√°s, se observa obesidad grado I (IMC 32.9) y 
diabetes mellitus descompensada. Estos factores combinados representan 
un riesgo cardiovascular elevado que requiere intervenci√≥n m√©dica 
inmediata. Se recomienda restricci√≥n de actividades de alto riesgo 
f√≠sico y evaluaci√≥n cardiol√≥gica urgente..."
```
‚úÖ Justificaci√≥n completa y detallada

**maxTokens 300 (Resumen):**
```
Resultado: "El trabajador presenta m√∫ltiples factores de riesgo que 
requieren atenci√≥n inmediata. Se detecta hipertensi√≥n severa y obesidad. 
Comparado con su examen anterior, se observa deterioro significativo. 
Se recomienda restricci√≥n de actividades de riesgo y evaluaci√≥n m√©dica 
urgente."
```
‚úÖ Conciso pero completo (~80 palabras)

**maxTokens 50 (Demasiado corto - NO recomendado):**
```
Resultado: "Hipertensi√≥n severa y obesidad. Requiere atenci√≥n m√©dica."
```
‚ùå Pierde informaci√≥n importante

---

### 5. Prompt Engineering

**¬øQu√© es?**
Prompt engineering es el arte de dise√±ar instrucciones efectivas para modelos de IA. Un buen prompt es claro, espec√≠fico y proporciona contexto.

**Anatom√≠a de un buen prompt (del workshop):**

```
1. CONTEXTO/ROL
   "Eres un m√©dico ocupacional experto en evaluar riesgos laborales."
   ‚Üí Define qui√©n es el modelo

2. TAREA
   "Clasifica el siguiente informe en uno de estos niveles: BAJO, MEDIO, ALTO"
   ‚Üí Define qu√© debe hacer

3. CRITERIOS
   "- BAJO: Par√°metros normales, apto sin restricciones
    - MEDIO: Par√°metros lim√≠trofes, requiere seguimiento
    - ALTO: Par√°metros alterados, requiere atenci√≥n inmediata"
   ‚Üí Define c√≥mo evaluar

4. EJEMPLOS (Few-Shot)
   [3 ejemplos concretos con datos y resultados]
   ‚Üí Muestra el formato esperado

5. CONTEXTO ADICIONAL (RAG)
   "CONTEXTO HIST√ìRICO: [informes anteriores]"
   ‚Üí Proporciona informaci√≥n relevante

6. INPUT
   "INFORME ACTUAL: [datos del informe]"
   ‚Üí Los datos a procesar

7. FORMATO DE SALIDA
   "Responde en formato JSON: {nivel_riesgo: ..., justificacion: ...}"
   ‚Üí Define el formato de respuesta
```

**Mejores pr√°cticas del workshop:**
- ‚úÖ Especifica la audiencia ("para gerentes, no m√©dicos")
- ‚úÖ Usa restricciones claras ("m√°ximo 150 palabras")
- ‚úÖ Proporciona ejemplos concretos (few-shot learning)
- ‚úÖ Incluye contexto relevante (RAG)
- ‚úÖ Define el formato de salida (JSON, p√°rrafos, etc.)

---

### 6. Comparaci√≥n: Clasificaci√≥n vs Resumen

**Tabla comparativa de configuraciones:**

| Aspecto | Clasificaci√≥n | Resumen |
|---------|---------------|---------|
| **Objetivo** | Decisi√≥n categ√≥rica (BAJO/MEDIO/ALTO) | Comunicaci√≥n fluida |
| **Audiencia** | Sistema/M√©dico | Gerente (no m√©dico) |
| **Temperature** | 0.1 (precisi√≥n) | 0.5 (balance) |
| **maxTokens** | 1000 (justificaci√≥n detallada) | 300 (concisi√≥n) |
| **Prompt** | Criterios t√©cnicos + ejemplos | Lenguaje claro + restricciones |
| **RAG** | √öltimos 3 informes | √öltimos 2 informes |
| **Salida** | JSON estructurado | Texto en p√°rrafos |
| **Tiempo** | ~30 segundos | ~15 segundos |

**Lecci√≥n clave:** No hay una configuraci√≥n "correcta" universal. Los par√°metros se ajustan seg√∫n el caso de uso espec√≠fico.

---

### üéØ Aplicando estos conceptos

**Pregunta de reflexi√≥n:** Si tuvieras que crear un sistema para generar emails de seguimiento, ¬øqu√© par√°metros usar√≠as?

**Respuesta sugerida:**
- Temperature: 0.6-0.7 (m√°s natural que resumen, menos que brainstorming)
- maxTokens: 400-500 (email completo pero no excesivo)
- Few-shot: 2-3 ejemplos de emails por nivel de riesgo
- RAG: Incluir historial de comunicaciones previas
- Prompt: Especificar tono (urgente/profesional/tranquilizador)

**Ver√°s esto en acci√≥n en el D√≠a 2 del workshop!** üöÄ

---

## üìö D√≠a 2: Capacidades Avanzadas

**üìù Nota:** El contenido del D√≠a 2 ser√° actualizado pr√≥ximamente para reflejar el nuevo enfoque:
- M√≥dulo 3: Emails personalizados por nivel de riesgo
- M√≥dulo 4: RAG avanzado con embeddings vectoriales
- M√≥dulo 5: Integraci√≥n de PDFs externos (cl√≠nicas externas)
- Experimentaci√≥n libre

**Por ahora, el contenido a continuaci√≥n corresponde a la versi√≥n anterior del workshop.**

---

### M√≥dulo 3: RAG con Embeddings Vectoriales (30 min)

#### Objetivo
Implementar RAG (Retrieval-Augmented Generation) para proporcionar contexto hist√≥rico a las respuestas de IA.

#### ¬øQu√© es RAG?

**RAG** = Retrieval-Augmented Generation

1. **Retrieval**: Buscar informaci√≥n relevante en una base de datos
2. **Augmented**: Agregar esa informaci√≥n al prompt
3. **Generation**: Generar respuesta con contexto

**Beneficios:**
- ‚úÖ Reduce alucinaciones
- ‚úÖ Proporciona contexto espec√≠fico
- ‚úÖ Mejora precisi√≥n de respuestas

#### Paso 1: Desplegar Stack RAG

```bash
cd cdk
cdk deploy AIRAGStack
```

**Recursos creados:**
- Lambda para generar embeddings
- Permisos para Amazon Titan Embeddings

#### Paso 2: Entender Embeddings

Los **embeddings** son representaciones vectoriales de texto:

```python
# Texto original
"Presi√≥n arterial: 140/90 mmHg"

# Embedding (vector de 1024 dimensiones)
[0.123, -0.456, 0.789, ..., 0.234]
```

**Ventaja:** Textos similares tienen embeddings similares.

#### Paso 3: Generar Embeddings

```bash
# Generar embeddings para un informe
aws lambda invoke \
  --function-name generate-embeddings \
  --payload '{"informe_id": 1}' \
  response.json

# Ver resultado
cat response.json
```

#### Paso 4: Revisar C√≥digo de B√∫squeda

Abre [`lambda/shared/similarity_search.py`](lambda/shared/similarity_search.py):

```python
def buscar_informes_similares(trabajador_id, embedding_actual, limit=3):
    """
    Busca informes anteriores del mismo trabajador usando similitud coseno.
    """
    sql = """
        SELECT 
            ie.informe_id,
            ie.contenido,
            1 - (ie.embedding <=> %s::vector) as similarity
        FROM informes_embeddings ie
        WHERE ie.trabajador_id = %s
          AND ie.informe_id != %s
        ORDER BY ie.embedding <=> %s::vector
        LIMIT %s
    """
```

**Conceptos clave:**
- `<=>` es el operador de distancia coseno de pgvector
- Menor distancia = mayor similitud
- Filtramos por trabajador_id para contexto relevante

#### Paso 5: Probar B√∫squeda RAG

```bash
# Crear varios informes para el mismo trabajador
aws lambda invoke \
  --function-name generate-test-data \
  --payload '{"trabajador_id": 1, "cantidad": 3}' \
  response.json

# Generar embeddings para todos
for i in {1..3}; do
  aws lambda invoke \
    --function-name generate-embeddings \
    --payload "{\"informe_id\": $i}" \
    response.json
done

# Ahora la b√∫squeda RAG encontrar√° informes anteriores
```

---

### M√≥dulo 4: Clasificaci√≥n de Riesgo con Few-Shot Learning (30 min)

#### Objetivo
Clasificar informes m√©dicos en niveles de riesgo (BAJO, MEDIO, ALTO) usando few-shot learning.

#### ¬øQu√© es Few-Shot Learning?

**Few-shot learning** = Ense√±ar al modelo con pocos ejemplos en el prompt.

```
Clasifica el siguiente informe m√©dico en: BAJO, MEDIO o ALTO riesgo.

Ejemplos:

BAJO: Presi√≥n 118/75, IMC 23.5, sin antecedentes
MEDIO: Presi√≥n 135/85, IMC 27.2, colesterol elevado
ALTO: Presi√≥n 155/95, IMC 32.1, diabetes tipo 2

Ahora clasifica este informe:
[informe actual]
```

#### Paso 1: Desplegar Stack de Clasificaci√≥n

```bash
cd cdk
cdk deploy AIClassificationStack
```

#### Paso 2: Revisar Prompt de Clasificaci√≥n

Abre [`prompts/classification.txt`](prompts/classification.txt):

```
Eres un m√©dico ocupacional experto en evaluar riesgos laborales.

Clasifica el siguiente informe en uno de estos niveles:
- BAJO: Par√°metros normales, apto sin restricciones
- MEDIO: Par√°metros lim√≠trofes, requiere seguimiento
- ALTO: Par√°metros alterados, requiere atenci√≥n inmediata

EJEMPLOS:

[Ejemplo BAJO con datos espec√≠ficos]
[Ejemplo MEDIO con datos espec√≠ficos]
[Ejemplo ALTO con datos espec√≠ficos]

CONTEXTO HIST√ìRICO:
[Informes anteriores del trabajador - proporcionado por RAG]

INFORME ACTUAL:
[Datos del informe]

Responde en formato JSON:
{
  "nivel_riesgo": "BAJO|MEDIO|ALTO",
  "justificacion": "explicaci√≥n detallada"
}
```

**Nota:** El contexto hist√≥rico viene de RAG.

#### Paso 3: Clasificar un Informe

```bash
# Clasificar informe
aws lambda invoke \
  --function-name classify-risk \
  --payload '{"informe_id": 1}' \
  response.json

# Ver resultado
cat response.json
```

#### Paso 4: Verificar Clasificaci√≥n en Aurora

```bash
psql -h <aurora-endpoint> -U postgres -d medical_reports

SELECT 
  id,
  trabajador_nombre,
  nivel_riesgo,
  justificacion_riesgo
FROM informes_completos
WHERE id = 1;
```

#### Ejercicio: Comparar Versiones de Prompts

Revisa las 3 versiones del prompt de clasificaci√≥n:

**Versi√≥n 1** ([`prompts/classification_v1.txt`](prompts/classification_v1.txt)):
- Sin ejemplos
- Resultados inconsistentes

**Versi√≥n 2** ([`prompts/classification_v2.txt`](prompts/classification_v2.txt)):
- Con ejemplos b√°sicos
- Mejor, pero sin contexto hist√≥rico

**Versi√≥n 3** ([`prompts/classification.txt`](prompts/classification.txt)):
- Con ejemplos detallados
- Con contexto hist√≥rico (RAG)
- Resultados precisos y consistentes

**Lecci√≥n:** Few-shot learning + RAG = Clasificaci√≥n precisa

---

### M√≥dulo 5: Res√∫menes y Emails Personalizados (30 min)

#### Objetivo
Generar res√∫menes ejecutivos y emails personalizados seg√∫n el nivel de riesgo.

#### Paso 1: Desplegar Stacks de Resumen y Email

```bash
cd cdk
cdk deploy AISummaryStack
cdk deploy AIEmailStack
```

#### Paso 2: Generar Resumen Ejecutivo

```bash
# Generar resumen
aws lambda invoke \
  --function-name generate-summary \
  --payload '{"informe_id": 1}' \
  response.json

# Ver resultado
cat response.json
```

**Caracter√≠sticas del resumen:**
- M√°ximo 150 palabras
- Lenguaje claro y no t√©cnico
- Incluye tendencias hist√≥ricas (RAG)
- Enfocado en lo m√°s importante

#### Paso 3: Revisar Prompt de Resumen

Abre [`prompts/summary.txt`](prompts/summary.txt):

```
Genera un resumen ejecutivo del informe m√©dico.

REQUISITOS:
- M√°ximo 150 palabras
- Lenguaje claro, no t√©cnico
- Enf√≥cate en hallazgos principales
- Incluye tendencias si hay informes anteriores

CONTEXTO HIST√ìRICO:
[Informes anteriores - proporcionado por RAG]

INFORME ACTUAL:
[Datos del informe]

FORMATO:
P√°rrafo √∫nico, directo y accionable.
```

**Par√°metros:**
- `temperature: 0.5` (balanceado entre precisi√≥n y fluidez)
- `maxTokens: 300`

#### Paso 4: Enviar Email Personalizado

```bash
# Enviar email
aws lambda invoke \
  --function-name send-email \
  --payload '{"informe_id": 1}' \
  response.json
```

#### Paso 5: Revisar Prompts de Email

Hay 3 prompts diferentes seg√∫n el nivel de riesgo:

**Email Riesgo ALTO** ([`prompts/email_high.txt`](prompts/email_high.txt)):
```
Genera un email URGENTE para el contratista.

TONO: Urgente pero profesional
OBJETIVO: Acci√≥n inmediata

Incluye:
- Hallazgos cr√≠ticos
- Acciones requeridas INMEDIATAMENTE
- Consecuencias de no actuar
```

**Email Riesgo MEDIO** ([`prompts/email_medium.txt`](prompts/email_medium.txt)):
```
Genera un email PROFESIONAL para el contratista.

TONO: Profesional y constructivo
OBJETIVO: Seguimiento programado

Incluye:
- Hallazgos que requieren atenci√≥n
- Recomendaciones de seguimiento
- Plazo sugerido
```

**Email Riesgo BAJO** ([`prompts/email_low.txt`](prompts/email_low.txt)):
```
Genera un email TRANQUILIZADOR para el contratista.

TONO: Positivo y alentador
OBJETIVO: Confirmar estado saludable

Incluye:
- Confirmaci√≥n de par√°metros normales
- Felicitaci√≥n por mantener salud
- Recordatorio de controles peri√≥dicos
```

**Par√°metros:**
- `temperature: 0.7` (m√°s creativo para personalizaci√≥n)
- `maxTokens: 500`

#### Paso 6: Verificar Email Recibido

Revisa tu bandeja de entrada. Deber√≠as recibir un email personalizado seg√∫n el nivel de riesgo del informe.

---

### üé® Experimentaci√≥n Libre (30 min)

Ahora es tu turno de experimentar. Aqu√≠ hay algunas ideas:

#### Experimento 1: Modificar Tono de Emails

1. Abre [`prompts/email_high.txt`](prompts/email_high.txt)
2. Cambia "URGENTE" por "IMPORTANTE"
3. Re-despliega: `cdk deploy AIEmailStack`
4. Env√≠a otro email y compara

#### Experimento 2: Ajustar Longitud de Res√∫menes

1. Abre [`prompts/summary.txt`](prompts/summary.txt)
2. Cambia "M√°ximo 150 palabras" a "M√°ximo 50 palabras"
3. Re-despliega: `cdk deploy AISummaryStack`
4. Genera otro resumen y compara

#### Experimento 3: Agregar M√°s Ejemplos a Clasificaci√≥n

1. Abre [`prompts/classification.txt`](prompts/classification.txt)
2. Agrega un 4to ejemplo con un caso espec√≠fico
3. Re-despliega: `cdk deploy AIClassificationStack`
4. Clasifica varios informes y observa mejoras

#### Experimento 4: Cambiar Temperature

Prueba diferentes valores de temperature:

| Temperature | Uso Ideal | Resultado |
|-------------|-----------|-----------|
| 0.0 - 0.2 | Extracci√≥n, clasificaci√≥n | Determin√≠stico, preciso |
| 0.3 - 0.5 | Res√∫menes, an√°lisis | Balanceado |
| 0.6 - 0.8 | Emails, contenido | Creativo, variado |
| 0.9 - 1.0 | Brainstorming | Muy creativo |

#### Experimento 5: Comparar Con y Sin RAG

1. Modifica [`lambda/ai/classify_risk/index.py`](lambda/ai/classify_risk/index.py)
2. Comenta la secci√≥n que agrega contexto hist√≥rico
3. Re-despliega y compara resultados

**Pregunta:** ¬øC√≥mo mejora RAG la precisi√≥n?

---

## üîß Troubleshooting

### Problema 1: "Lambda not found" o "Function not found"

**Causa:** La Lambda no se despleg√≥ correctamente o est√°s usando el prefijo incorrecto.

**Soluci√≥n:**
```bash
# 1. Verifica que usaste tu prefijo correcto
# Ejemplo: participant-1, participant-2, etc.

# 2. Verifica que las Lambdas existen
aws lambda list-functions --query 'Functions[?contains(FunctionName, `participant-1`)].FunctionName'

# 3. Si no aparecen, re-despliega los AI Stacks
cd cdk
npx cdk deploy participant-1-AIClassificationStack participant-1-AISummaryStack --require-approval never
```

**Checklist:**
- ‚úÖ ¬øUsaste el prefijo correcto en todos los comandos?
- ‚úÖ ¬øCompletaste el despliegue del Paso 4 del Setup?
- ‚úÖ ¬øEst√°s en la regi√≥n correcta (us-east-2)?

---

### Problema 2: "Access denied to Aurora" o "Database connection failed"

**Causa:** La Lambda no tiene permisos para acceder a Aurora o hay un problema de red.

**Soluci√≥n:**
```bash
# 1. Verifica que el LegacyStack se despleg√≥ correctamente
aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].StackStatus'

# Debe retornar: "CREATE_COMPLETE" o "UPDATE_COMPLETE"

# 2. Verifica que Aurora est√° disponible
aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`AuroraEndpoint`].OutputValue' \
  --output text

# 3. Si el problema persiste, contacta al instructor
```

**Nota:** El instructor despleg√≥ tu LegacyStack antes del workshop. Si hay problemas, es probable que necesite re-desplegarlo.

---

### Problema 3: "Bedrock access denied" o "Model access denied"

**Causa:** Tu cuenta no tiene acceso al modelo Nova Pro o la regi√≥n es incorrecta.

**Soluci√≥n:**
```bash
# 1. Verifica que est√°s en us-east-2
aws configure get region

# 2. Verifica acceso a Bedrock
aws bedrock list-foundation-models --region us-east-2 \
  --query 'modelSummaries[?contains(modelId, `nova-pro`)].modelId'

# 3. Si no aparece, contacta al instructor
# El instructor debe habilitar el modelo en la cuenta
```

**Nota:** El acceso a Bedrock debe estar configurado por el instructor antes del workshop.

---

### Problema 4: Los logs no aparecen en CloudWatch

**Causa:** Los logs pueden tardar 1-2 minutos en aparecer despu√©s de invocar la Lambda.

**Soluci√≥n:**
```bash
# 1. Espera 1-2 minutos despu√©s de invocar la Lambda

# 2. Verifica que la Lambda se ejecut√≥
aws lambda invoke \
  --function-name participant-1-classify-risk \
  --payload '{"informe_id": 1}' \
  response.json

# 3. Intenta ver los logs nuevamente
aws logs tail /aws/lambda/participant-1-classify-risk --follow

# 4. Si a√∫n no aparecen, verifica el nombre del log group
aws logs describe-log-groups \
  --log-group-name-prefix /aws/lambda/participant-1
```

**Tip:** Presiona Ctrl+C para salir del comando `--follow`.

---

### Problema 5: La App Web no carga o muestra error

**Causa:** La URL es incorrecta o el bucket S3 no est√° configurado correctamente.

**Soluci√≥n:**
```bash
# 1. Obt√©n la URL correcta de tu app web
aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`WebsiteURL`].OutputValue' \
  --output text

# 2. Copia y pega la URL en tu navegador

# 3. Si muestra error 403 o 404, contacta al instructor
```

---

### Problema 6: "Informe not classified" al generar resumen

**Causa:** Est√°s intentando generar un resumen de un informe que no ha sido clasificado.

**Soluci√≥n:**
```bash
# 1. Primero clasifica el informe
aws lambda invoke \
  --function-name participant-1-classify-risk \
  --payload '{"informe_id": 1}' \
  response.json

# 2. Verifica que se clasific√≥ correctamente
cat response.json

# 3. Ahora genera el resumen
aws lambda invoke \
  --function-name participant-1-generate-summary \
  --payload '{"informe_id": 1}' \
  summary.json
```

**Regla:** Siempre debes clasificar un informe antes de generar su resumen.

---

### Problema 7: Comandos de CloudShell no funcionan

**Causa:** Sintaxis incorrecta o variables no definidas.

**Soluci√≥n:**
```bash
# 1. Verifica que definiste las variables de entorno
echo $CLUSTER_ARN
echo $SECRET_ARN

# 2. Si est√°n vac√≠as, def√≠nelas nuevamente
CLUSTER_ARN=$(aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`ClusterArn`].OutputValue' \
  --output text)

SECRET_ARN=$(aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs[?OutputKey==`SecretArn`].OutputValue' \
  --output text)

# 3. Verifica que ahora tienen valores
echo $CLUSTER_ARN
echo $SECRET_ARN
```

---

### Checklist General de Verificaci√≥n

Si tienes problemas, verifica estos puntos en orden:

1. **‚úÖ Prefijo correcto:** ¬øEst√°s usando `participant-1`, `participant-2`, etc. seg√∫n tu asignaci√≥n?
2. **‚úÖ Regi√≥n correcta:** ¬øEst√°s en `us-east-2`?
3. **‚úÖ Sesi√≥n AWS activa:** ¬øPuedes ejecutar `aws sts get-caller-identity` sin errores?
4. **‚úÖ Stacks desplegados:** ¬øCompletaste el Paso 4 del Setup (despliegue de AI Stacks)?
5. **‚úÖ Logs recientes:** ¬øEsperaste 1-2 minutos para que aparezcan los logs?

---

### Comandos √ötiles para Debugging

```bash
# Ver todos tus stacks
aws cloudformation list-stacks \
  --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE \
  --query 'StackSummaries[?contains(StackName, `participant-1`)].StackName'

# Ver todas tus Lambdas
aws lambda list-functions \
  --query 'Functions[?contains(FunctionName, `participant-1`)].FunctionName'

# Ver outputs de un stack
aws cloudformation describe-stacks \
  --stack-name participant-1-MedicalReportsLegacyStack \
  --query 'Stacks[0].Outputs'

# Ver √∫ltimos logs de una Lambda (sin follow)
aws logs tail /aws/lambda/participant-1-classify-risk --since 5m
```

---

### ¬øCu√°ndo pedir ayuda al instructor?

Pide ayuda si:
- ‚ùå Los comandos de verificaci√≥n muestran que faltan recursos
- ‚ùå Ves errores de permisos IAM o Bedrock
- ‚ùå La App Web no carga despu√©s de verificar la URL
- ‚ùå Los problemas persisten despu√©s de seguir las soluciones

**No te preocupes:** Estos workshops tienen muchas partes m√≥viles. El instructor est√° para ayudarte! üôÇ

---

## üìã Ejemplos de Output Esperado

Esta secci√≥n muestra ejemplos de outputs correctos para que puedas verificar que todo funciona bien.

### Output 1: Clasificaci√≥n Exitosa

**Comando:**
```bash
aws lambda invoke \
  --function-name participant-1-classify-risk \
  --payload '{"informe_id": 1}' \
  response.json && cat response.json
```

**Output esperado:**
```json
{
  "statusCode": 200,
  "body": {
    "informe_id": 1,
    "nivel_riesgo": "ALTO",
    "justificacion": "El trabajador presenta hipertensi√≥n arterial severa (165/102 mmHg) que supera significativamente los valores normales. Adem√°s, se observa obesidad grado I (IMC 32.9) y diabetes mellitus descompensada. Estos factores combinados representan un riesgo cardiovascular elevado que requiere intervenci√≥n m√©dica inmediata.",
    "tiempo_procesamiento": "2.3s",
    "informes_anteriores_encontrados": 2
  }
}
```

**Qu√© verificar:**
- ‚úÖ `statusCode: 200` (√©xito)
- ‚úÖ `nivel_riesgo` es uno de: BAJO, MEDIO, ALTO
- ‚úÖ `justificacion` tiene sentido m√©dicamente
- ‚úÖ `tiempo_procesamiento` es razonable (1-5 segundos)

---

### Output 2: Generaci√≥n de Resumen Exitosa

**Comando:**
```bash
aws lambda invoke \
  --function-name participant-1-generate-summary \
  --payload '{"informe_id": 1}' \
  summary.json && cat summary.json
```

**Output esperado:**
```json
{
  "statusCode": 200,
  "body": {
    "informe_id": 1,
    "resumen": "El trabajador Carlos Rodr√≠guez presenta m√∫ltiples factores de riesgo que requieren atenci√≥n m√©dica inmediata. Se detecta hipertensi√≥n arterial severa (165/102 mmHg) y obesidad grado I (IMC: 32.9). Los ex√°menes de laboratorio revelan diabetes mellitus descompensada. Comparado con su examen anterior hace 6 meses, se observa deterioro significativo en todos los par√°metros. Se recomienda restricci√≥n inmediata de actividades de alto riesgo y evaluaci√≥n m√©dica urgente.",
    "palabras": 87,
    "tiempo_procesamiento": "1.8s",
    "incluye_contexto_historico": true
  }
}
```

**Qu√© verificar:**
- ‚úÖ `statusCode: 200` (√©xito)
- ‚úÖ `resumen` es claro y no t√©cnico
- ‚úÖ `palabras` est√° entre 80-180
- ‚úÖ Menciona el nivel de riesgo y acciones recomendadas

---

### Output 3: Logs de Clasificaci√≥n

**Comando:**
```bash
aws logs tail /aws/lambda/participant-1-classify-risk --since 5m
```

**Output esperado (fragmentos clave):**
```
2024-12-02T10:15:23.456Z [INFO] Lambda invocation started
2024-12-02T10:15:23.567Z [INFO] Loading informe ID: 1
2024-12-02T10:15:23.678Z [INFO] Worker ID: 3, searching for historical reports
2024-12-02T10:15:23.789Z [INFO] RAG: Retrieved 2 previous reports
2024-12-02T10:15:23.890Z [INFO] Loading classification prompt from S3
2024-12-02T10:15:23.991Z [INFO] Few-shot examples loaded: 3 examples
2024-12-02T10:15:24.102Z [INFO] Invoking Bedrock with inference profile: us.amazon.nova-pro-v1:0
2024-12-02T10:15:25.234Z [INFO] Bedrock response received
2024-12-02T10:15:25.345Z [INFO] Classification result: ALTO
2024-12-02T10:15:25.456Z [INFO] Saving to Aurora database
2024-12-02T10:15:25.567Z [INFO] Lambda execution completed successfully
```

**Qu√© buscar:**
- ‚úÖ `RAG: Retrieved X previous reports` (contexto hist√≥rico)
- ‚úÖ `Few-shot examples loaded` (prompt con ejemplos)
- ‚úÖ `Invoking Bedrock` (llamada a IA)
- ‚úÖ `Classification result: BAJO/MEDIO/ALTO` (resultado)
- ‚úÖ `Lambda execution completed successfully` (√©xito)

---

### Output 4: Query a Aurora

**Comando:**
```bash
aws rds-data execute-statement \
  --resource-arn $CLUSTER_ARN \
  --secret-arn $SECRET_ARN \
  --database medical_reports \
  --sql "SELECT id, nivel_riesgo, LENGTH(resumen_ejecutivo) as resumen_length FROM informes_medicos WHERE id = 1"
```

**Output esperado:**
```json
{
  "records": [
    [
      {"longValue": 1},
      {"stringValue": "ALTO"},
      {"longValue": 523}
    ]
  ],
  "columnMetadata": [
    {"name": "id", "type": 4},
    {"name": "nivel_riesgo", "type": 12},
    {"name": "resumen_length", "type": 4}
  ]
}
```

**Qu√© verificar:**
- ‚úÖ `nivel_riesgo` tiene un valor (BAJO/MEDIO/ALTO)
- ‚úÖ `resumen_length` es mayor a 0 (si ya generaste el resumen)

---

### Output 5: Lista de Informes (App Web)

**Endpoint:** `GET /informes`

**Output esperado:**
```json
{
  "informes": [
    {
      "id": 1,
      "trabajador_nombre": "Juan P√©rez G√≥mez",
      "tipo_examen": "Examen Ocupacional Peri√≥dico",
      "presion_arterial": "165/102",
      "nivel_riesgo": "ALTO",
      "fecha_examen": "2024-12-01T10:00:00Z"
    },
    {
      "id": 2,
      "trabajador_nombre": "Mar√≠a Gonz√°lez L√≥pez",
      "tipo_examen": "Examen Pre-Ocupacional",
      "presion_arterial": "135/85",
      "nivel_riesgo": "MEDIO",
      "fecha_examen": "2024-12-01T11:00:00Z"
    },
    ...
  ]
}
```

**Qu√© verificar:**
- ‚úÖ Array con 10 informes
- ‚úÖ Cada informe tiene datos completos
- ‚úÖ Algunos tienen `nivel_riesgo` null (no clasificados a√∫n)

---

### Errores Comunes y Sus Outputs

#### Error 1: Lambda no encontrada
```json
{
  "errorMessage": "Function not found: arn:aws:lambda:us-east-2:123456789012:function:participant-1-classify-risk",
  "errorType": "ResourceNotFoundException"
}
```
**Soluci√≥n:** Verifica el prefijo y que desplegaste los AI Stacks.

#### Error 2: Informe no clasificado
```json
{
  "statusCode": 400,
  "body": {
    "error": "InformeNotClassifiedError",
    "message": "El informe debe ser clasificado antes de generar resumen",
    "informe_id": 1
  }
}
```
**Soluci√≥n:** Clasifica el informe primero con `classify-risk`.

#### Error 3: Bedrock access denied
```json
{
  "statusCode": 502,
  "body": {
    "error": "BedrockInvocationError",
    "message": "Access denied to Bedrock model",
    "model_id": "us.amazon.nova-pro-v1:0"
  }
}
```
**Soluci√≥n:** Contacta al instructor para habilitar acceso a Bedrock.

---

## üßπ Limpieza de Recursos

Al finalizar el workshop, elimina todos los recursos:

```bash
cd cdk

# Eliminar todos los stacks
cdk destroy --all

# Confirmar: y

# Verificar que todo se elimin√≥
aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE
```

**Importante:** Aurora se eliminar√° autom√°ticamente sin crear snapshots (configurado para la demo).

---

## üìä Resumen de Conceptos Aprendidos

### Servicios AWS
- ‚úÖ **Amazon Bedrock** - LLMs como servicio
- ‚úÖ **Amazon Nova Pro** - Modelo de lenguaje avanzado
- ‚úÖ **Amazon Titan Embeddings** - Generaci√≥n de embeddings
- ‚úÖ **Amazon Textract** - OCR para PDFs
- ‚úÖ **Aurora Serverless v2** - Base de datos con pgvector
- ‚úÖ **Lambda** - Funciones serverless
- ‚úÖ **S3** - Almacenamiento de objetos
- ‚úÖ **SES** - Env√≠o de emails
- ‚úÖ **CDK** - Infraestructura como c√≥digo

### T√©cnicas de IA Generativa
- ‚úÖ **Prompt Engineering** - Dise√±o de prompts efectivos
- ‚úÖ **Few-Shot Learning** - Aprendizaje con pocos ejemplos
- ‚úÖ **RAG** - Retrieval-Augmented Generation
- ‚úÖ **Embeddings Vectoriales** - Representaci√≥n de texto
- ‚úÖ **Temperature Control** - Control de aleatoriedad
- ‚úÖ **Token Management** - Gesti√≥n de longitud de respuestas

### Mejores Pr√°cticas
- ‚úÖ Prompts espec√≠ficos con ejemplos
- ‚úÖ Temperature baja para precisi√≥n
- ‚úÖ RAG para reducir alucinaciones
- ‚úÖ Iteraci√≥n de prompts
- ‚úÖ Validaci√≥n de salidas
- ‚úÖ Monitoreo con CloudWatch

---

## üéØ Pr√≥ximos Pasos

Despu√©s del workshop, puedes:

1. **Experimentar m√°s** con diferentes prompts y par√°metros
2. **Agregar nuevos casos de uso** (ej: an√°lisis de tendencias)
3. **Integrar con otros servicios** (ej: Step Functions para orquestaci√≥n)
4. **Optimizar costos** ajustando modelos y par√°metros
5. **Implementar en producci√≥n** con mejores pr√°cticas de seguridad

---

## üìö Recursos Adicionales

- [Amazon Bedrock Documentation](https://docs.aws.amazon.com/bedrock/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [AWS CDK Documentation](https://docs.aws.amazon.com/cdk/)
- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [RAG Best Practices](https://aws.amazon.com/blogs/machine-learning/rag-best-practices/)

---

## ‚ùì Preguntas Frecuentes

**P: ¬øCu√°nto cuesta ejecutar esta demo?**
R: Aproximadamente $5-10 USD por participante (Aurora + Bedrock + otros servicios).

**P: ¬øPuedo usar otros modelos de Bedrock?**
R: S√≠, puedes cambiar el modelId en el c√≥digo. Ejemplos: Claude, Llama, etc.

**P: ¬øFunciona en otras regiones?**
R: S√≠, pero verifica disponibilidad de Bedrock en tu regi√≥n.

**P: ¬øC√≥mo escalo esto a producci√≥n?**
R: Agrega: autenticaci√≥n, rate limiting, monitoreo avanzado, CI/CD, y backups.

**P: ¬øPuedo usar mis propios PDFs?**
R: S√≠, sube cualquier PDF m√©dico a S3 en la carpeta `/external-reports/`.

---

**¬°Felicitaciones!** üéâ Has completado el workshop de Automatizaci√≥n de Informes M√©dicos con AWS y Amazon Bedrock.

¬øPreguntas? Consulta con el instructor o revisa la [Gu√≠a del Instructor](INSTRUCTOR_GUIDE.md).


---

## üèóÔ∏è Arquitectura del Workshop (Informaci√≥n Adicional)

### ¬øPor qu√© el despliegue es tan r√°pido ahora?

El workshop usa una **arquitectura optimizada** que separa la infraestructura en dos capas:

#### Capa 1: Infraestructura Base (Desplegada por el Instructor)
- **SharedNetworkStack:** VPC compartida para todos los participantes
- **LegacyStack:** Tu Aurora, S3, API Gateway y Lambdas Legacy
- **Tiempo:** ~15 minutos por participante (desplegado antes del workshop)

#### Capa 2: AI Stacks (Desplegada por Ti)
- **5 AI Stacks:** Lambdas de procesamiento de IA
- **Tiempo:** ~5-8 minutos (desplegado durante el workshop)

### Beneficios de esta Arquitectura

‚úÖ **M√°s tiempo para aprender:** 70-80% menos tiempo de despliegue en vivo
‚úÖ **Recursos compartidos:** VPC compartida reduce costos
‚úÖ **Aislamiento completo:** Cada participante tiene su propia Aurora y S3
‚úÖ **Despliegue paralelo:** El instructor puede preparar m√∫ltiples participantes simult√°neamente

### Recursos que Tienes

Despu√©s del despliegue, tienes acceso a:

**Base de Datos:**
- Aurora Serverless v2 (PostgreSQL 15.8 con pgvector)
- Credenciales en AWS Secrets Manager
- Tablas: `patients`, `exams`, `exam_embeddings`

**Almacenamiento:**
- S3 Bucket individual: `<tu-prefix>-medical-reports-<account-id>`
- Carpetas: `external-reports/`, `generated-reports/`

**APIs:**
- API Gateway con endpoints:
  - `POST /examenes` - Registrar examen
  - `POST /examenes/generar-prueba` - Generar datos de prueba

**Lambdas de IA:**
- `extract-pdf` - Extracci√≥n con Textract + Bedrock
- `generate-embeddings` - Embeddings con Titan
- `classify-risk` - Clasificaci√≥n con Nova Pro
- `generate-summary` - Res√∫menes con Nova Pro
- `send-email` - Emails con Nova Pro + SES

### Documentaci√≥n Adicional

- **Modos de despliegue:** Ver [`cdk/DEPLOY_MODES.md`](cdk/DEPLOY_MODES.md)
- **Gu√≠a del instructor:** Ver [`INSTRUCTOR_GUIDE.md`](INSTRUCTOR_GUIDE.md)
- **Arquitectura t√©cnica:** Ver [`.kiro/specs/workshop-deployment-optimization/design.md`](.kiro/specs/workshop-deployment-optimization/design.md)

---

## üÜò Soporte

Si tienes problemas durante el workshop:

1. **Revisa la secci√≥n de Troubleshooting** en el Setup Inicial
2. **Verifica CloudFormation** en la consola AWS
3. **Consulta CloudWatch Logs** para errores de Lambda
4. **Contacta al instructor** para ayuda

---

**¬°Disfruta el workshop y aprende mucho! üöÄ**
