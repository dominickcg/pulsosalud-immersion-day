# GuÃ­a de ExperimentaciÃ³n Libre - Workshop DÃ­a 2

## IntroducciÃ³n

Esta guÃ­a proporciona ideas y ejercicios para que explores las capacidades avanzadas de IA del DÃ­a 2 por tu cuenta. Experimenta, prueba, rompe cosas y aprende.

## Ideas para Experimentar

### 1. Modificar Prompts de Emails

#### Experimento: Cambiar el Tono de los Emails

**Objetivo**: Ver cÃ³mo diferentes prompts afectan el tono y contenido de los emails.

**Pasos**:
1. Abre `prompts/email-alto-riesgo.txt`
2. Modifica el tono (mÃ¡s formal, mÃ¡s casual, mÃ¡s tÃ©cnico)
3. Guarda los cambios
4. Ejecuta `.\invoke-email.ps1 -InformeId 1`
5. Compara el resultado con el email original

**Variaciones para probar**:
- Tono mÃ¡s tÃ©cnico (incluir mÃ¡s tÃ©rminos mÃ©dicos)
- Tono mÃ¡s simple (lenguaje mÃ¡s accesible)
- MÃ¡s empÃ¡tico (enfatizar apoyo emocional)
- MÃ¡s directo (ir al grano rÃ¡pidamente)

**Preguntas guÃ­a**:
- Â¿QuÃ© tono funciona mejor para cada nivel de riesgo?
- Â¿CÃ³mo afecta el tono a la longitud del email?
- Â¿QuÃ© tono preferirÃ­as recibir como empleado?

#### Experimento: Agregar Secciones Nuevas

**Objetivo**: Personalizar la estructura de los emails.

**Ideas**:
- Agregar secciÃ³n de "Preguntas Frecuentes"
- Incluir timeline visual de seguimiento
- Agregar recursos adicionales (videos, artÃ­culos)
- Incluir testimonios motivacionales (sin violar privacidad)

### 2. Experimentar con Embeddings

#### Experimento: Comparar Similitud de Diferentes Casos

**Objetivo**: Entender quÃ© hace que dos casos sean "similares".

**Pasos**:
1. Genera embeddings para varios informes:
   ```powershell
   1..5 | ForEach-Object { .\invoke-embeddings.ps1 -InformeId $_ }
   ```

2. Busca similares para cada uno:
   ```powershell
   1..5 | ForEach-Object { 
       Write-Host "`n=== Similares para Informe $_ ===" 
       .\test-similarity-search.ps1 -InformeId $_ 
   }
   ```

3. Analiza los resultados:
   - Â¿QuÃ© casos tienen similarity scores mÃ¡s altos?
   - Â¿Por quÃ© son similares?
   - Â¿Hay sorpresas?

**Preguntas guÃ­a**:
- Â¿Los casos con mismo tipo de examen son mÃ¡s similares?
- Â¿Los casos con misma ocupaciÃ³n son mÃ¡s similares?
- Â¿QuÃ© pesa mÃ¡s: datos numÃ©ricos o texto de observaciones?

#### Experimento: Modificar el Texto de Embeddings

**Objetivo**: Ver cÃ³mo diferentes textos afectan la similitud.

**Pasos**:
1. Abre `lambda/ai/generate_embeddings/index.py`
2. Modifica la funciÃ³n que construye el texto para embeddings
3. Prueba diferentes combinaciones:
   - Solo observaciones
   - Solo datos numÃ©ricos
   - Observaciones + tipo de examen
   - Todo el contexto

4. Regenera embeddings y compara resultados

**Nota**: Esto requiere redesplegar la Lambda.

### 3. Experimentar con BÃºsqueda de Similitud

#### Experimento: Ajustar el NÃºmero de Resultados

**Objetivo**: Encontrar el nÃºmero Ã³ptimo de casos similares.

**Pasos**:
```powershell
# Probar diferentes valores de TopK
.\test-similarity-search.ps1 -InformeId 1 -TopK 3
.\test-similarity-search.ps1 -InformeId 1 -TopK 5
.\test-similarity-search.ps1 -InformeId 1 -TopK 10
```

**Preguntas guÃ­a**:
- Â¿CuÃ¡ntos casos similares son Ãºtiles para un mÃ©dico?
- Â¿A partir de quÃ© nÃºmero los scores bajan mucho?
- Â¿Hay un punto de rendimientos decrecientes?

#### Experimento: Filtrar por Nivel de Riesgo

**Objetivo**: Buscar solo casos similares con el mismo nivel de riesgo.

**Pasos**:
1. Modifica la query en `test-similarity-search.ps1`
2. Agrega filtro: `AND im.nivel_riesgo = 'ALTO'`
3. Compara resultados con y sin filtro

**Preguntas guÃ­a**:
- Â¿Es Ãºtil filtrar por nivel de riesgo?
- Â¿O es mejor ver casos similares de todos los niveles?
- Â¿QuÃ© informaciÃ³n es mÃ¡s valiosa para el mÃ©dico?

### 4. Experimentar con Modelos de IA

#### Experimento: Cambiar Temperatura del Modelo

**Objetivo**: Ver cÃ³mo la temperatura afecta la creatividad del modelo.

**Pasos**:
1. Abre `lambda/ai/send_email/index.py`
2. Encuentra la configuraciÃ³n de temperatura (actualmente 0.7)
3. Prueba diferentes valores:
   - 0.3 (mÃ¡s conservador, mÃ¡s predecible)
   - 0.7 (balanceado)
   - 0.9 (mÃ¡s creativo, mÃ¡s variado)

4. Genera emails con cada temperatura y compara

**Preguntas guÃ­a**:
- Â¿QuÃ© temperatura genera emails mÃ¡s apropiados?
- Â¿Hay diferencia notable entre temperaturas?
- Â¿QuÃ© temperatura preferirÃ­as para emails mÃ©dicos?

#### Experimento: Probar Diferentes Modelos

**Objetivo**: Comparar modelos de Bedrock.

**Modelos disponibles**:
- Claude 3 Sonnet
- Claude 3.5 Sonnet
- Nova Pro (actual)
- Nova Lite

**Pasos**:
1. Modifica el model ID en la Lambda
2. Redesplega
3. Genera emails con cada modelo
4. Compara calidad, velocidad y costo

### 5. Experimentar con Queries SQL

#### Experimento: Crear Queries Personalizadas

**Objetivo**: Explorar los datos de diferentes maneras.

**Ideas de queries**:

```sql
-- 1. DistribuciÃ³n de niveles de riesgo por tipo de examen
SELECT 
    tipo_examen,
    nivel_riesgo,
    COUNT(*) as total
FROM informes_medicos
WHERE nivel_riesgo IS NOT NULL
GROUP BY tipo_examen, nivel_riesgo
ORDER BY tipo_examen, nivel_riesgo;

-- 2. Promedio de similarity scores por tipo de examen
SELECT 
    im.tipo_examen,
    AVG(1 - (ie1.embedding <=> ie2.embedding)) as avg_similarity
FROM informes_medicos im
JOIN informes_embeddings ie1 ON im.id = ie1.informe_id
CROSS JOIN informes_embeddings ie2
WHERE im.id != ie2.informe_id
GROUP BY im.tipo_examen;

-- 3. Casos con mayor variabilidad en similarity
SELECT 
    im.id,
    im.trabajador_nombre,
    MAX(1 - (ie1.embedding <=> ie2.embedding)) as max_sim,
    MIN(1 - (ie1.embedding <=> ie2.embedding)) as min_sim,
    MAX(1 - (ie1.embedding <=> ie2.embedding)) - 
    MIN(1 - (ie1.embedding <=> ie2.embedding)) as variability
FROM informes_medicos im
JOIN informes_embeddings ie1 ON im.id = ie1.informe_id
CROSS JOIN informes_embeddings ie2
WHERE im.id != ie2.informe_id
GROUP BY im.id, im.trabajador_nombre
ORDER BY variability DESC;
```

### 6. Experimentar con Privacidad

#### Experimento: Validar que Emails No Violan Privacidad

**Objetivo**: Asegurar que los emails generados respetan privacidad.

**Checklist de validaciÃ³n**:
```powershell
# Generar varios emails
1..10 | ForEach-Object {
    Write-Host "`n=== Email para Informe $_ ==="
    .\invoke-email.ps1 -InformeId $_
    
    # Revisar manualmente:
    # - Â¿Menciona otros empleados? âŒ
    # - Â¿Dice "casos similares"? âŒ
    # - Â¿Solo datos del empleado actual? âœ…
}
```

**Preguntas guÃ­a**:
- Â¿AlgÃºn email menciona informaciÃ³n de terceros?
- Â¿Los prompts son suficientemente claros sobre privacidad?
- Â¿Hay formas de mejorar los prompts?

## Ejercicios Guiados

### Ejercicio 1: Pipeline Completo

**Objetivo**: Ejecutar el flujo completo de procesamiento.

**Pasos**:
```powershell
# 1. Seleccionar un informe
$INFORME_ID = 1

# 2. Clasificar
.\invoke-classify.ps1 -InformeId $INFORME_ID

# 3. Generar resumen
.\invoke-summary.ps1 -InformeId $INFORME_ID

# 4. Generar embedding
.\invoke-embeddings.ps1 -InformeId $INFORME_ID

# 5. Buscar similares
.\test-similarity-search.ps1 -InformeId $INFORME_ID

# 6. Generar email
.\invoke-email.ps1 -InformeId $INFORME_ID
```

**Preguntas de reflexiÃ³n**:
- Â¿CuÃ¡nto tiempo tomÃ³ todo el proceso?
- Â¿QuÃ© paso fue mÃ¡s lento?
- Â¿CÃ³mo se podrÃ­a optimizar?

### Ejercicio 2: ComparaciÃ³n A/B de Prompts

**Objetivo**: Comparar dos versiones de un prompt.

**Pasos**:
1. Crea una copia del prompt original:
   ```powershell
   Copy-Item prompts/email-alto-riesgo.txt prompts/email-alto-riesgo-v2.txt
   ```

2. Modifica la versiÃ³n 2 con cambios especÃ­ficos

3. Genera emails con ambas versiones:
   ```powershell
   # VersiÃ³n 1
   .\invoke-email.ps1 -InformeId 1 > email-v1.txt
   
   # Cambiar prompt en Lambda a v2 y redesplegar
   
   # VersiÃ³n 2
   .\invoke-email.ps1 -InformeId 1 > email-v2.txt
   ```

4. Compara resultados:
   ```powershell
   code --diff email-v1.txt email-v2.txt
   ```

### Ejercicio 3: AnÃ¡lisis de Clusters

**Objetivo**: Identificar grupos de casos similares.

**Pasos**:
1. Genera embeddings para todos los informes
2. Calcula matriz de similitud completa
3. Identifica clusters (grupos de casos muy similares)
4. Analiza quÃ© tienen en comÃºn

**Query de ejemplo**:
```sql
-- Pares de informes con alta similitud (>0.9)
SELECT 
    im1.id as informe1,
    im2.id as informe2,
    t1.nombre as trabajador1,
    t2.nombre as trabajador2,
    im1.tipo_examen,
    1 - (ie1.embedding <=> ie2.embedding) as similarity
FROM informes_medicos im1
JOIN informes_embeddings ie1 ON im1.id = ie1.informe_id
JOIN trabajadores t1 ON im1.trabajador_id = t1.id
CROSS JOIN informes_medicos im2
JOIN informes_embeddings ie2 ON im2.id = ie2.informe_id
JOIN trabajadores t2 ON im2.trabajador_id = t2.id
WHERE im1.id < im2.id
  AND 1 - (ie1.embedding <=> ie2.embedding) > 0.9
ORDER BY similarity DESC;
```

## Preguntas de ExploraciÃ³n

### Sobre Embeddings

1. Â¿QuÃ© tan sensibles son los embeddings a cambios pequeÃ±os en el texto?
2. Â¿Los embeddings capturan mejor informaciÃ³n numÃ©rica o textual?
3. Â¿CÃ³mo afecta la longitud del texto a la calidad del embedding?
4. Â¿Hay casos donde embeddings dan resultados inesperados?

### Sobre BÃºsqueda de Similitud

1. Â¿QuÃ© threshold de similitud es apropiado? (0.7, 0.8, 0.9?)
2. Â¿Es mejor buscar muchos casos con baja similitud o pocos con alta?
3. Â¿CÃ³mo manejar casos donde no hay similares (similarity < 0.5)?
4. Â¿DeberÃ­amos filtrar por fecha (solo casos recientes)?

### Sobre GeneraciÃ³n de Emails

1. Â¿QuÃ© longitud de email es Ã³ptima?
2. Â¿DeberÃ­amos incluir mÃ¡s o menos detalles tÃ©cnicos?
3. Â¿CÃ³mo balancear informaciÃ³n vs. simplicidad?
4. Â¿QuÃ© secciones son mÃ¡s importantes para los empleados?

### Sobre Privacidad

1. Â¿Hay formas sutiles de violar privacidad que no son obvias?
2. Â¿CÃ³mo asegurar que prompts futuros respeten privacidad?
3. Â¿DeberÃ­amos auditar emails generados automÃ¡ticamente?
4. Â¿QuÃ© controles adicionales se podrÃ­an implementar?

## Recursos Adicionales

### DocumentaciÃ³n

- [Amazon Bedrock Documentation](https://docs.aws.amazon.com/bedrock/)
- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)

### Herramientas

- **AWS CloudWatch**: Ver logs de Lambdas
- **RDS Query Editor**: Ejecutar queries SQL
- **VS Code**: Editar prompts y cÃ³digo

### Scripts Ãštiles

```powershell
# Ver logs en tiempo real
.\view-logs.ps1

# Ejecutar query personalizada
aws rds-data execute-statement `
  --resource-arn $env:CLUSTER_ARN `
  --secret-arn $env:SECRET_ARN `
  --database $env:DATABASE_NAME `
  --sql "TU_QUERY_AQUI"

# Listar todas las Lambdas
aws lambda list-functions `
  --query 'Functions[?contains(FunctionName, `'$env:PARTICIPANT_PREFIX'`)].FunctionName'
```

## DesafÃ­os Avanzados

### DesafÃ­o 1: Optimizar Performance

**Objetivo**: Reducir el tiempo de procesamiento del pipeline completo.

**Ideas**:
- Procesar embeddings en paralelo
- Cachear resultados de bÃºsqueda
- Optimizar queries SQL
- Usar Ã­ndices mÃ¡s eficientes

### DesafÃ­o 2: Mejorar Calidad de Emails

**Objetivo**: Generar emails mÃ¡s personalizados y efectivos.

**Ideas**:
- Incluir historial del trabajador
- Adaptar lenguaje segÃºn educaciÃ³n/rol
- Agregar visualizaciones (grÃ¡ficos de tendencias)
- Incluir comparaciÃ³n con exÃ¡menes previos

### DesafÃ­o 3: Implementar ValidaciÃ³n AutomÃ¡tica

**Objetivo**: Detectar automÃ¡ticamente violaciones de privacidad.

**Ideas**:
- Crear funciÃ³n que analiza emails generados
- Buscar patrones prohibidos (nombres, "casos similares", etc.)
- Implementar sistema de alertas
- Crear dashboard de mÃ©tricas de privacidad

### DesafÃ­o 4: AnÃ¡lisis de Patrones Ocupacionales

**Objetivo**: Identificar riesgos por tipo de trabajo.

**Ideas**:
- Agrupar informes por ocupaciÃ³n
- Calcular riesgos promedio por ocupaciÃ³n
- Identificar patrones de salud ocupacional
- Generar recomendaciones preventivas por ocupaciÃ³n

## ConclusiÃ³n

La experimentaciÃ³n es clave para entender profundamente estas tecnologÃ­as. No tengas miedo de:

- Romper cosas (puedes redesplegar)
- Probar ideas locas
- Hacer preguntas
- Compartir descubrimientos con otros participantes

**Recuerda**: El objetivo es aprender, no tener todo perfecto.

## Comparte tus Descubrimientos

Si encuentras algo interesante:
1. Documenta quÃ© hiciste
2. Anota los resultados
3. Comparte con el instructor y otros participantes
4. Considera contribuir mejoras al proyecto

Â¡Feliz experimentaciÃ³n! ðŸš€
