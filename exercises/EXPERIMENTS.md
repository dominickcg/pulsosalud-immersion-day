# üß™ Ejercicios Pr√°cticos de Experimentaci√≥n

Esta gu√≠a contiene ejercicios pr√°cticos para experimentar con prompts, par√°metros y t√©cnicas de IA Generativa en el workshop de Medical Reports Automation.

## üéØ Objetivos

Al completar estos ejercicios, aprender√°s a:
- Ajustar par√°metros de modelos (temperature, maxTokens)
- Iterar y mejorar prompts
- Comparar resultados con y sin RAG
- Modificar tonos y estilos de contenido
- Medir el impacto de cambios en la calidad

---

## üìö Ejercicio 1: Experimentar con Temperature en Extracci√≥n

### Objetivo
Entender c√≥mo la temperature afecta la consistencia y precisi√≥n en tareas de extracci√≥n de datos.

### Contexto
La **temperature** controla la aleatoriedad del modelo:
- **0.0 - 0.2**: Determin√≠stico, siempre da respuestas similares
- **0.8 - 1.0**: Creativo, respuestas muy variadas

Para extracci√≥n de datos, queremos consistencia (temperature baja).

### Pasos

#### 1. Configuraci√≥n Inicial (Temperature 0.1)

Verifica la configuraci√≥n actual en `lambda/ai/extract_pdf/index.py`:

```python
"inferenceConfig": {
    "temperature": 0.1,  # ‚Üê Valor actual
    "maxTokens": 2000
}
```

#### 2. Subir PDF de Prueba

```bash
bash scripts/upload_sample_pdf.sh sample_data/informe_medio_riesgo.pdf <bucket-name>
```

#### 3. Verificar Resultado

```bash
# Ver logs
aws logs tail /aws/lambda/extract-pdf --follow

# Consultar datos extra√≠dos
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT trabajador_nombre, presion_arterial, peso FROM informes_medicos WHERE id = (SELECT MAX(id) FROM informes_medicos);"
```

Anota los resultados.

#### 4. Cambiar Temperature a 0.8

Edita `lambda/ai/extract_pdf/index.py`:

```python
"inferenceConfig": {
    "temperature": 0.8,  # ‚Üê Cambiar a 0.8
    "maxTokens": 2000
}
```

#### 5. Re-desplegar

```bash
cd cdk
cdk deploy AIExtractionStack
```

#### 6. Subir el Mismo PDF Otra Vez

```bash
# Renombrar para que se procese de nuevo
aws s3 cp sample_data/informe_medio_riesgo.pdf \
  s3://<bucket-name>/external-reports/informe_medio_riesgo_test2.pdf
```

#### 7. Comparar Resultados

```bash
# Ver √∫ltimos 2 registros
psql -h <endpoint> -U postgres -d medical_reports \
  -c "SELECT id, trabajador_nombre, presion_arterial, peso FROM informes_medicos ORDER BY id DESC LIMIT 2;"
```

### Preguntas para Reflexionar

1. ¬øLos datos extra√≠dos son id√©nticos con temperature 0.1 y 0.8?
2. ¬øCu√°l configuraci√≥n es m√°s consistente?
3. ¬øPor qu√© es importante la consistencia en extracci√≥n de datos?

### Resultado Esperado

- **Temperature 0.1**: Datos id√©nticos en m√∫ltiples extracciones
- **Temperature 0.8**: Puede haber variaciones en formato o valores

### Conclusi√≥n

Para extracci√≥n de datos estructurados, usa **temperature baja (0.1-0.2)** para garantizar consistencia.

---


## üìö Ejercicio 2: Ajustar maxTokens en Res√∫menes

### Objetivo
Entender c√≥mo maxTokens afecta la longitud y completitud de las respuestas.

### Contexto
**maxTokens** limita la longitud m√°xima de la respuesta del modelo:
- Muy bajo: Respuestas cortadas
- Muy alto: Respuestas verbosas
- Justo: Respuestas completas y concisas

### Pasos

#### 1. Configuraci√≥n Inicial (maxTokens 300)

Verifica en `lambda/ai/generate_summary/index.py`:

```python
"inferenceConfig": {
    "temperature": 0.5,
    "maxTokens": 300  # ‚Üê Valor actual
}
```

#### 2. Generar Resumen

```bash
aws lambda invoke \
  --function-name generate-summary \
  --payload '{"informe_id": 1}' \
  response.json

cat response.json
```

Anota la longitud del resumen (cuenta palabras).

#### 3. Cambiar maxTokens a 100

Edita `lambda/ai/generate_summary/index.py`:

```python
"inferenceConfig": {
    "temperature": 0.5,
    "maxTokens": 100  # ‚Üê Cambiar a 100
}
```

#### 4. Re-desplegar

```bash
cd cdk
cdk deploy AISummaryStack
```

#### 5. Generar Resumen con L√≠mite Bajo

```bash
# Actualizar el mismo informe
aws lambda invoke \
  --function-name generate-summary \
  --payload '{"informe_id": 1}' \
  response.json

cat response.json
```

#### 6. Cambiar maxTokens a 1000

```python
"inferenceConfig": {
    "temperature": 0.5,
    "maxTokens": 1000  # ‚Üê Cambiar a 1000
}
```

Re-desplegar y generar resumen nuevamente.

### Comparaci√≥n

| maxTokens | Longitud | Completitud | Observaciones |
|-----------|----------|-------------|---------------|
| 100 | ~50-70 palabras | Incompleto | Se corta a mitad |
| 300 | ~120-150 palabras | Completo | Balance ideal |
| 1000 | ~150-200 palabras | Completo | Puede ser verboso |

### Preguntas para Reflexionar

1. ¬øQu√© pasa cuando maxTokens es muy bajo?
2. ¬øEl modelo usa todos los tokens disponibles?
3. ¬øCu√°l es el balance ideal para res√∫menes ejecutivos?

### Resultado Esperado

- **maxTokens 100**: Resumen cortado, informaci√≥n incompleta
- **maxTokens 300**: Resumen completo y conciso
- **maxTokens 1000**: Resumen completo, posiblemente con informaci√≥n redundante

### Conclusi√≥n

Ajusta maxTokens seg√∫n la tarea:
- Res√∫menes cortos: 200-300 tokens
- Res√∫menes detallados: 500-800 tokens
- An√°lisis completos: 1000-2000 tokens

---

## üìö Ejercicio 3: Mejorar Few-Shot Learning en Clasificaci√≥n

### Objetivo
Ver c√≥mo agregar m√°s ejemplos mejora la precisi√≥n de clasificaci√≥n.

### Contexto
**Few-shot learning** usa ejemplos en el prompt para ense√±ar al modelo. M√°s ejemplos (hasta cierto punto) = mejor precisi√≥n.

### Pasos

#### 1. Versi√≥n Actual (3 ejemplos)

Revisa `prompts/classification.txt`. Actualmente tiene 3 ejemplos (BAJO, MEDIO, ALTO).

#### 2. Clasificar Varios Informes

```bash
# Generar 5 informes de prueba
for i in {1..5}; do
  aws lambda invoke \
    --function-name generate-test-data \
    --payload '{}' \
    response.json
done

# Clasificar todos
for i in {1..5}; do
  aws lambda invoke \
    --function-name classify-risk \
    --payload "{\"informe_id\": $i}" \
    response.json
  
  echo "Informe $i:"
  cat response.json
  echo ""
done
```

Anota la precisi√≥n de las clasificaciones.

#### 3. Agregar M√°s Ejemplos

Edita `prompts/classification.txt` y agrega 2 ejemplos m√°s:

```
EJEMPLOS:

[Ejemplo BAJO 1]
...

[Ejemplo BAJO 2 - NUEVO]
Trabajador: Ana Mart√≠nez
Presi√≥n: 115/72 mmHg
IMC: 22.1
Colesterol: 175 mg/dL
Glucosa: 88 mg/dL
Clasificaci√≥n: BAJO
Justificaci√≥n: Todos los par√°metros √≥ptimos. Trabajadora joven y saludable...

[Ejemplo MEDIO 1]
...

[Ejemplo MEDIO 2 - NUEVO]
Trabajador: Roberto Silva
Presi√≥n: 138/86 mmHg
IMC: 26.8
Colesterol: 208 mg/dL
Clasificaci√≥n: MEDIO
Justificaci√≥n: Presi√≥n arterial en l√≠mite superior. Sobrepeso leve...

[Ejemplo ALTO 1]
...

[Ejemplo ALTO 2 - NUEVO]
Trabajador: Patricia G√≥mez
Presi√≥n: 160/98 mmHg
IMC: 33.5
Glucosa: 152 mg/dL
Colesterol: 245 mg/dL
Clasificaci√≥n: ALTO
Justificaci√≥n: Hipertensi√≥n grado 2, obesidad, hiperglucemia...
```

#### 4. Re-desplegar

```bash
cd cdk
cdk deploy AIClassificationStack
```

#### 5. Clasificar los Mismos Informes

```bash
# Reclasificar
for i in {1..5}; do
  aws lambda invoke \
    --function-name classify-risk \
    --payload "{\"informe_id\": $i}" \
    response.json
  
  echo "Informe $i (con m√°s ejemplos):"
  cat response.json
  echo ""
done
```

### Comparaci√≥n

| Configuraci√≥n | Precisi√≥n | Justificaciones | Observaciones |
|---------------|-----------|-----------------|---------------|
| 3 ejemplos | ~70-80% | Gen√©ricas | Funciona pero puede mejorar |
| 6 ejemplos | ~85-95% | M√°s espec√≠ficas | Mejor comprensi√≥n de matices |

### Preguntas para Reflexionar

1. ¬øLas clasificaciones son m√°s precisas con m√°s ejemplos?
2. ¬øLas justificaciones son m√°s detalladas?
3. ¬øHay un punto donde m√°s ejemplos no ayudan?

### Resultado Esperado

- **3 ejemplos**: Clasificaci√≥n funcional pero b√°sica
- **6 ejemplos**: Clasificaci√≥n m√°s precisa y justificaciones detalladas
- **10+ ejemplos**: Mejora marginal (rendimientos decrecientes)

### Conclusi√≥n

Para few-shot learning:
- **M√≠nimo**: 1-2 ejemplos por categor√≠a
- **√ìptimo**: 2-3 ejemplos por categor√≠a
- **M√°ximo √∫til**: 5 ejemplos por categor√≠a

---


## üìö Ejercicio 4: Modificar Tono en Emails

### Objetivo
Aprender a controlar el tono y estilo del contenido generado mediante prompts.

### Contexto
El mismo dato puede comunicarse con diferentes tonos seg√∫n la audiencia y urgencia. Los prompts permiten controlar esto.

### Pasos

#### 1. Tono Actual (Urgente para ALTO riesgo)

Revisa `prompts/email_high.txt`:

```
Genera un email URGENTE para el contratista.

TONO: Urgente pero profesional
OBJETIVO: Acci√≥n inmediata

Incluye:
- Hallazgos cr√≠ticos destacados
- Acciones requeridas INMEDIATAMENTE
- Consecuencias de no actuar
```

#### 2. Enviar Email con Tono Urgente

```bash
# Aseg√∫rate de tener un informe de ALTO riesgo
aws lambda invoke \
  --function-name send-email \
  --payload '{"informe_id": 1}' \
  response.json
```

Revisa el email recibido. Anota el tono y lenguaje usado.

#### 3. Cambiar a Tono Profesional Tranquilizador

Edita `prompts/email_high.txt`:

```
Genera un email PROFESIONAL para el contratista.

TONO: Profesional pero tranquilizador
OBJETIVO: Informar sin alarmar, pero motivar acci√≥n

Incluye:
- Hallazgos importantes de manera objetiva
- Recomendaciones claras y accionables
- Apoyo disponible para seguimiento
- Mensaje de que la situaci√≥n es manejable

EVITA:
- Lenguaje alarmista
- Palabras como "URGENTE", "CR√çTICO", "INMEDIATO"
- Tono de emergencia

USA:
- "Recomendamos atenci√≥n prioritaria"
- "Es importante abordar estos hallazgos"
- "Estamos disponibles para apoyar"
```

#### 4. Re-desplegar

```bash
cd cdk
cdk deploy AIEmailStack
```

#### 5. Enviar Email con Nuevo Tono

```bash
aws lambda invoke \
  --function-name send-email \
  --payload '{"informe_id": 1}' \
  response.json
```

Revisa el nuevo email. Compara con el anterior.

### Comparaci√≥n

| Aspecto | Tono Urgente | Tono Profesional |
|---------|--------------|------------------|
| Asunto | [URGENTE] Hallazgos cr√≠ticos | Informe m√©dico - Atenci√≥n requerida |
| Apertura | "Requiere atenci√≥n INMEDIATA" | "Le informamos sobre hallazgos importantes" |
| Cuerpo | Palabras en MAY√öSCULAS | Lenguaje objetivo y claro |
| Cierre | "Contactar HOY" | "Disponibles para consultas" |
| Impacto | Puede alarmar | Informa sin alarmar |

### Experimento Adicional: Tono Muy Formal

Prueba con un tono extremadamente formal:

```
Genera un email FORMAL CORPORATIVO para el contratista.

TONO: Extremadamente formal y t√©cnico
OBJETIVO: Comunicaci√≥n oficial

ESTILO:
- Lenguaje t√©cnico m√©dico
- Estructura de carta formal
- Referencias a normativas
- Terminolog√≠a legal

Ejemplo de apertura:
"Estimado/a [Nombre],

Por medio de la presente, nos dirigimos a usted en cumplimiento
de la normativa vigente en materia de salud ocupacional..."
```

### Preguntas para Reflexionar

1. ¬øC√≥mo afecta el tono a la percepci√≥n del mensaje?
2. ¬øQu√© tono es m√°s apropiado para cada nivel de riesgo?
3. ¬øC√≥mo balanceas urgencia con profesionalismo?

### Resultado Esperado

- **Tono Urgente**: Efectivo para acci√≥n inmediata, puede alarmar
- **Tono Profesional**: Balance entre seriedad y tranquilidad
- **Tono Formal**: Apropiado para comunicaciones oficiales

### Conclusi√≥n

El tono debe adaptarse a:
- **Nivel de riesgo**: ALTO = m√°s urgente, BAJO = tranquilizador
- **Audiencia**: Gerentes = ejecutivo, M√©dicos = t√©cnico
- **Contexto**: Primera notificaci√≥n = informativo, Seguimiento = urgente

---

## üìö Ejercicio 5: Comparar Resultados Con y Sin RAG

### Objetivo
Demostrar c√≥mo RAG (contexto hist√≥rico) mejora la precisi√≥n y relevancia de las respuestas.

### Contexto
RAG proporciona contexto espec√≠fico del trabajador, permitiendo clasificaciones y res√∫menes m√°s precisos que consideran tendencias.

### Pasos

#### 1. Crear Historial para un Trabajador

```bash
# Generar 3 informes para el mismo trabajador
for i in {1..3}; do
  aws lambda invoke \
    --function-name generate-test-data \
    --payload '{"trabajador_id": 1}' \
    response.json
  
  sleep 2
done

# Generar embeddings
for i in {1..3}; do
  aws lambda invoke \
    --function-name generate-embeddings \
    --payload "{\"informe_id\": $i}" \
    response.json
done
```

#### 2. Clasificar CON RAG (Configuraci√≥n Actual)

```bash
aws lambda invoke \
  --function-name classify-risk \
  --payload '{"informe_id": 3}' \
  response_with_rag.json

cat response_with_rag.json
```

Anota la justificaci√≥n. Deber√≠a mencionar tendencias o informes anteriores.

#### 3. Modificar C√≥digo para Omitir RAG

Edita `lambda/ai/classify_risk/index.py`:

```python
# Comentar la secci√≥n de RAG
# informes_anteriores = buscar_informes_similares(...)
# contexto_historico = construir_contexto(informes_anteriores)

# Usar contexto vac√≠o
contexto_historico = "No hay informes anteriores disponibles."
```

#### 4. Re-desplegar

```bash
cd cdk
cdk deploy AIClassificationStack
```

#### 5. Clasificar SIN RAG

```bash
aws lambda invoke \
  --function-name classify-risk \
  --payload '{"informe_id": 3}' \
  response_without_rag.json

cat response_without_rag.json
```

### Comparaci√≥n

| Aspecto | Sin RAG | Con RAG |
|---------|---------|---------|
| Contexto | Solo informe actual | Informe + historial |
| Justificaci√≥n | Basada en valores absolutos | Basada en tendencias |
| Precisi√≥n | ~70% | ~85-90% |
| Ejemplo | "Presi√≥n 135/85 es MEDIO" | "Presi√≥n subi√≥ de 120/75 a 135/85, tendencia preocupante = MEDIO" |

### Ejemplo de Salida

**Sin RAG:**
```json
{
  "nivel_riesgo": "MEDIO",
  "justificacion": "Presi√≥n arterial en 135/85 mmHg est√° en rango de pre-hipertensi√≥n. IMC de 27.2 indica sobrepeso leve."
}
```

**Con RAG:**
```json
{
  "nivel_riesgo": "MEDIO",
  "justificacion": "Presi√≥n arterial ha aumentado progresivamente en los √∫ltimos 3 ex√°menes (120/75 ‚Üí 128/80 ‚Üí 135/85 mmHg), mostrando tendencia ascendente preocupante. IMC tambi√©n aument√≥ de 25.1 a 27.2. Se recomienda seguimiento cercano para prevenir progresi√≥n a hipertensi√≥n."
}
```

### Preguntas para Reflexionar

1. ¬øLa justificaci√≥n con RAG es m√°s completa?
2. ¬øRAG detecta tendencias que sin RAG no se ven?
3. ¬øEn qu√© casos es cr√≠tico tener contexto hist√≥rico?

### Resultado Esperado

- **Sin RAG**: Clasificaci√≥n basada solo en valores actuales
- **Con RAG**: Clasificaci√≥n considerando evoluci√≥n y tendencias
- **Mejora**: 15-20% m√°s de precisi√≥n con RAG

### Conclusi√≥n

RAG es esencial cuando:
- El contexto hist√≥rico es relevante
- Las tendencias importan m√°s que valores absolutos
- Se necesita personalizaci√≥n por individuo

---


## üéØ Resumen de Ejercicios

### Ejercicio 1: Temperature en Extracci√≥n
**Aprendizaje clave:** Temperature baja (0.1-0.2) para tareas que requieren consistencia.

### Ejercicio 2: maxTokens en Res√∫menes
**Aprendizaje clave:** Ajustar maxTokens seg√∫n longitud deseada, con margen de seguridad.

### Ejercicio 3: Few-Shot Learning
**Aprendizaje clave:** 2-3 ejemplos por categor√≠a es √≥ptimo para clasificaci√≥n.

### Ejercicio 4: Control de Tono
**Aprendizaje clave:** El prompt controla el tono; adaptar seg√∫n audiencia y urgencia.

### Ejercicio 5: RAG vs Sin RAG
**Aprendizaje clave:** RAG mejora significativamente cuando el contexto hist√≥rico es relevante.

---

## üìä Tabla de Referencia R√°pida

### Par√°metros Recomendados por Tarea

| Tarea | Temperature | maxTokens | Few-Shot | RAG |
|-------|-------------|-----------|----------|-----|
| Extracci√≥n de datos | 0.1 - 0.2 | 1000-2000 | No necesario | No |
| Clasificaci√≥n | 0.2 - 0.4 | 300-500 | S√≠ (2-3 ejemplos) | S√≠ |
| Res√∫menes | 0.4 - 0.6 | 300-500 | Opcional | S√≠ |
| Emails | 0.6 - 0.8 | 500-800 | Opcional | Opcional |
| Contenido creativo | 0.7 - 0.9 | 800-1500 | Opcional | No |

### Gu√≠a de Temperature

| Rango | Uso | Caracter√≠sticas |
|-------|-----|-----------------|
| 0.0 - 0.2 | Extracci√≥n, datos | Determin√≠stico, preciso, consistente |
| 0.3 - 0.5 | An√°lisis, clasificaci√≥n | Balanceado, confiable |
| 0.6 - 0.8 | Contenido, emails | Creativo pero controlado |
| 0.9 - 1.0 | Brainstorming, ideas | Muy creativo, variado |

### Gu√≠a de maxTokens

| Longitud Deseada | maxTokens | Uso |
|------------------|-----------|-----|
| Muy corto (50 palabras) | 100-150 | T√≠tulos, res√∫menes ultra-cortos |
| Corto (100-150 palabras) | 200-300 | Res√∫menes ejecutivos |
| Medio (200-300 palabras) | 400-600 | An√°lisis, emails |
| Largo (500+ palabras) | 1000-2000 | Informes detallados |

---

## üî¨ Experimentos Avanzados (Opcional)

### Experimento A: Combinar M√∫ltiples T√©cnicas

Prueba combinar:
- Few-shot learning (3 ejemplos)
- RAG (contexto hist√≥rico)
- Temperature √≥ptima (0.3)
- Prompt bien estructurado

Compara con configuraci√≥n b√°sica.

### Experimento B: Prompt Engineering Iterativo

1. Escribe un prompt b√°sico
2. Prueba con 5 casos
3. Identifica errores comunes
4. Mejora el prompt
5. Repite hasta lograr 95%+ precisi√≥n

### Experimento C: A/B Testing de Prompts

Crea 2 versiones de un prompt:
- Versi√≥n A: Instrucciones directas
- Versi√≥n B: Con ejemplos y restricciones

Prueba con 20 casos y compara resultados.

### Experimento D: Optimizaci√≥n de Costos

Reduce costos sin sacrificar calidad:
1. Usa el modelo m√°s peque√±o que funcione
2. Reduce maxTokens al m√≠nimo necesario
3. Optimiza prompts para ser m√°s concisos
4. Implementa caching de respuestas comunes

---

## üìù Plantilla de Documentaci√≥n de Experimentos

Usa esta plantilla para documentar tus propios experimentos:

```markdown
## Experimento: [Nombre]

### Hip√≥tesis
[Qu√© esperas que pase]

### Configuraci√≥n
- Par√°metro modificado: [nombre]
- Valor original: [valor]
- Valor nuevo: [valor]

### Metodolog√≠a
1. [Paso 1]
2. [Paso 2]
3. [Paso 3]

### Resultados
| M√©trica | Original | Nuevo | Diferencia |
|---------|----------|-------|------------|
| [M√©trica 1] | [valor] | [valor] | [%] |
| [M√©trica 2] | [valor] | [valor] | [%] |

### Observaciones
- [Observaci√≥n 1]
- [Observaci√≥n 2]

### Conclusi√≥n
[Qu√© aprendiste]

### Recomendaci√≥n
[Qu√© configuraci√≥n usar en producci√≥n]
```

---

## üéì Evaluaci√≥n de Aprendizaje

Despu√©s de completar los ejercicios, deber√≠as poder responder:

### Preguntas Conceptuales

1. ¬øCu√°ndo usar temperature alta vs baja?
2. ¬øQu√© es few-shot learning y cu√°ndo usarlo?
3. ¬øC√≥mo RAG mejora las respuestas?
4. ¬øC√≥mo controlar el tono del contenido generado?
5. ¬øQu√© es maxTokens y c√≥mo afecta las respuestas?

### Preguntas Pr√°cticas

1. ¬øQu√© temperature usar√≠as para extraer datos de facturas?
2. ¬øCu√°ntos ejemplos incluir√≠as para clasificar sentimientos?
3. ¬øUsar√≠as RAG para generar descripciones de productos?
4. ¬øQu√© maxTokens configurar√≠as para tweets (280 caracteres)?
5. ¬øC√≥mo modificar√≠as un prompt para hacerlo m√°s formal?

### Desaf√≠o Final

Crea un nuevo caso de uso (ej: clasificar urgencia de tickets de soporte) y:
1. Dise√±a el prompt
2. Elige par√°metros apropiados
3. Decide si usar RAG
4. Implementa y prueba
5. Itera hasta lograr 90%+ precisi√≥n

---

## üìö Recursos Adicionales

### Documentaci√≥n

- [Amazon Bedrock - Inference Parameters](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [RAG Best Practices](https://aws.amazon.com/blogs/machine-learning/rag-best-practices/)

### Papers

- [Few-Shot Learning](https://arxiv.org/abs/2005.14165)
- [RAG: Retrieval-Augmented Generation](https://arxiv.org/abs/2005.11401)
- [Temperature in Language Models](https://arxiv.org/abs/1904.09751)

### Comunidades

- [AWS re:Post - Bedrock](https://repost.aws/tags/TA4IHBWMFxRRKzKzuCJAV_Aw/amazon-bedrock)
- [Prompt Engineering Discord](https://discord.gg/promptengineering)

---

## ‚úÖ Checklist de Completitud

Marca los ejercicios que completaste:

- [ ] Ejercicio 1: Temperature en Extracci√≥n
- [ ] Ejercicio 2: maxTokens en Res√∫menes
- [ ] Ejercicio 3: Few-Shot Learning en Clasificaci√≥n
- [ ] Ejercicio 4: Modificar Tono en Emails
- [ ] Ejercicio 5: Comparar Con y Sin RAG

Experimentos opcionales:
- [ ] Experimento A: Combinar M√∫ltiples T√©cnicas
- [ ] Experimento B: Prompt Engineering Iterativo
- [ ] Experimento C: A/B Testing de Prompts
- [ ] Experimento D: Optimizaci√≥n de Costos

---

## üéâ ¬°Felicitaciones!

Si completaste todos los ejercicios, ahora tienes experiencia pr√°ctica con:
- ‚úÖ Ajuste de par√°metros de modelos
- ‚úÖ Prompt engineering efectivo
- ‚úÖ Few-shot learning
- ‚úÖ RAG (Retrieval-Augmented Generation)
- ‚úÖ Control de tono y estilo
- ‚úÖ Experimentaci√≥n sistem√°tica

Est√°s listo para aplicar estas t√©cnicas en tus propios proyectos de IA Generativa.

---

**¬øPreguntas?** Consulta con el instructor o revisa:
- [Gu√≠a para Participantes](../PARTICIPANT_GUIDE.md)
- [Gu√≠a del Instructor](../INSTRUCTOR_GUIDE.md)
- [README Principal](../README.md)
